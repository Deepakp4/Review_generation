{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"148EcMqornzs-0uQ7oKhz5CaF06AtVyxe","authorship_tag":"ABX9TyP64V7UNpdlMqAz93nZcyEn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"70fced24c5a54e97be1fbcaec7c7fe8a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f495c49700514cd6b5e98caa3e7e9513","IPY_MODEL_258ab3211f454d9eae4cac7f075082a0","IPY_MODEL_a87e6b8f17db4114b71a0758a125bf5d"],"layout":"IPY_MODEL_b74088f4a537478abe1b3dcad94ca482"}},"f495c49700514cd6b5e98caa3e7e9513":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3ffd71f0d464be3b0ff44ebe973628b","placeholder":"​","style":"IPY_MODEL_9a68190ececf48c0b461059629f8a544","value":"100%"}},"258ab3211f454d9eae4cac7f075082a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e14c389b62bd4467a13067497241b0fc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a4dfc3134cc4588bc2f72bf908a70e3","value":1}},"a87e6b8f17db4114b71a0758a125bf5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68d09566f697493bb1aeb798742b37a2","placeholder":"​","style":"IPY_MODEL_af9a9ac63caa4a5199399288e42493b5","value":" 1/1 [00:00&lt;00:00,  4.23it/s]"}},"b74088f4a537478abe1b3dcad94ca482":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3ffd71f0d464be3b0ff44ebe973628b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a68190ececf48c0b461059629f8a544":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e14c389b62bd4467a13067497241b0fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a4dfc3134cc4588bc2f72bf908a70e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68d09566f697493bb1aeb798742b37a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af9a9ac63caa4a5199399288e42493b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36d379cc69b74b72a2dc711c1536fa91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd50c86224ae477ba9b2a041f5d4a802","IPY_MODEL_27e8b02f637d467b9affc68aa0ac5c4d","IPY_MODEL_14d15a5fbff44781885f92c36ebf732f"],"layout":"IPY_MODEL_2f84908cd8074913b07d4e01c2dd6411"}},"fd50c86224ae477ba9b2a041f5d4a802":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b377dc8953049efbf36a049f20af57e","placeholder":"​","style":"IPY_MODEL_2a5f1091743542af97d10bcea23ac977","value":"100%"}},"27e8b02f637d467b9affc68aa0ac5c4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fab31dd0a5d74d8ca7948b79c277498c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d21d0d7b0d2142209d1c58efcfb1d26a","value":1}},"14d15a5fbff44781885f92c36ebf732f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8c461150a3a45bdab9332f34ac46779","placeholder":"​","style":"IPY_MODEL_775adffecb3c4d7e86ed04c5ab2d045b","value":" 1/1 [00:00&lt;00:00, 48.84it/s]"}},"2f84908cd8074913b07d4e01c2dd6411":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b377dc8953049efbf36a049f20af57e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a5f1091743542af97d10bcea23ac977":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fab31dd0a5d74d8ca7948b79c277498c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d21d0d7b0d2142209d1c58efcfb1d26a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8c461150a3a45bdab9332f34ac46779":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"775adffecb3c4d7e86ed04c5ab2d045b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c7934460eb64f489516442ea240dc5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5267be041dc347e288fe45560d665473","IPY_MODEL_4702d9248bc6477e86027a0a919ecf75","IPY_MODEL_6e9e721e16cf45bfbe040976fb0b2454"],"layout":"IPY_MODEL_ec9da83594e849be800300bb54a007c2"}},"5267be041dc347e288fe45560d665473":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35045706f15f40bd95ab0affb58ed009","placeholder":"​","style":"IPY_MODEL_c887cb31ae654b7aa60a5f9680d0fdb9","value":"tokenizer_config.json: 100%"}},"4702d9248bc6477e86027a0a919ecf75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c8671034c484ba29531c704a2f3c312","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84091a60f3da4a189a7e41adca6b471c","value":25}},"6e9e721e16cf45bfbe040976fb0b2454":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9af3aaeabf64435fa369a79715e50444","placeholder":"​","style":"IPY_MODEL_bf48660e6fd8499a9ffa9f0596a9b2fb","value":" 25.0/25.0 [00:00&lt;00:00, 427B/s]"}},"ec9da83594e849be800300bb54a007c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35045706f15f40bd95ab0affb58ed009":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c887cb31ae654b7aa60a5f9680d0fdb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c8671034c484ba29531c704a2f3c312":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84091a60f3da4a189a7e41adca6b471c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9af3aaeabf64435fa369a79715e50444":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf48660e6fd8499a9ffa9f0596a9b2fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c7251c4e2ff46fb8cd78980dc472f0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0bb65857f4d244b1b09ef8f39b9617cb","IPY_MODEL_56f4244fca0049218e42e686a4c63ae4","IPY_MODEL_9361307afdfb4697966f17f563896336"],"layout":"IPY_MODEL_1cf27b95120e4c8eac43528770db8593"}},"0bb65857f4d244b1b09ef8f39b9617cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_812d5c4b9c204a9dbfff1685ce1bcba4","placeholder":"​","style":"IPY_MODEL_dc3e693ad23f4991aba6154fb19cfe56","value":"config.json: 100%"}},"56f4244fca0049218e42e686a4c63ae4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f787179fc30f4b19a4e05513b2fcb1d1","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_325625482a894123888875ac14f22bba","value":482}},"9361307afdfb4697966f17f563896336":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d6521a87bb94519af802689cba60f9f","placeholder":"​","style":"IPY_MODEL_b15e91b61f2245a59ad4cc56782f124f","value":" 482/482 [00:00&lt;00:00, 15.5kB/s]"}},"1cf27b95120e4c8eac43528770db8593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"812d5c4b9c204a9dbfff1685ce1bcba4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc3e693ad23f4991aba6154fb19cfe56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f787179fc30f4b19a4e05513b2fcb1d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"325625482a894123888875ac14f22bba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d6521a87bb94519af802689cba60f9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b15e91b61f2245a59ad4cc56782f124f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d5b71f37cdf4809ac595f795e36828c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5641369757eb4bb3a7e48e54a1b12d54","IPY_MODEL_ed713c2bce5d40cd860a4743b91097b6","IPY_MODEL_28770d730a10437fad24ee87ecab9c82"],"layout":"IPY_MODEL_46bc3abece124cde92f10a210745fb1e"}},"5641369757eb4bb3a7e48e54a1b12d54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1436a61d2d6b4573bb3e48bdf5a42357","placeholder":"​","style":"IPY_MODEL_d2dc7ef847ac41289860d0029a949a1a","value":"vocab.json: 100%"}},"ed713c2bce5d40cd860a4743b91097b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf7a24b138ae492da60da194feff3459","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a72f2320e1d74c42a8910e62e993b00c","value":898823}},"28770d730a10437fad24ee87ecab9c82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52ab2de7c99843caaa9d47bc0090884e","placeholder":"​","style":"IPY_MODEL_e7d1b6dcf2bc4c2286591f7b6fbb2684","value":" 899k/899k [00:00&lt;00:00, 1.30MB/s]"}},"46bc3abece124cde92f10a210745fb1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1436a61d2d6b4573bb3e48bdf5a42357":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2dc7ef847ac41289860d0029a949a1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf7a24b138ae492da60da194feff3459":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a72f2320e1d74c42a8910e62e993b00c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52ab2de7c99843caaa9d47bc0090884e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7d1b6dcf2bc4c2286591f7b6fbb2684":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1ff224f118e4769a96c9f4478b59d4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f8b0f24f79744338906c098fab6b562","IPY_MODEL_39884050088742eebf0ba17790a8d5fd","IPY_MODEL_cbdf6db4f81f4c83a68e256dd58dd2e5"],"layout":"IPY_MODEL_90cf1e9c1f704941b5ea72ac4eacc055"}},"1f8b0f24f79744338906c098fab6b562":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_893b83cfca764c93b94fd0b5624e2528","placeholder":"​","style":"IPY_MODEL_5db5fc3d45394b44b62d3ca1cf73449c","value":"merges.txt: 100%"}},"39884050088742eebf0ba17790a8d5fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c83138f04c5e483983b755f7f537f4cf","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5f84710072640288cee0f164de07b13","value":456318}},"cbdf6db4f81f4c83a68e256dd58dd2e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19912aeef009413691854003e2709343","placeholder":"​","style":"IPY_MODEL_5c9b9218cdec4fe2a9bbc592ec8fb36a","value":" 456k/456k [00:00&lt;00:00, 902kB/s]"}},"90cf1e9c1f704941b5ea72ac4eacc055":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"893b83cfca764c93b94fd0b5624e2528":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5db5fc3d45394b44b62d3ca1cf73449c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c83138f04c5e483983b755f7f537f4cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5f84710072640288cee0f164de07b13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19912aeef009413691854003e2709343":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c9b9218cdec4fe2a9bbc592ec8fb36a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d52c1e5cae6a41678bda6f3b84f2fe24":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08a3b406c59547d6a2cb355deac2bcbd","IPY_MODEL_c403833634c84729a1ace5192210ad72","IPY_MODEL_0a5d63f801434dd189c48d4da67550dc"],"layout":"IPY_MODEL_fc359521dbd5426d98b1f56996239bd2"}},"08a3b406c59547d6a2cb355deac2bcbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0db1f5c7a7624641a499c772784bcaba","placeholder":"​","style":"IPY_MODEL_4fe2fb020b6546dbab7696b7a3003674","value":"tokenizer.json: 100%"}},"c403833634c84729a1ace5192210ad72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e08b8892ad3a4b87ba803e770e0e6456","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_886ba8b53a554778aef5e29371505ff3","value":1355863}},"0a5d63f801434dd189c48d4da67550dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e72375e7c8446639bd73bc7962dccfc","placeholder":"​","style":"IPY_MODEL_04c4b4f703624def8d168dd581a4a892","value":" 1.36M/1.36M [00:00&lt;00:00, 7.64MB/s]"}},"fc359521dbd5426d98b1f56996239bd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0db1f5c7a7624641a499c772784bcaba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fe2fb020b6546dbab7696b7a3003674":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e08b8892ad3a4b87ba803e770e0e6456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"886ba8b53a554778aef5e29371505ff3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e72375e7c8446639bd73bc7962dccfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04c4b4f703624def8d168dd581a4a892":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f90f653ef38415f8635bc0aa0524269":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_363ff0aa5abc421484f44d8056a3125f","IPY_MODEL_0cf979c1ba994ec2beb955e81d8e5ec7","IPY_MODEL_f55ffdf1a1244cda93459b54fe870afc"],"layout":"IPY_MODEL_37e98f94c31247ccb4d6eaca6b230630"}},"363ff0aa5abc421484f44d8056a3125f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f636b9b2b9c84e8ca788a0c6290795df","placeholder":"​","style":"IPY_MODEL_17a8b14fdd4f40cf9b91e9f435f1bbcf","value":"model.safetensors: 100%"}},"0cf979c1ba994ec2beb955e81d8e5ec7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3d5eccd011445108629e4016dfd8ad9","max":1421700479,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4fc9ecf89a24a31b6187967a55be814","value":1421700479}},"f55ffdf1a1244cda93459b54fe870afc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3e77bf120e04673ab18a1f52f956014","placeholder":"​","style":"IPY_MODEL_bc7d4701bf0f4c3d8a1679bb32b6b56e","value":" 1.42G/1.42G [00:21&lt;00:00, 83.5MB/s]"}},"37e98f94c31247ccb4d6eaca6b230630":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f636b9b2b9c84e8ca788a0c6290795df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17a8b14fdd4f40cf9b91e9f435f1bbcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3d5eccd011445108629e4016dfd8ad9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4fc9ecf89a24a31b6187967a55be814":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3e77bf120e04673ab18a1f52f956014":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc7d4701bf0f4c3d8a1679bb32b6b56e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4f18bbc3f864296a598888a986c1d97":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a261d6bb848a4aa88848546a88856b3b","IPY_MODEL_b89d03378a8a421d9052e74342560e60","IPY_MODEL_d5e4ade75ef0464085da8378cdae6299"],"layout":"IPY_MODEL_523937b7bdab477fa385762cf8b5e6a1"}},"a261d6bb848a4aa88848546a88856b3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebee22d7f39a43588a2b43f167209c41","placeholder":"​","style":"IPY_MODEL_f244b1ed872d4ee7b00bb1916ae922a7","value":"100%"}},"b89d03378a8a421d9052e74342560e60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d94001953be1409b8f0279a1e46d3097","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63af27df613945df93f16c9e27045cb3","value":1}},"d5e4ade75ef0464085da8378cdae6299":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45ce41592a4241898225e5862aec07bc","placeholder":"​","style":"IPY_MODEL_3f789738af104506a2ad68171dba7c3d","value":" 1/1 [00:11&lt;00:00, 11.02s/it]"}},"523937b7bdab477fa385762cf8b5e6a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebee22d7f39a43588a2b43f167209c41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f244b1ed872d4ee7b00bb1916ae922a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d94001953be1409b8f0279a1e46d3097":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63af27df613945df93f16c9e27045cb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45ce41592a4241898225e5862aec07bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f789738af104506a2ad68171dba7c3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18cecac2b19042849ac9f867c9b5b61c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2655399b44d8469a82f0b9511829baa7","IPY_MODEL_519844e5030d42a0b09af18d2531c104","IPY_MODEL_c151308281ce434497d0db6a9669da72"],"layout":"IPY_MODEL_4148413c715e44ce8239e6ea06922b37"}},"2655399b44d8469a82f0b9511829baa7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f56e70b6bb14449aa303963d405fdb6c","placeholder":"​","style":"IPY_MODEL_c68896965a784ca390fcf475c8d41e8e","value":"100%"}},"519844e5030d42a0b09af18d2531c104":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0aaee3dfe07f4a4b8b4f53156e9b47b2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a28340861de844afabc80919d373c5dc","value":1}},"c151308281ce434497d0db6a9669da72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b59770fdcbeb4a5098152be453ee6054","placeholder":"​","style":"IPY_MODEL_9488291c7fc3412eafa2e0d2ba7fff62","value":" 1/1 [00:00&lt;00:00, 15.45it/s]"}},"4148413c715e44ce8239e6ea06922b37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f56e70b6bb14449aa303963d405fdb6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c68896965a784ca390fcf475c8d41e8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0aaee3dfe07f4a4b8b4f53156e9b47b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a28340861de844afabc80919d373c5dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b59770fdcbeb4a5098152be453ee6054":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9488291c7fc3412eafa2e0d2ba7fff62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"kGAtfVFSGsQd","executionInfo":{"status":"ok","timestamp":1724778567415,"user_tz":-60,"elapsed":35367,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","data = pd.read_json('/content/drive/MyDrive/Dissertation_review/merged/final_data-review.json')\n"]},{"cell_type":"markdown","source":["Baseline model 1\n"],"metadata":{"id":"Ndu138JLphsO"}},{"cell_type":"code","source":["\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":486},"id":"R9PcdwV12GsH","executionInfo":{"status":"ok","timestamp":1724778567416,"user_tz":-60,"elapsed":26,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"45be6968-9fa9-4328-919a-2e16bcfbb741"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              id conference                  decision  \\\n","0  ICLR_2017_381       ICLR                    Reject   \n","1  ICLR_2017_211       ICLR  Invite to Workshop Track   \n","2  ICLR_2017_200       ICLR  Invite to Workshop Track   \n","3  ICLR_2017_106       ICLR           Accept (Poster)   \n","4   ICLR_2017_64       ICLR           Accept (Poster)   \n","\n","                                                 url hasContent hasReview  \\\n","0  http://openreview.net/pdf/63b92f7ce8708e9df35d...       true      true   \n","1  http://openreview.net/pdf/5c54afd2ea867c72b8ae...       true      true   \n","2  http://openreview.net/pdf/e2d348d16ad96d19425e...       true      true   \n","3  http://openreview.net/pdf/5ab63afda67c68cd39a6...       true      true   \n","4  http://openreview.net/pdf/2cb01001f2f89ca11252...       true      true   \n","\n","                                               title  \\\n","0  Multi-task learning with deep model based rein...   \n","1  Nonparametrically Learning Activation Function...   \n","2  Discovering objects and their relations from e...   \n","3  Attend, Adapt and Transfer: Attentive Deep Arc...   \n","4  Training Compressed Fully-Connected Networks w...   \n","\n","                                             authors  \\\n","0                                     [Asier Mujika]   \n","1           [Carson Eisenach, Zhaoran Wang, Han Liu]   \n","2  [David Raposo, Adam Santoro, David Barrett, Ra...   \n","3  [Janarthanan Rajendran, Aravind Lakshminarayan...   \n","4  [Shengjie Wang, Haoran Cai, Jeff Bilmes, Willi...   \n","\n","                                             reviews metaReview  \\\n","0  [{'review': 'The term strategy is a bit ambigu...       None   \n","1  [{'review': 'This paper provides a principled ...       None   \n","2  [{'review': '+ Understanding relations between...       None   \n","3  [{'review': 'In this paper a well known soft m...       None   \n","4  [{'review': 'The method proposes to compress t...       None   \n","\n","                name                                           metadata  \n","0  ICLR_2017_381.pdf  {'source': 'CRF', 'title': 'MULTI-TASK LEARNIN...  \n","1  ICLR_2017_211.pdf  {'source': 'CRF', 'title': 'NONPARAMETRICALLY ...  \n","2  ICLR_2017_200.pdf  {'source': 'CRF', 'title': 'DISCOVERING OBJECT...  \n","3  ICLR_2017_106.pdf  {'source': 'CRF', 'title': 'TRANSFER FROM MULT...  \n","4   ICLR_2017_64.pdf  {'source': 'CRF', 'title': None, 'authors': ['...  "],"text/html":["\n","  <div id=\"df-0b6c244a-171b-456f-b09c-8345a9d76250\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>conference</th>\n","      <th>decision</th>\n","      <th>url</th>\n","      <th>hasContent</th>\n","      <th>hasReview</th>\n","      <th>title</th>\n","      <th>authors</th>\n","      <th>reviews</th>\n","      <th>metaReview</th>\n","      <th>name</th>\n","      <th>metadata</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ICLR_2017_381</td>\n","      <td>ICLR</td>\n","      <td>Reject</td>\n","      <td>http://openreview.net/pdf/63b92f7ce8708e9df35d...</td>\n","      <td>true</td>\n","      <td>true</td>\n","      <td>Multi-task learning with deep model based rein...</td>\n","      <td>[Asier Mujika]</td>\n","      <td>[{'review': 'The term strategy is a bit ambigu...</td>\n","      <td>None</td>\n","      <td>ICLR_2017_381.pdf</td>\n","      <td>{'source': 'CRF', 'title': 'MULTI-TASK LEARNIN...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ICLR_2017_211</td>\n","      <td>ICLR</td>\n","      <td>Invite to Workshop Track</td>\n","      <td>http://openreview.net/pdf/5c54afd2ea867c72b8ae...</td>\n","      <td>true</td>\n","      <td>true</td>\n","      <td>Nonparametrically Learning Activation Function...</td>\n","      <td>[Carson Eisenach, Zhaoran Wang, Han Liu]</td>\n","      <td>[{'review': 'This paper provides a principled ...</td>\n","      <td>None</td>\n","      <td>ICLR_2017_211.pdf</td>\n","      <td>{'source': 'CRF', 'title': 'NONPARAMETRICALLY ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ICLR_2017_200</td>\n","      <td>ICLR</td>\n","      <td>Invite to Workshop Track</td>\n","      <td>http://openreview.net/pdf/e2d348d16ad96d19425e...</td>\n","      <td>true</td>\n","      <td>true</td>\n","      <td>Discovering objects and their relations from e...</td>\n","      <td>[David Raposo, Adam Santoro, David Barrett, Ra...</td>\n","      <td>[{'review': '+ Understanding relations between...</td>\n","      <td>None</td>\n","      <td>ICLR_2017_200.pdf</td>\n","      <td>{'source': 'CRF', 'title': 'DISCOVERING OBJECT...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ICLR_2017_106</td>\n","      <td>ICLR</td>\n","      <td>Accept (Poster)</td>\n","      <td>http://openreview.net/pdf/5ab63afda67c68cd39a6...</td>\n","      <td>true</td>\n","      <td>true</td>\n","      <td>Attend, Adapt and Transfer: Attentive Deep Arc...</td>\n","      <td>[Janarthanan Rajendran, Aravind Lakshminarayan...</td>\n","      <td>[{'review': 'In this paper a well known soft m...</td>\n","      <td>None</td>\n","      <td>ICLR_2017_106.pdf</td>\n","      <td>{'source': 'CRF', 'title': 'TRANSFER FROM MULT...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ICLR_2017_64</td>\n","      <td>ICLR</td>\n","      <td>Accept (Poster)</td>\n","      <td>http://openreview.net/pdf/2cb01001f2f89ca11252...</td>\n","      <td>true</td>\n","      <td>true</td>\n","      <td>Training Compressed Fully-Connected Networks w...</td>\n","      <td>[Shengjie Wang, Haoran Cai, Jeff Bilmes, Willi...</td>\n","      <td>[{'review': 'The method proposes to compress t...</td>\n","      <td>None</td>\n","      <td>ICLR_2017_64.pdf</td>\n","      <td>{'source': 'CRF', 'title': None, 'authors': ['...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b6c244a-171b-456f-b09c-8345a9d76250')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0b6c244a-171b-456f-b09c-8345a9d76250 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0b6c244a-171b-456f-b09c-8345a9d76250');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-625c4ee3-2a53-4fce-b1f1-13dc475288e3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-625c4ee3-2a53-4fce-b1f1-13dc475288e3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-625c4ee3-2a53-4fce-b1f1-13dc475288e3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 8614,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8512,\n        \"samples\": [\n          \"ICLR_2020_1164\",\n          \"ICLR_2019_1318\",\n          \"NIPS_2019_406\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conference\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NIPS\",\n          \"ICLR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Reject\",\n          \"Invite to Workshop Track\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8512,\n        \"samples\": [\n          \"http://openreview.net/pdf/f23689c16196b0d87398092eb7e60a137ad7275e.pdf\",\n          \"http://openreview.net/pdf/d2729e43481122474e30b5cb4ce4bc7bf837556d.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hasContent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"false\",\n          \"true\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hasReview\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"true\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8485,\n        \"samples\": [\n          \"Rethinking the Hyperparameters for Fine-tuning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviews\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metaReview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5859,\n        \"samples\": [\n          \"The authors propose to use identity + some weights in the recurrent connections to prevent vanishing gradients. The reviewers found the experiments to have weak baselines, weakening the claims of the paper.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8512,\n        \"samples\": [\n          \"ICLR_2020_1164.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["has_none_string = data['metadata'].apply(lambda x: x == \"None\").any()\n","print(has_none_string)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jccAe9odmZke","executionInfo":{"status":"ok","timestamp":1724657606475,"user_tz":-60,"elapsed":554,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"ffba7161-35e9-4d30-ee40-7238cd8a853c"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"code","source":["data['metadata'].iloc[5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0UDQXpvmtOR","executionInfo":{"status":"ok","timestamp":1724657642415,"user_tz":-60,"elapsed":650,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"375e28e5-a85d-4550-83a2-77aab24eedc0"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'source': 'CRF',\n"," 'title': 'Transfer Learning with Neural AutoML',\n"," 'authors': ['Catherine Wong', 'Neil Houlsby', 'Yifeng Lu'],\n"," 'emails': ['catwong@mit.edu',\n","  'neilhoulsby@google.com',\n","  'yifenglu@google.com',\n","  'agesmundo@google.com'],\n"," 'sections': [{'heading': None,\n","   'text': 'We reduce the computational cost of Neural AutoML with transfer learning. AutoML relieves human effort by automating the design of ML algorithms. Neural AutoML has become popular for the design of deep learning architectures, however, this method has a high computation cost. To address this we propose Transfer Neural AutoML that uses knowledge from prior tasks to speed up network design. We extend RL-based architecture search methods to support parallel training on multiple tasks and then transfer the search strategy to new tasks. On language and image classification tasks, Transfer Neural AutoML reduces convergence time over single-task training by over an order of magnitude on many tasks.'},\n","  {'heading': '1 Introduction',\n","   'text': 'Automatic Machine Learning (AutoML) aims to find the best performing learning algorithms with minimal human intervention. Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8]. We focus on neural AutoML, that uses deep RL to optimize architectures. These methods have shown promising results. For example, Neural Architecture Search has discovered novel networks that rival the best human-designed architectures on challenging image classification tasks [9, 10].\\nHowever, neural AutoML is expensive because it requires training many networks. This may require vast computations resources; Zoph and Le [8] report 800 concurrent GPUs to train on Cifar-10. Further, training needs to be repeated for every new task. Some methods have been proposed to address this cost, such as using a progressive search space [11], or by sharing weights among generated networks [12, 13]. We propose a complementary solution, applicable when one has multiple ML tasks to solve. Humans can tune networks based on knowledge gained from prior tasks. We aim to leverage the same information using transfer learning.\\nWe exploit the fact that deep RL-based AutoML algorithms learn an explicit parameterization of the distribution over performant models. We present Transfer Neural AutoML, a method to accelerate network design on new tasks based on priors learned on previous tasks. To do this we design a network that performs neural AutoML on multiple tasks simultaneously. Our method for multitask neural AutoML learns both hyperparameter choices common to multiple tasks and specific choices for individual tasks. We then transfer this controller to new tasks and leverage the learned priors over performant models. We reduce the time to converge in both text and image domains by over an order of magnitude in most tasks. In our experiments we save 10s of CPU hours for every task that we transfer to. 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montréal, Canada.'},\n","  {'heading': '2 Methods', 'text': ''},\n","  {'heading': '2.1 Neural Architecture Search',\n","   'text': 'Transfer Neural AutoML is based on Neural Architecture Search (NAS) [8]. NAS uses deep RL to generate models that maximize performance on a given task. The framework consists of two components: a controller model and child models.\\nThe controller is an RNN that generates a sequence of discrete actions. Each action specifies a design choice; for example, if the child models are CNNs, these choices could include the filter heights, widths, and strides. The controller is an autoregressive model, like a language model: the action taken at each time step is fed into the RNN as input for the next time step. The recurrent state of the RNN maintains a history of the design choices taken so far. The use of an RNN allows dependencies between the design choices to be learned. The sequence of design choices define a child model that is trained and evaluated on the ML task at hand. The performance of the child network on the validation set is used as a reward to update the controller via a policy gradient algorithm.'},\n","  {'heading': '2.2 Multitask Training',\n","   'text': 'We propose Multitask Neural AutoML, that searches for model on multiple tasks simultaneously. It requires defining a generic search space that is shared across tasks. Many deep learning models require the same common design decisions, such as choice of network depth, learning rate, and number of training iterations. By defining a generic search space that contains common architecture and hyperparameter choices, the controller can generate a wide range of models applicable to many common problems. Multitask training allows the controller to learn a broadly applicable prior over the search space by observing shared behaviour across tasks. The proposed multitask controller has two key features: learned task representations, and advantage normalization.\\nLearned task representations The multitask AutoML controller characterizes the tasks by learning a unique embedding vector for each task. This task-embedding allows to condition model generation on the task ID. The task-embeddings are analogous to word-embeddings commonly used for NLP, where each word is associated to a trainable vector [14].\\nFigure 1 (left) shows the architecture of the multitask controller at each time step. The task embedding is fed into the RNN at every time step. In standard single-task training of NAS, only the embedding of the previous action is fed into the RNN. In multitask training, the task embedding is concatenated to the action embedding. We also add a skip connection across the RNN cell to ease the learning of action marginal distributions. The task embeddings are the only task-specific parameters. One embedding is assigned to each task; these are randomly initialized and trained jointly with the controller.\\nAt each iteration of multitask training, a task is sampled at random. This task’s embedding is fed to the controller, which generates a sequence of actions conditioned on this embedding. The child model defined by these actions is trained and evaluated on the task, and the reward is used to update the task-agnostic parameters and the corresponding task embedding.\\nTask-specific advantage normalization We train the controller using policy gradient. Each task defines a different performance metric which we use as reward. The reward affects the amplitude of the gradients applied to update the controller’s policy, π . To maintain a balanced gradient updates across tasks, we ensure that the distribution of each task’s rewards are scaled to have same mean and variance.\\nThe mean of each task’s reward distribution is centered on zero by subtracting the expected reward for the given task. The centered reward, or advantage, Aτ (m), of a model, m, applied to a task, τ , is defined as the difference between the reward obtained by the model, Rτ (m), and the expected reward for the given task, bτ = Em∼π[Rτ (m)]: Aτ (m) = Rτ (m) − bτ . bτ . Subtracting such a baseline is a standard technique in policy gradient algorithms used to reduce the variance of the parameter updates [15].\\nThe variance of each task’s reward distribution is normalized by dividing the advantage by the standard deviation of the reward: A′τ (m) = (Rτ (m)− bτ )σ−1τ . Where στ = √ Em∼π[(Rτ (m)− bτ )2]. We\\nRNN Cell\\nFFNN\\nState\\nTask embedding\\nPrev. action\\nPrev. state\\nSample action\\nAction distribution\\nFFNN\\nTask\\nAction embedding\\nC o m\\np la\\nin ts\\nN e w\\ns A\\ng g re\\ng a to\\nr\\nA ir\\nlin e\\nP ri\\nm a ry\\nE m\\no ti\\no n\\nE co\\nn o m\\nic N\\ne w\\ns\\nP o lit\\nic a l M\\ne ss\\na g e\\nS e n ti\\nm e n t\\nS S T\\nU S E\\nco n o m\\ny\\nComplaints\\nNews Aggregator\\nAirline\\nPrimary Emotion\\nEconomic News\\nPolitical Message\\nSentiment SST\\nUS Economy 0.8\\n0.4\\n0.0\\n0.4\\n0.8\\nFigure 1: Left:A single time step of the recurrent multitask AutoML controller, in which a single action is taken. The task embedding is concatenated with the embedding of the action sampled at the previous timestep and passed into the controller RNN. All parameters, other than the task embeddings, are shared across tasks. Right: Cosine similarity between the task embeddings learned by the multitask neural AutoML model.\\nrefer to A′ as the normalized advantage. The gradient update to the parameters of the policy θ is the product of the advantage and expected derivative of the log probability of sampling an action: A′τ (m)Eπ[∇θ log πθ(m)]. Thus, normalizing the advantage may also be seen as adapting the learning rate for each task.\\nIn practice, we compute bτ and στ using exponential moving averages over the sequence of rewards: btτ = (1− α)bt−1τ + αRτ (m), σ2,tτ = (1− α)σ2,t−1τ + α(Rτ (m)− btτ )2, where t indexes the trial, and α = 0.01 is the decay factor.'},\n","  {'heading': '2.3 Transfer Learning',\n","   'text': 'The multitask controller is pretrained on a set of tasks and learns a prior over generic architectural and parameter choices, along with task-specific decisions encoded in the task embeddings. Given a new task, we can perform transfer of the controller by: 1) reloading the parameters of the pretrained multitask controller, 2) adding a new randomly initialized task embedding for the new task. Then, architecture search is resumed, and the controller’s parameters are updated jointly with the new task embedding. By learning an embedding for the new task, the controller learns a representation that biases towards actions that performed well on similar tasks.'},\n","  {'heading': '3 Related Work',\n","   'text': 'A variety of optimization methods have been proposed to search over architectures, hyperparameters, and learning algorithms. These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19]. An emerging body of neuro-evolution research has adapted genetic algorithms for these complex optimization problems [20], including to set the parameters of existing deep networks [21], evolve image classifiers [5], and evolve generic deep neural networks [6].\\nOur work relates closest to NAS [8]. NAS was applied to construct CNNs for the CIFAR-10 image classification and RNNs for the Penn Treebank language modelling. Subsequent work reduces the computational cost for more challenging tasks [10]. To engineer an architecture for ImageNet classification, Zoph et al. [10] train the NAS controller on the simpler CIFAR-10 task and then transfer the child architecture to ImageNet by stacking it. However, they did not transfer the controller model itself, relying instead on the intuition that additional depth is necessary for the more challenging task. Other works apply RL to automate architecture generation and also reduce the computation cost. MetaQNN sequentially chooses CNN layers using Q-learning [22]. MetaQNN uses an aggressive exploration to reduce search time, though it can cause the resulting architectures to underperform.\\nCai et al. [23] transform existing architectures incrementally to avoid generating entire networks from scratch. Liu et al. [11] reduce search time by progressively increasing architecture complexity, and [12] propose child-model weight sharing to reduce child training time.\\nTransfer learning has achieved excellent results as an initialization method for deep networks, including for models trained using RL [24, 25, 26]. Recent meta-learning research has broadened this concept to learn generalizable representations across classes of tasks [27, 28]. Simultaneous multitask training can facilitate learning between tasks with a common structure, though retaining knowledge effectively across tasks is still an active area of research [29, 30]. There is also prior research on transfer of optimizers for Neural AutoML; Sequential Model-based Optimizers have been transferred across tasks to improve hyperparameter tuning [31, 32], we propose a parallel solution for neural methods.'},\n","  {'heading': '4 Experiments',\n","   'text': 'Child models Constructing the search space needs human input, so we choose wide parameter ranges to minimize injected domain expertise. Our search space for child models contains two-tower feedforward neural networks (FFNN), similar to the wide and deep models in Cheng et al. [33]. One tower is a deep FFNN, containing an input embedding module, fully connected layers and a softmax classification layer. This tower is regularized with an L2 loss. The other is a wide-shallow layer that directly connects the one-hot token encodings to the softmax classification layer with a linear projection. This tower is regularized with a sparse L1 loss. The wide layer allows the model to learn task-specific biases for each token directly. The deep FFNN’s embedding modules are pretrained1.This results in child models with higher quality and faster convergence.\\nThe single search space for all tasks is defined by the following sequence of choices: 1) Pretrained embedding module. 2) Whether to fine-tune the embedding module. 3) Number of hidden layers (HL). 4) HL size. 5) HL activation function. 6) HL normalization scheme to use. 7) HL dropout rate. 8) Deep column learning rate. 9) Deep column regularization weight. 10) Wide layer learning rate. 11) Wide layer regularization weight. 12) Training steps. The Appendix contains the exact specification. The search space is much larger than the number of possible trials, containing 1.1B configurations. All models are trained using Proximal Adagrad with batch size 100. Notice that this search space aims to optimize jointly the architecture and hyperparameters. While standard NAS search spaces are defined strictly over architectural parameters.\\nController models The controller is a 2-layer LSTM with 50 units. The action and task embeddings have size 25. The controller and embedding weights are initialized uniformly at random, yielding an approximate uniform initial distribution over actions. The learning rate is set to 10−4 and it receives gradient updates after every child completes. We tried four variants of policy gradient to train the controller: REINFORCE [34], TRPO [35], UREX [36] and PPO [37]. In preliminary experiments on four NLP tasks, we found REINFORCE and TRPO to perform best and selected REINFORCE for the following experiments.\\nWe evaluate three controllers. First, Transfer Neural AutoML, our neural controller that transfers from multitask pre-training. Second, Single-task AutoML, which is trained from scratch on each task. Finally, a baseline, Random Search (RS), that selects action uniformly at random.\\nMetrics To measure the ability of the different AutoML controllers to find good models, we compute the average accuracy of the topN (accuracy-topN) child models generated during the search. We select the best topN models according to accuracy on the validation set. We then report the validation and test performance of these models.\\nWe assess convergence rates with two metrics: 1) accuracy-topN achieved with a fixed budget of trials, 2) the number of trials required to attain a certain reward. The latter can only be used with validation accuracy-topN since test accuracy-topN does not necessarily increase monotonically with the number of trials.\\n1The pretrained modules are distributed via TensorFlow Hub: https://www.tensorflow.org/hub .'},\n","  {'heading': '4.1 Natural Language Processing',\n","   'text': 'Data We evaluate using 21 text classification tasks with varied statistics. The dataset sizes range from 500 to 420k datapoints. The number of classes range from 2 to 157, and the mean length of the texts, in characters, range from 19 to 20k. The Appendix contains full statistics and references.\\nEach child model is trained on the training set. The accuracy on the validation set is used as reward for the controller. The topN child models, selected on the validation set, are evaluated on the test set. Datasets without a pre-defined train/validation/test split, are split randomly 80/10/10.\\nThe multitask controller is pretrained on 8 randomly sampled tasks: Airline, Complaints, Economic News, News Aggregator, Political Message, Primary Emotion, Sentiment SST, US Economy. We then transfer from this controller to each of the remaining 13 tasks.\\nResults To assess the controllers’ ability to optimize the reward (validation set accuracy) we compute the speed-up versus the baseline, RS. We first compute accuracy-top10 on the validation set for RS given a fixed budget of B trials. We use B = 5000, except for the Brown Corpus and 20 Newsgroups where we can only use a B = 500, 3500, respectively, because these datasets were slower to train. We then report the number of trials required by AutoML and T-AutoML to achieve the same validation accuracy-top10 as RS with B trials. Table 1 (left) shows the results. Note that RS may exhibit fewer than B = 5000 trials if it converged earlier. These results shows that T-AutoML is effective at optimizing validation accuracy, offering a large reduction in time to attain a fixed reward. In 12 of the 13 datasets T-AutoML achieves the desired reward fastest, and in 9 cases achieves an order of magnitude speed-up.\\nNext, we assess the quality of the models on the test set. Table 1 (right) shows test accuracy-top10 with a budget of 500 trials (250 for Brown Corpus). Within this budget, T-AutoML performs best on all but one dataset. T-AutoML outperforms single-task AutoML on 10 out of the 13 datasets, ties on one, and loses on two. On the datasets where T-AutoML does not produce the best final model at 500 trials, it often produces better models at earlier iterations. Figure 2 shows the full learning curves of test set accuracy-top10 versus number of trials. Figure 2 shows that in most cases the controller with transfer starts with a much better prior over good models. On some datasets the quality is improved with further training e.g. Emotion, Corp Messaging, but in others the initial configurations learned from the multitask model are not improved.\\nFor reference, we put the learning curves for the initial multitask training phase in the Appendix. We also ran RS and single-task AutoML on these datasets. Slightly disappointingly, multitask training\\ndid not in itself yield substantial improvements over single-task; it attains a higher accuracy on two datasets, and in similar on the other six.\\nWe aim to to attain good performance with fewest possible trials. We do not seek to beat state-of-theart all datasets because first, although our search space is large, it does not contain all performant model components (e.g. convolutions). Second, we use embedding modules pretrained on large datasets which makes the results incomparable to those that only uses in-domain training data.\\nHowever, to confirm that Neural AutoML generates good models we compare to some previous published results where available. Overall we find that Transfer AutoML with the search space described above yields models competitive with the state-of-the-art. For example, Almeida et al. [38] use classical ML classifiers (Logistic Regression, SVMs, etc.) on SMS Spam and report best accuracy of 97.59%. Transfer AutoML gets accuracy-top10 of 98.1%. Le and Mikolov [39] report 92.58% accuracy on Sentiment IMDB with more complex architectures, Transfer AutoML’s is a little behind, accuracy top-10 is 88.1%. Li et al. [40] report 86.8% accuracy using an ensemble of weighted neural BOWs on MPQA. Transfer AutoML achieve accuracy-top10 of 88.6%. Li et al. [40] also evaluate their ensemble of weighted neural BOW models on Customer Reviews, and achieve 82.5% best accuracy, though the best accuracy of any single model is 81.1%. Comparably, T-AutoML gets an accuracy-top10 of 81.4%. Barnes et al. [41] compare many algorithms and report best accuracy on Sentiment-SST of 83.1% using LSTMs. Multitask AutoML gets an accuracy-Top10 of 83.4%. The best performance achieved with a more complex architecture that is not in our search space is: 87.8% [39]. Maas et al. [42] report 88.1% on Movie Subj, Transfer AutoML gets accuracy-top10 of 93.4%.\\nComputational Cost and Savings The median cost to perform a single trial across all 21 datasets in our experiments is T = 268s. If we run B trials with a speedup factor of S, we save BT (1 − S−1)/3600CPU-h per task to attain a fixed reward (validation accuracy-top10). Estimating the speedup factors from Table 1 (left) for transfer over single-task, we attain a median computational saving of 30CPU-h per task when performing B = 500 trials. The mean is 89CPU-h, but this is heavily influenced by the slow Brown Corpus. The time to train the multitask controller is 15h on\\n100 CPUs. If we do not need the M models for the tasks used to train the multitask controller, then we must run > (1 − 1/S)−1M new tasks to amortize this cost. For the median speedup in our experiments S = 22 that is > 1.05M new tasks.'},\n","  {'heading': '4.2 Image classification',\n","   'text': 'To validate the generality of our approach we evaluate on image classification task: Cifar-10. We compare the same three controllers: RS, AutoML trained from scratch, and Transfer AutoML pretrained on MNIST and Flowers2. Figure 3 shows the mean accuracy-top-10 on the test set. The transferred controller attains an accuracy-top-10 of 96.5%, similar to the other methods, but converges much faster as in the NLP tasks. The best models embed images with a finetuned Inception v3 network, pretrained on ImageNet. Relu activations are preferred over Swish [43] and the dropout rate of converges to 0.3.'},\n","  {'heading': '4.3 Analysis',\n","   'text': 'Meta overfitting The controller is trained on the tasks’ validation sets. Overfitting of AutoML to the validation set is not often addressed. This type of overfitting may seem unlikely because each trial is expensive, and many trials may be required to overfit. However, we observe it in some cases.\\nFigure 4 (left, center) shows the accuracy-top10 on the validation and test sets on the Prog Opinion dataset. Transfer Neural AutoML attains good solutions in the first few trials, but afterwards its validation performance grows while test performance does not. The generalization gap between the validation and test accuracy increases over time. This is the most extreme case we observed, but some other datasets exhibit some generalization gap also (see Appendix for all validation curves). This effect is largest on Prog Opinion because the validation set is tiny, with only 116 examples.\\nOverfitting arises from bias due to selecting the best models on the validation set. Child evaluation contains randomness due to the stochastic training procedure. Therefore, over time we see an improved validation score, even after convergence, due to lucky evaluations. However, those apparent improvements are not reflected on the test set. Transfer AutoML exhibits more overfitting than single-task because it converges earlier. We confirmed this effect; if we ‘cheat’ and select models by their test-set performance, we observe the same artificial improvement on the test score as on the validation score. Other than entropy regularization, we do not combat overfitting extensively. Here, we simply emphasize that because our Transfer Neural AutoML model observes many trials in total, meta-overfitting becomes a bigger issue. We leave combatting this effect to future research.\\nDistant transfer: across languages The more distant the tasks, the harder it is to perform transfer learning. The Sentiment Cine task is an outlier because it is the only Spanish task. Figure 2 and Table 1 show poorer performance of transfer on this task.\\nThe most language-sensitive parameters are the pretrained word embeddings. The controller selects from eight pretrained embeddings (see Appendix), six of which are English, and two Spanish. In the first 1500 iterations, the transferred controller chooses English embeddings, limiting the performance. However, after further training, the controller switches to Spanish tables at around 2000th trial, Figure 4 (right). At trial 2000, T-AutoML attains a test accuracy-top10 of 79.8%, approximately equal to that or random search with 79.4%, and greater than single-task with 78.1%. This indicates that although transfer works best on similar tasks, the controller is still able to adapt to outliers given sufficient training time.\\n2goo.gl/tpzfR1\\nTask representations and learned models We inspect the learned task similarities via the embeddings. Figure 1 (right) shows the cosine similarity between the task embeddings learned during multitask training. The model assigns most tasks to two clusters. It is hard to guess a priori which tasks require similar models; the dataset sizes, number of classes and text lengths differ greatly. However, the controller assigns the same model to tasks within the same cluster. At convergence, the cluster {Complaints, New Agg, Airline, Primary Emotion} is assigned (with high probability) a 1-layer networks with 256 units, Swish activation function, wide-layer learning rate 0.01, and dropout rate 0.2. The cluster {Economic News, Political Emotion, Sentiment SST} is assigned 2-layer networks with 64 units, Relu activation, wide-layer learning rate 0.003, and dropout rate 0.3.\\nOther choices follow similar distributions for each cluster. For example, the same 128D word embeddings, trained using a Neural Language Model are chosen. The controller also always chooses to fine-tune these embeddings. The controller may remove either the deep or wide tower by setting the regularization very high, but in all cases it chooses to keep both active.\\nAblation We consider two ablations of T-NAML. First, we remove the task embeddings. For this, we train a task-agnostic multitask controller without task embeddings, then transfer this controller as for T-NAML. Second, we transfer a single architecture rather than the controller parameters. For this, we train the task-agnostic multitask controller to convergence, and select the final child model. We then re-train this single architecture on each new task. Omitting task embeddings performs well on some tasks, but poorly on those that require a model different to the mode. Overall, according to accuracy-top10 at 500 trials, T-NAML outperforms the version without task embeddings on 8 tasks, loses 4, and draws on 1. The mean performance drop when ablating task embeddings is 1.8%. Using just a single model performs very poorly on many tasks, T-NAML wins 8 cases, loses 2, and draws 3, with a mean performance increase of 4.8%.'},\n","  {'heading': '5 Conclusion',\n","   'text': 'Neural AutoML, whilst becoming popular, comes with a high computational cost. To address this we propose transfer learning of the controller and show a large reductions in convergence time across many datasets. Extensions to this work include: Broadening the search space to contain more models classes. Attempting transfer across modalities; some priors over hyperparameter combinations learned on NLP tasks may be useful for images or other domains. Making the controller more robust to evaluation noise, and addressing the potential to meta overfit on small datasets.'},\n","  {'heading': 'Acknowledgments',\n","   'text': 'We are very grateful to Quentin de Laroussilhe, Andrey Khorlin, Quoc Le, Sylvain Gelly, the Tensorflow Hub team and the Google Brain team Zurich for developing software frameworks and many useful discussions.'}],\n"," 'references': [{'title': 'Random search for hyper-parameter optimization',\n","   'author': ['James Bergstra', 'Yoshua Bengio'],\n","   'venue': None,\n","   'citeRegEx': '1',\n","   'shortCiteRegEx': '1',\n","   'year': 2012},\n","  {'title': 'Algorithms for hyper-parameter optimization',\n","   'author': ['James S Bergstra',\n","    'Rémi Bardenet',\n","    'Yoshua Bengio',\n","    'Balázs Kégl'],\n","   'venue': 'In NIPS,',\n","   'citeRegEx': '2',\n","   'shortCiteRegEx': '2',\n","   'year': 2011},\n","  {'title': 'Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures',\n","   'author': ['James Bergstra', 'Daniel Yamins', 'David Cox'],\n","   'venue': 'In ICML,',\n","   'citeRegEx': '3',\n","   'shortCiteRegEx': '3',\n","   'year': 2013},\n","  {'title': 'Practical bayesian optimization of machine learning algorithms',\n","   'author': ['Jasper Snoek', 'Hugo Larochelle', 'Ryan P Adams'],\n","   'venue': 'In NIPS,',\n","   'citeRegEx': '4',\n","   'shortCiteRegEx': '4',\n","   'year': 2012},\n","  {'title': 'Large-scale evolution of image classifiers',\n","   'author': ['Esteban Real',\n","    'Sherry Moore',\n","    'Andrew Selle',\n","    'Saurabh Saxena',\n","    'Yutaka Leon Suematsu',\n","    'Quoc Le',\n","    'Alex Kurakin'],\n","   'venue': None,\n","   'citeRegEx': '5',\n","   'shortCiteRegEx': '5',\n","   'year': 2017},\n","  {'title': 'Designing neural network architectures using reinforcement learning',\n","   'author': ['Bowen Baker', 'Otkrist Gupta', 'Nikhil Naik', 'Ramesh Raskar'],\n","   'venue': 'In ICLR,',\n","   'citeRegEx': '7',\n","   'shortCiteRegEx': '7',\n","   'year': 2017},\n","  {'title': 'Neural architecture search with reinforcement learning',\n","   'author': ['Barret Zoph', 'Quoc V. Le'],\n","   'venue': 'In ICLR,',\n","   'citeRegEx': '8',\n","   'shortCiteRegEx': '8',\n","   'year': 2017},\n","  {'title': 'Practical network blocks design with q-learning',\n","   'author': ['Zhao Zhong', 'Junjie Yan', 'Cheng-Lin Liu'],\n","   'venue': 'In AAAI,',\n","   'citeRegEx': '9',\n","   'shortCiteRegEx': '9',\n","   'year': 2018},\n","  {'title': 'Learning transferable architectures for scalable image recognition',\n","   'author': ['Barret Zoph',\n","    'Vijay Vasudevan',\n","    'Jonathon Shlens',\n","    'Quoc V. Le'],\n","   'venue': None,\n","   'citeRegEx': '10',\n","   'shortCiteRegEx': '10',\n","   'year': 2017},\n","  {'title': 'Progressive neural architecture search',\n","   'author': ['Chenxi Liu',\n","    'Barret Zoph',\n","    'Jonathon Shlens',\n","    'Wei Hua',\n","    'Li-Jia Li',\n","    'Li Fei-Fei',\n","    'Alan Yuille',\n","    'Jonathan Huang',\n","    'Kevin Murphy'],\n","   'venue': 'arXiv preprint arXiv:1712.00559,',\n","   'citeRegEx': '11',\n","   'shortCiteRegEx': '11',\n","   'year': 2017},\n","  {'title': 'Efficient neural architecture search via parameter sharing',\n","   'author': ['Hieu Pham',\n","    'Melody Y Guan',\n","    'Barret Zoph',\n","    'Quoc V Le',\n","    'Jeff Dean'],\n","   'venue': 'arXiv preprint arXiv:1802.03268,',\n","   'citeRegEx': '12',\n","   'shortCiteRegEx': '12',\n","   'year': 2018},\n","  {'title': 'Darts: Differentiable architecture search',\n","   'author': ['Hanxiao Liu', 'Karen Simonyan', 'Yiming Yang'],\n","   'venue': 'arXiv preprint arXiv:1806.09055,',\n","   'citeRegEx': '13',\n","   'shortCiteRegEx': '13',\n","   'year': 2018},\n","  {'title': 'Distributed representations of words and phrases and their compositionality',\n","   'author': ['Tomas Mikolov',\n","    'Ilya Sutskever',\n","    'Kai Chen',\n","    'Greg S Corrado',\n","    'Jeff Dean'],\n","   'venue': 'In NIPS,',\n","   'citeRegEx': '14',\n","   'shortCiteRegEx': '14',\n","   'year': 2013},\n","  {'title': 'Variance reduction techniques for gradient estimates in reinforcement learning',\n","   'author': ['Evan Greensmith', 'Peter L Bartlett', 'Jonathan Baxter'],\n","   'venue': None,\n","   'citeRegEx': '15',\n","   'shortCiteRegEx': '15',\n","   'year': 2004},\n","  {'title': 'Initializing bayesian hyperparameter optimization via meta-learning',\n","   'author': ['Matthias Feurer', 'Jost Tobias Springenberg', 'Frank Hutter'],\n","   'venue': 'In AAAI,',\n","   'citeRegEx': '16',\n","   'shortCiteRegEx': '16',\n","   'year': 2015},\n","  {'title': 'Deeparchitect: Automatically designing and training deep architectures',\n","   'author': ['Renato Negrinho', 'Geoff Gordon'],\n","   'venue': 'arXiv preprint arXiv:1704.08792,',\n","   'citeRegEx': '17',\n","   'shortCiteRegEx': '17',\n","   'year': 2017},\n","  {'title': 'Learned optimizers that scale and generalize',\n","   'author': ['Olga Wichrowska',\n","    'Niru Maheswaranathan',\n","    'Matthew W Hoffman',\n","    'Sergio Gomez Colmenarejo',\n","    'Misha Denil',\n","    'Nando de Freitas',\n","    'Jascha Sohl-Dickstein'],\n","   'venue': 'arXiv preprint arXiv:1703.04813,',\n","   'citeRegEx': '18',\n","   'shortCiteRegEx': '18',\n","   'year': 2017},\n","  {'title': 'Neural optimizer search with reinforcement learning',\n","   'author': ['Irwan Bello', 'Barret Zoph', 'Vijay Vasudevan', 'Quoc V. Le'],\n","   'venue': 'In ICML,',\n","   'citeRegEx': '19',\n","   'shortCiteRegEx': '19',\n","   'year': 2017},\n","  {'title': 'Improving exploration in evolution strategies for deep reinforcement learning via a population of novelty-seeking agents',\n","   'author': ['Edoardo Conti',\n","    'Vashisht Madhavan',\n","    'Felipe Petroski Such',\n","    'Joel Lehman',\n","    'Kenneth O Stanley',\n","    'Jeff Clune'],\n","   'venue': 'arXiv preprint arXiv:1712.06560,',\n","   'citeRegEx': '20',\n","   'shortCiteRegEx': '20',\n","   'year': 2017},\n","  {'title': 'Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning',\n","   'author': ['Felipe Petroski Such',\n","    'Vashisht Madhavan',\n","    'Edoardo Conti',\n","    'Joel Lehman',\n","    'Kenneth O Stanley',\n","    'Jeff Clune'],\n","   'venue': 'arXiv preprint arXiv:1712.06567,',\n","   'citeRegEx': '21',\n","   'shortCiteRegEx': '21',\n","   'year': 2017},\n","  {'title': 'Designing neural network architectures using reinforcement learning',\n","   'author': ['Bowen Baker', 'Otkrist Gupta', 'Nikhil Naik', 'Ramesh Raskar'],\n","   'venue': 'arXiv preprint arXiv:1611.02167,',\n","   'citeRegEx': '22',\n","   'shortCiteRegEx': '22',\n","   'year': 2016},\n","  {'title': 'Reinforcement learning for architecture search by network transformation',\n","   'author': ['Han Cai',\n","    'Tianyao Chen',\n","    'Weinan Zhang',\n","    'Yong Yu',\n","    'Jun Wang'],\n","   'venue': 'arXiv preprint arXiv:1707.04873,',\n","   'citeRegEx': '23',\n","   'shortCiteRegEx': '23',\n","   'year': 2017},\n","  {'title': 'How transferable are features in deep neural networks',\n","   'author': ['Jason Yosinski', 'Jeff Clune', 'Yoshua Bengio', 'Hod Lipson'],\n","   'venue': 'In NIPS,',\n","   'citeRegEx': '24',\n","   'shortCiteRegEx': '24',\n","   'year': 2014},\n","  {'title': 'Cnn features off-the-shelf: an astounding baseline for recognition',\n","   'author': ['Ali Sharif Razavian',\n","    'Hossein Azizpour',\n","    'Josephine Sullivan',\n","    'Stefan Carlsson'],\n","   'venue': 'In CVPR workshops,',\n","   'citeRegEx': '25',\n","   'shortCiteRegEx': '25',\n","   'year': 2014},\n","  {'title': 'Online transfer learning in reinforcement learning domains',\n","   'author': ['Yusen Zhan', 'Matthew E Taylor'],\n","   'venue': 'arXiv preprint arXiv:1507.00436,',\n","   'citeRegEx': '26',\n","   'shortCiteRegEx': '26',\n","   'year': 2015},\n","  {'title': 'Model-agnostic meta-learning for fast adaptation of deep networks',\n","   'author': ['Chelsea Finn', 'Pieter Abbeel', 'Sergey Levine'],\n","   'venue': None,\n","   'citeRegEx': '27',\n","   'shortCiteRegEx': '27',\n","   'year': 2017},\n","  {'title': 'A simple neural attentive meta-learner',\n","   'author': ['Nikhil Mishra',\n","    'Mostafa Rohaninejad',\n","    'Xi Chen',\n","    'Pieter Abbeel'],\n","   'venue': 'In NIPS 2017 Workshop on Meta-Learning,',\n","   'citeRegEx': '28',\n","   'shortCiteRegEx': '28',\n","   'year': 2017},\n","  {'title': 'Overcoming catastrophic forgetting in neural networks',\n","   'author': ['James Kirkpatrick',\n","    'Razvan Pascanu',\n","    'Neil Rabinowitz',\n","    'Joel Veness',\n","    'Guillaume Desjardins',\n","    'Andrei A Rusu',\n","    'Kieran Milan',\n","    'John Quan',\n","    'Tiago Ramalho',\n","    'Agnieszka Grabska-Barwinska'],\n","   'venue': None,\n","   'citeRegEx': '29',\n","   'shortCiteRegEx': '29',\n","   'year': 2017},\n","  {'title': 'Distral: Robust multitask reinforcement learning',\n","   'author': ['Yee Whye Teh',\n","    'Victor Bapst',\n","    'Wojciech Marian Czarnecki',\n","    'John Quan',\n","    'James Kirkpatrick',\n","    'Raia Hadsell',\n","    'Nicolas Heess',\n","    'Razvan Pascanu'],\n","   'venue': 'arXiv preprint arXiv:1707.04175,',\n","   'citeRegEx': '30',\n","   'shortCiteRegEx': '30',\n","   'year': 2017},\n","  {'title': 'Collaborative hyperparameter tuning',\n","   'author': ['Rémi Bardenet',\n","    'Mátyás Brendel',\n","    'Balázs Kégl',\n","    'Michele Sebag'],\n","   'venue': 'In ICML,',\n","   'citeRegEx': '31',\n","   'shortCiteRegEx': '31',\n","   'year': 2013},\n","  {'title': 'Efficient transfer learning method for automatic hyperparameter tuning',\n","   'author': ['Dani Yogatama', 'Gideon Mann'],\n","   'venue': 'In AISTATS,',\n","   'citeRegEx': '32',\n","   'shortCiteRegEx': '32',\n","   'year': 2014},\n","  {'title': 'Simple statistical gradient-following algorithms for connectionist reinforcement learning',\n","   'author': ['Ronald J Williams'],\n","   'venue': 'In Reinforcement Learning. Springer,',\n","   'citeRegEx': '34',\n","   'shortCiteRegEx': '34',\n","   'year': 1992},\n","  {'title': 'Trust region policy optimization',\n","   'author': ['John Schulman',\n","    'Sergey Levine',\n","    'Pieter Abbeel',\n","    'Michael Jordan',\n","    'Philipp Moritz'],\n","   'venue': 'In ICML,',\n","   'citeRegEx': '35',\n","   'shortCiteRegEx': '35',\n","   'year': 2015},\n","  {'title': 'Improving policy gradient by exploring under-appreciated rewards',\n","   'author': ['Ofir Nachum', 'Mohammad Norouzi', 'Dale Schuurmans'],\n","   'venue': 'In ICLR,',\n","   'citeRegEx': '36',\n","   'shortCiteRegEx': '36',\n","   'year': 2017},\n","  {'title': 'Proximal policy optimization algorithms',\n","   'author': ['John Schulman',\n","    'Filip Wolski',\n","    'Prafulla Dhariwal',\n","    'Alec Radford',\n","    'Oleg Klimov'],\n","   'venue': 'arXiv preprint arXiv:1707.06347,',\n","   'citeRegEx': '37',\n","   'shortCiteRegEx': '37',\n","   'year': 2017},\n","  {'title': 'Towards sms spam filtering: Results under a new dataset',\n","   'author': ['Tiago Almeida',\n","    'José María Gómez Hidalgo',\n","    'Tiago Pasqualini Silva'],\n","   'venue': 'International Journal of Information Security Science,',\n","   'citeRegEx': '38',\n","   'shortCiteRegEx': '38',\n","   'year': 2013},\n","  {'title': 'Distributed representations of sentences and documents',\n","   'author': ['Quoc Le', 'Tomas Mikolov'],\n","   'venue': 'In ICML,',\n","   'citeRegEx': '39',\n","   'shortCiteRegEx': '39',\n","   'year': 2014},\n","  {'title': 'Weighted neural bag-of-n-grams model: New baselines for text classification',\n","   'author': ['Bofang Li', 'Zhe Zhao', 'Tao Liu', 'Puwei Wang', 'Xiaoyong Du'],\n","   'venue': None,\n","   'citeRegEx': '40',\n","   'shortCiteRegEx': '40',\n","   'year': 2016},\n","  {'title': 'Assessing state-of-the-art sentiment models on state-of-the-art sentiment datasets',\n","   'author': ['Jeremy Barnes', 'Roman Klinger', 'Sabine Schulte im Walde'],\n","   'venue': 'In Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis',\n","   'citeRegEx': '41',\n","   'shortCiteRegEx': '41',\n","   'year': 2017},\n","  {'title': 'Learning word vectors for sentiment analysis',\n","   'author': ['Andrew L. Maas',\n","    'Raymond E. Daly',\n","    'Peter T. Pham',\n","    'Dan Huang',\n","    'Andrew Y. Ng',\n","    'Christopher Potts'],\n","   'venue': 'In ACL: Human Language Technologies. ACL,',\n","   'citeRegEx': '42',\n","   'shortCiteRegEx': '42',\n","   'year': 2011},\n","  {'title': 'Swish: a self-gated activation function',\n","   'author': ['Prajit Ramachandran', 'Barret Zoph', 'Quoc V Le'],\n","   'venue': 'arXiv preprint arXiv:1710.05941,',\n","   'citeRegEx': '43',\n","   'shortCiteRegEx': '43',\n","   'year': 2017}],\n"," 'referenceMentions': [{'referenceID': 0,\n","   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n","   'startOffset': 51,\n","   'endOffset': 54},\n","  {'referenceID': 1,\n","   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n","   'startOffset': 78,\n","   'endOffset': 84},\n","  {'referenceID': 2,\n","   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n","   'startOffset': 78,\n","   'endOffset': 84},\n","  {'referenceID': 3,\n","   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n","   'startOffset': 108,\n","   'endOffset': 111},\n","  {'referenceID': 4,\n","   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n","   'startOffset': 132,\n","   'endOffset': 138},\n","  {'referenceID': 5,\n","   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n","   'startOffset': 146,\n","   'endOffset': 152},\n","  {'referenceID': 6,\n","   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n","   'startOffset': 146,\n","   'endOffset': 152},\n","  {'referenceID': 7,\n","   'context': 'For example, Neural Architecture Search has discovered novel networks that rival the best human-designed architectures on challenging image classification tasks [9, 10].',\n","   'startOffset': 161,\n","   'endOffset': 168},\n","  {'referenceID': 8,\n","   'context': 'For example, Neural Architecture Search has discovered novel networks that rival the best human-designed architectures on challenging image classification tasks [9, 10].',\n","   'startOffset': 161,\n","   'endOffset': 168},\n","  {'referenceID': 6,\n","   'context': 'This may require vast computations resources; Zoph and Le [8] report 800 concurrent GPUs to train on Cifar-10.',\n","   'startOffset': 58,\n","   'endOffset': 61},\n","  {'referenceID': 9,\n","   'context': 'Some methods have been proposed to address this cost, such as using a progressive search space [11], or by sharing weights among generated networks [12, 13].',\n","   'startOffset': 95,\n","   'endOffset': 99},\n","  {'referenceID': 10,\n","   'context': 'Some methods have been proposed to address this cost, such as using a progressive search space [11], or by sharing weights among generated networks [12, 13].',\n","   'startOffset': 148,\n","   'endOffset': 156},\n","  {'referenceID': 11,\n","   'context': 'Some methods have been proposed to address this cost, such as using a progressive search space [11], or by sharing weights among generated networks [12, 13].',\n","   'startOffset': 148,\n","   'endOffset': 156},\n","  {'referenceID': 6,\n","   'context': 'Transfer Neural AutoML is based on Neural Architecture Search (NAS) [8].',\n","   'startOffset': 68,\n","   'endOffset': 71},\n","  {'referenceID': 12,\n","   'context': 'The task-embeddings are analogous to word-embeddings commonly used for NLP, where each word is associated to a trainable vector [14].',\n","   'startOffset': 128,\n","   'endOffset': 132},\n","  {'referenceID': 13,\n","   'context': 'Subtracting such a baseline is a standard technique in policy gradient algorithms used to reduce the variance of the parameter updates [15].',\n","   'startOffset': 135,\n","   'endOffset': 139},\n","  {'referenceID': 0,\n","   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n","   'startOffset': 28,\n","   'endOffset': 31},\n","  {'referenceID': 2,\n","   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n","   'startOffset': 52,\n","   'endOffset': 55},\n","  {'referenceID': 14,\n","   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n","   'startOffset': 99,\n","   'endOffset': 103},\n","  {'referenceID': 15,\n","   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n","   'startOffset': 186,\n","   'endOffset': 190},\n","  {'referenceID': 16,\n","   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n","   'startOffset': 236,\n","   'endOffset': 244},\n","  {'referenceID': 17,\n","   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n","   'startOffset': 236,\n","   'endOffset': 244},\n","  {'referenceID': 18,\n","   'context': 'An emerging body of neuro-evolution research has adapted genetic algorithms for these complex optimization problems [20], including to set the parameters of existing deep networks [21], evolve image classifiers [5], and evolve generic deep neural networks [6].',\n","   'startOffset': 116,\n","   'endOffset': 120},\n","  {'referenceID': 19,\n","   'context': 'An emerging body of neuro-evolution research has adapted genetic algorithms for these complex optimization problems [20], including to set the parameters of existing deep networks [21], evolve image classifiers [5], and evolve generic deep neural networks [6].',\n","   'startOffset': 180,\n","   'endOffset': 184},\n","  {'referenceID': 4,\n","   'context': 'An emerging body of neuro-evolution research has adapted genetic algorithms for these complex optimization problems [20], including to set the parameters of existing deep networks [21], evolve image classifiers [5], and evolve generic deep neural networks [6].',\n","   'startOffset': 211,\n","   'endOffset': 214},\n","  {'referenceID': 8,\n","   'context': 'Subsequent work reduces the computational cost for more challenging tasks [10].',\n","   'startOffset': 74,\n","   'endOffset': 78},\n","  {'referenceID': 8,\n","   'context': '[10] train the NAS controller on the simpler CIFAR-10 task and then transfer the child architecture to ImageNet by stacking it.',\n","   'startOffset': 0,\n","   'endOffset': 4},\n","  {'referenceID': 20,\n","   'context': 'MetaQNN sequentially chooses CNN layers using Q-learning [22].',\n","   'startOffset': 57,\n","   'endOffset': 61},\n","  {'referenceID': 21,\n","   'context': '[23] transform existing architectures incrementally to avoid generating entire networks from scratch.',\n","   'startOffset': 0,\n","   'endOffset': 4},\n","  {'referenceID': 9,\n","   'context': '[11] reduce search time by progressively increasing architecture complexity, and [12] propose child-model weight sharing to reduce child training time.',\n","   'startOffset': 0,\n","   'endOffset': 4},\n","  {'referenceID': 10,\n","   'context': '[11] reduce search time by progressively increasing architecture complexity, and [12] propose child-model weight sharing to reduce child training time.',\n","   'startOffset': 81,\n","   'endOffset': 85},\n","  {'referenceID': 22,\n","   'context': 'Transfer learning has achieved excellent results as an initialization method for deep networks, including for models trained using RL [24, 25, 26].',\n","   'startOffset': 134,\n","   'endOffset': 146},\n","  {'referenceID': 23,\n","   'context': 'Transfer learning has achieved excellent results as an initialization method for deep networks, including for models trained using RL [24, 25, 26].',\n","   'startOffset': 134,\n","   'endOffset': 146},\n","  {'referenceID': 24,\n","   'context': 'Transfer learning has achieved excellent results as an initialization method for deep networks, including for models trained using RL [24, 25, 26].',\n","   'startOffset': 134,\n","   'endOffset': 146},\n","  {'referenceID': 25,\n","   'context': 'Recent meta-learning research has broadened this concept to learn generalizable representations across classes of tasks [27, 28].',\n","   'startOffset': 120,\n","   'endOffset': 128},\n","  {'referenceID': 26,\n","   'context': 'Recent meta-learning research has broadened this concept to learn generalizable representations across classes of tasks [27, 28].',\n","   'startOffset': 120,\n","   'endOffset': 128},\n","  {'referenceID': 27,\n","   'context': 'Simultaneous multitask training can facilitate learning between tasks with a common structure, though retaining knowledge effectively across tasks is still an active area of research [29, 30].',\n","   'startOffset': 183,\n","   'endOffset': 191},\n","  {'referenceID': 28,\n","   'context': 'Simultaneous multitask training can facilitate learning between tasks with a common structure, though retaining knowledge effectively across tasks is still an active area of research [29, 30].',\n","   'startOffset': 183,\n","   'endOffset': 191},\n","  {'referenceID': 29,\n","   'context': 'There is also prior research on transfer of optimizers for Neural AutoML; Sequential Model-based Optimizers have been transferred across tasks to improve hyperparameter tuning [31, 32], we propose a parallel solution for neural methods.',\n","   'startOffset': 176,\n","   'endOffset': 184},\n","  {'referenceID': 30,\n","   'context': 'There is also prior research on transfer of optimizers for Neural AutoML; Sequential Model-based Optimizers have been transferred across tasks to improve hyperparameter tuning [31, 32], we propose a parallel solution for neural methods.',\n","   'startOffset': 176,\n","   'endOffset': 184},\n","  {'referenceID': 31,\n","   'context': 'We tried four variants of policy gradient to train the controller: REINFORCE [34], TRPO [35], UREX [36] and PPO [37].',\n","   'startOffset': 77,\n","   'endOffset': 81},\n","  {'referenceID': 32,\n","   'context': 'We tried four variants of policy gradient to train the controller: REINFORCE [34], TRPO [35], UREX [36] and PPO [37].',\n","   'startOffset': 88,\n","   'endOffset': 92},\n","  {'referenceID': 33,\n","   'context': 'We tried four variants of policy gradient to train the controller: REINFORCE [34], TRPO [35], UREX [36] and PPO [37].',\n","   'startOffset': 99,\n","   'endOffset': 103},\n","  {'referenceID': 34,\n","   'context': 'We tried four variants of policy gradient to train the controller: REINFORCE [34], TRPO [35], UREX [36] and PPO [37].',\n","   'startOffset': 112,\n","   'endOffset': 116},\n","  {'referenceID': 35,\n","   'context': '[38] use classical ML classifiers (Logistic Regression, SVMs, etc.',\n","   'startOffset': 0,\n","   'endOffset': 4},\n","  {'referenceID': 37,\n","   'context': '[40] also evaluate their ensemble of weighted neural BOW models on Customer Reviews, and achieve 82.',\n","   'startOffset': 0,\n","   'endOffset': 4},\n","  {'referenceID': 38,\n","   'context': '[41] compare many algorithms and report best accuracy on Sentiment-SST of 83.',\n","   'startOffset': 0,\n","   'endOffset': 4},\n","  {'referenceID': 40,\n","   'context': 'Relu activations are preferred over Swish [43] and the dropout rate of converges to 0.',\n","   'startOffset': 42,\n","   'endOffset': 46}],\n"," 'year': 2018,\n"," 'abstractText': 'We reduce the computational cost of Neural AutoML with transfer learning. AutoML relieves human effort by automating the design of ML algorithms. Neural AutoML has become popular for the design of deep learning architectures, however, this method has a high computation cost. To address this we propose Transfer Neural AutoML that uses knowledge from prior tasks to speed up network design. We extend RL-based architecture search methods to support parallel training on multiple tasks and then transfer the search strategy to new tasks. On language and image classification tasks, Transfer Neural AutoML reduces convergence time over single-task training by over an order of magnitude on many tasks.',\n"," 'creator': 'LaTeX with hyperref package'}"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["data.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"c5fDf-cJmIwy","executionInfo":{"status":"ok","timestamp":1724657481435,"user_tz":-60,"elapsed":652,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"ba41a89d-b0e1-4f67-fb8e-7fa25a47ef18"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id             0\n","conference     0\n","decision       0\n","url            0\n","hasContent     0\n","hasReview      0\n","title          0\n","authors        0\n","reviews        0\n","metaReview    24\n","name           0\n","metadata       0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>id</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>conference</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>decision</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>url</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hasContent</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>hasReview</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>title</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>authors</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>reviews</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>metaReview</th>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>name</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>metadata</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["\n","!pip install datasets\n","import nltk\n","nltk.download('punkt')\n","!pip install torch transformers bert-score\n","!pip install tqdm\n","!pip install rouge_score\n","!pip install sentence_transformers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Br_dEMJMMAlp","executionInfo":{"status":"ok","timestamp":1724778850480,"user_tz":-60,"elapsed":35940,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"32fa8fe8-3002-439e-9d8a-dc20c594dc76"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.1.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n","Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.42.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.4.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.3.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","from tqdm import tqdm\n","from typing import List, Dict\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import re\n","import bert_score\n","from bert_score import score\n","\n","def clean_text(text):\n","    if text is None:\n","        return \"\"\n","    text = text.lower()\n","    text = re.sub(r'\\s+', ' ', text)\n","    return text.strip()\n","\n","def extract_introduction(metadata):\n","    \"\"\"Extracting the introduction section if available. If not, returns None.\"\"\"\n","    if metadata is not None and isinstance(metadata, dict):\n","        sections = metadata.get('sections', [])\n","        for section in sections:\n","            if section and section.get('heading'):  # Ensure section and heading are valid\n","                heading = section.get('heading', '').lower()\n","                if 'introduction' in heading:  # Look for \"introduction\"\n","                    text = section.get('text', '')\n","                    return clean_text(text) if text else None  # Return cleaned introduction text\n","    return None  # Return None if no valid introduction found\n","\n","\n","\n","# TF-IDF based sentence extraction\n","class TFIDFBaselineExtractor:\n","    def __init__(self):\n","        self.vectorizer = TfidfVectorizer(stop_words='english')\n","\n","    def extract_salient_sentences(self, text: str, num_sentences: int = 3) -> str:\n","        if not text:\n","            return ''\n","\n","        sentences = self._split_into_sentences(text)\n","        if len(sentences) <= num_sentences:\n","            return \" \".join(sentences)\n","\n","        tfidf_matrix = self.vectorizer.fit_transform(sentences)\n","        sentence_scores = np.sum(tfidf_matrix.toarray(), axis=1)\n","        top_sentence_indices = sentence_scores.argsort()[-num_sentences:][::-1]\n","\n","        return \" \".join([sentences[i] for i in sorted(top_sentence_indices)])\n","\n","    def _split_into_sentences(self, text: str) -> list:\n","        return [s.strip() for s in text.split('.') if s.strip()]\n","\n","\n","\n","\n"],"metadata":{"id":"DcXZpN1c0Rl8","executionInfo":{"status":"ok","timestamp":1724778850481,"user_tz":-60,"elapsed":11,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["extract_introduction(data['metadata'].iloc[5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"re3_Km71nIpv","executionInfo":{"status":"ok","timestamp":1724657995946,"user_tz":-60,"elapsed":438,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"884fe75a-872a-41d2-facd-6ead1f7e55a2"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'automatic machine learning (automl) aims to find the best performing learning algorithms with minimal human intervention. many automl methods exist, including random search [1], performance modelling [2, 3], bayesian optimization [4], genetic algorithms [5, 6] and rl [7, 8]. we focus on neural automl, that uses deep rl to optimize architectures. these methods have shown promising results. for example, neural architecture search has discovered novel networks that rival the best human-designed architectures on challenging image classification tasks [9, 10]. however, neural automl is expensive because it requires training many networks. this may require vast computations resources; zoph and le [8] report 800 concurrent gpus to train on cifar-10. further, training needs to be repeated for every new task. some methods have been proposed to address this cost, such as using a progressive search space [11], or by sharing weights among generated networks [12, 13]. we propose a complementary solution, applicable when one has multiple ml tasks to solve. humans can tune networks based on knowledge gained from prior tasks. we aim to leverage the same information using transfer learning. we exploit the fact that deep rl-based automl algorithms learn an explicit parameterization of the distribution over performant models. we present transfer neural automl, a method to accelerate network design on new tasks based on priors learned on previous tasks. to do this we design a network that performs neural automl on multiple tasks simultaneously. our method for multitask neural automl learns both hyperparameter choices common to multiple tasks and specific choices for individual tasks. we then transfer this controller to new tasks and leverage the learned priors over performant models. we reduce the time to converge in both text and image domains by over an order of magnitude in most tasks. in our experiments we save 10s of cpu hours for every task that we transfer to. 32nd conference on neural information processing systems (neurips 2018), montréal, canada.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# Generating review based on extracted introduction\n","def generate_review(metadata):\n","    introduction = extract_introduction(metadata)\n","    if introduction: # Check if introduction is not None\n","        extractor = TFIDFBaselineExtractor()\n","        return extractor.extract_salient_sentences(introduction, num_sentences=8)\n","    return ''  # Return empty if no introduction\n","\n","# Function to calculate BERTScore for evaluation\n","def calculate_bertscore(introduction, generated_review):\n","    \"\"\"\n","    This function calculates the BERTScore between the introduction and the generated review.\n","    \"\"\"\n","    if not introduction or not generated_review:\n","        return None, None, None\n","\n","    # Calculate BERTScore\n","    P, R, F1 = score([generated_review], [introduction], lang=\"en\", verbose=True)\n","\n","    return P.mean().item(), R.mean().item(), F1.mean().item()\n","\n","# Process the dataset\n","def process_dataset(data: pd.DataFrame):\n","    processed_data = []\n","\n","    # Iterate through the dataset rows\n","    for idx, row in tqdm(data.iterrows(), total=len(data)):\n","        metadata = row['metadata']\n","        try:\n","            generated_review = generate_review(metadata)\n","        except TypeError:  # Catch the TypeError that was causing the issue\n","            print(f\"Skipping row {idx} due to error.\")\n","            continue  # Move on to the next row\n","\n","        if generated_review:  # Proceed only if there's a generated review\n","            introduction = extract_introduction(metadata)\n","\n","\n","            processed_data.append({\n","                'paper_id': row['id'],\n","                'title': row.get('title', 'unknown'),\n","                'metadata': metadata,\n","                'generated_review': generated_review,\n","\n","            })\n","\n","    # Convert to DataFrame for easy saving/processing\n","    return pd.DataFrame(processed_data)\n","processed_data = process_dataset(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrwhlZMunGLn","executionInfo":{"status":"ok","timestamp":1724778916269,"user_tz":-60,"elapsed":65041,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"46ca9417-8225-4457-8a1d-f85df9044251"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":[" 93%|█████████▎| 8027/8614 [01:02<00:02, 236.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Skipping row 8000 due to error.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8614/8614 [01:05<00:00, 132.51it/s]\n"]}]},{"cell_type":"code","source":["# Save the processed data\n","processed_data.to_csv('generated_reviews-baseline.csv', index=False)\n","\n","# Example of how to access the first few results\n","print(processed_data.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYHvE9yS66Wn","executionInfo":{"status":"ok","timestamp":1724778967865,"user_tz":-60,"elapsed":51623,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"f513a51a-3a85-4071-ad4c-0971574b433e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["        paper_id                                              title  \\\n","0  ICLR_2017_381  Multi-task learning with deep model based rein...   \n","1  ICLR_2017_211  Nonparametrically Learning Activation Function...   \n","2  ICLR_2017_200  Discovering objects and their relations from e...   \n","3  ICLR_2017_106  Attend, Adapt and Transfer: Attentive Deep Arc...   \n","4   ICLR_2017_64  Training Compressed Fully-Connected Networks w...   \n","\n","                                            metadata  \\\n","0  {'source': 'CRF', 'title': 'MULTI-TASK LEARNIN...   \n","1  {'source': 'CRF', 'title': 'NONPARAMETRICALLY ...   \n","2  {'source': 'CRF', 'title': 'DISCOVERING OBJECT...   \n","3  {'source': 'CRF', 'title': 'TRANSFER FROM MULT...   \n","4  {'source': 'CRF', 'title': None, 'authors': ['...   \n","\n","                                    generated_review  \n","0  recently, there has been a lot of success in a...  \n","1  deep learning techniques have proven particula...  \n","2  for example, object relations enable the trans...  \n","3  transferring knowledge gained from tasks solve...  \n","4  deep neural networks have achieved great succe...  \n"]}]},{"cell_type":"code","source":["processed_data['generated_review'].iloc[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"-OSfE786nGFR","executionInfo":{"status":"ok","timestamp":1724664003373,"user_tz":-60,"elapsed":385,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"61f9c43c-85db-4637-96df-09607c5bb4e1"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'reinforcement learning (rl) is a field of research that uses dynamic programing (dp; bertsekas 2008), among other approaches, to solve sequential decision making problems the main challenge in applying dp to real world problems is an exponential growth of computational requirements as the problem size increases, known as the curse of dimensionality (bertsekas, 2008) popular function approximators for this task include deep neural networks, henceforth termed deep rl (drl), and linear architectures, henceforth termed shallow rl (srl) in particular, batch algorithms based on a least squares (ls) approach, such as least squares temporal difference (lstd, lagoudakis & parr 2003) and fitted-q iteration (fqi, ernst et al recent advancements in drl using convolutional neural networks demonstrated learning of expressive features (zahavy et al this motivates us to ask: can we combine drl with srl to leverage the benefits of both? in this work, we develop a hybrid approach that combines batch srl algorithms with online drl following this insight, we propose a method that repeatedly re-trains the last hidden layer of a drl network with a batch srl algorithm, using data collected throughout the drl run our experiments demonstrate that this hybrid approach significantly improves performance on the atari benchmark for several combinations of drl and srl methods'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["from bert_score import score\n","\n","\n","introduction = processed_data.iloc[1]['introduction']\n","generated_review = \" \".join(processed_data.iloc[1]['generated_review'])\n","\n","# Calculate BERTScore\n","P, R, F1 = score([generated_review], [introduction], lang=\"en\", verbose=True)\n","\n","# Print the results\n","print(f\"BERTScore Precision: {P.mean().item()}\")\n","print(f\"BERTScore Recall: {R.mean().item()}\")\n","print(f\"BERTScore F1: {F1.mean().item()}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257,"referenced_widgets":["70fced24c5a54e97be1fbcaec7c7fe8a","f495c49700514cd6b5e98caa3e7e9513","258ab3211f454d9eae4cac7f075082a0","a87e6b8f17db4114b71a0758a125bf5d","b74088f4a537478abe1b3dcad94ca482","c3ffd71f0d464be3b0ff44ebe973628b","9a68190ececf48c0b461059629f8a544","e14c389b62bd4467a13067497241b0fc","5a4dfc3134cc4588bc2f72bf908a70e3","68d09566f697493bb1aeb798742b37a2","af9a9ac63caa4a5199399288e42493b5","36d379cc69b74b72a2dc711c1536fa91","fd50c86224ae477ba9b2a041f5d4a802","27e8b02f637d467b9affc68aa0ac5c4d","14d15a5fbff44781885f92c36ebf732f","2f84908cd8074913b07d4e01c2dd6411","0b377dc8953049efbf36a049f20af57e","2a5f1091743542af97d10bcea23ac977","fab31dd0a5d74d8ca7948b79c277498c","d21d0d7b0d2142209d1c58efcfb1d26a","a8c461150a3a45bdab9332f34ac46779","775adffecb3c4d7e86ed04c5ab2d045b"]},"id":"MsPJ1L96i9Ox","executionInfo":{"status":"ok","timestamp":1724775207345,"user_tz":-60,"elapsed":2019,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"bcef457e-3d24-427a-c8f0-d369ff171979"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["calculating scores...\n","computing bert embedding.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70fced24c5a54e97be1fbcaec7c7fe8a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["computing greedy matching.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36d379cc69b74b72a2dc711c1536fa91"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["done in 0.26 seconds, 3.82 sentences/sec\n","BERTScore Precision: 0.6023514270782471\n","BERTScore Recall: 0.7386294603347778\n","BERTScore F1: 0.6635658144950867\n"]}]},{"cell_type":"code","source":["introduction = extract_introduction(processed_data.iloc[0]['metadata']) # Extract introduction from metadata\n","generated_review = \" \".join(processed_data.iloc[0]['generated_review'])\n","\n","# Calculate BERTScore\n","P, R, F1 = score([generated_review], [introduction], lang=\"en\", verbose=True)\n","\n","# Print the results\n","print(f\"BERTScore Precision: {P.mean().item()}\")\n","print(f\"BERTScore Recall: {R.mean().item()}\")\n","print(f\"BERTScore F1: {F1.mean().item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553,"referenced_widgets":["0c7934460eb64f489516442ea240dc5a","5267be041dc347e288fe45560d665473","4702d9248bc6477e86027a0a919ecf75","6e9e721e16cf45bfbe040976fb0b2454","ec9da83594e849be800300bb54a007c2","35045706f15f40bd95ab0affb58ed009","c887cb31ae654b7aa60a5f9680d0fdb9","3c8671034c484ba29531c704a2f3c312","84091a60f3da4a189a7e41adca6b471c","9af3aaeabf64435fa369a79715e50444","bf48660e6fd8499a9ffa9f0596a9b2fb","8c7251c4e2ff46fb8cd78980dc472f0c","0bb65857f4d244b1b09ef8f39b9617cb","56f4244fca0049218e42e686a4c63ae4","9361307afdfb4697966f17f563896336","1cf27b95120e4c8eac43528770db8593","812d5c4b9c204a9dbfff1685ce1bcba4","dc3e693ad23f4991aba6154fb19cfe56","f787179fc30f4b19a4e05513b2fcb1d1","325625482a894123888875ac14f22bba","2d6521a87bb94519af802689cba60f9f","b15e91b61f2245a59ad4cc56782f124f","5d5b71f37cdf4809ac595f795e36828c","5641369757eb4bb3a7e48e54a1b12d54","ed713c2bce5d40cd860a4743b91097b6","28770d730a10437fad24ee87ecab9c82","46bc3abece124cde92f10a210745fb1e","1436a61d2d6b4573bb3e48bdf5a42357","d2dc7ef847ac41289860d0029a949a1a","cf7a24b138ae492da60da194feff3459","a72f2320e1d74c42a8910e62e993b00c","52ab2de7c99843caaa9d47bc0090884e","e7d1b6dcf2bc4c2286591f7b6fbb2684","d1ff224f118e4769a96c9f4478b59d4d","1f8b0f24f79744338906c098fab6b562","39884050088742eebf0ba17790a8d5fd","cbdf6db4f81f4c83a68e256dd58dd2e5","90cf1e9c1f704941b5ea72ac4eacc055","893b83cfca764c93b94fd0b5624e2528","5db5fc3d45394b44b62d3ca1cf73449c","c83138f04c5e483983b755f7f537f4cf","c5f84710072640288cee0f164de07b13","19912aeef009413691854003e2709343","5c9b9218cdec4fe2a9bbc592ec8fb36a","d52c1e5cae6a41678bda6f3b84f2fe24","08a3b406c59547d6a2cb355deac2bcbd","c403833634c84729a1ace5192210ad72","0a5d63f801434dd189c48d4da67550dc","fc359521dbd5426d98b1f56996239bd2","0db1f5c7a7624641a499c772784bcaba","4fe2fb020b6546dbab7696b7a3003674","e08b8892ad3a4b87ba803e770e0e6456","886ba8b53a554778aef5e29371505ff3","9e72375e7c8446639bd73bc7962dccfc","04c4b4f703624def8d168dd581a4a892","0f90f653ef38415f8635bc0aa0524269","363ff0aa5abc421484f44d8056a3125f","0cf979c1ba994ec2beb955e81d8e5ec7","f55ffdf1a1244cda93459b54fe870afc","37e98f94c31247ccb4d6eaca6b230630","f636b9b2b9c84e8ca788a0c6290795df","17a8b14fdd4f40cf9b91e9f435f1bbcf","b3d5eccd011445108629e4016dfd8ad9","a4fc9ecf89a24a31b6187967a55be814","e3e77bf120e04673ab18a1f52f956014","bc7d4701bf0f4c3d8a1679bb32b6b56e","f4f18bbc3f864296a598888a986c1d97","a261d6bb848a4aa88848546a88856b3b","b89d03378a8a421d9052e74342560e60","d5e4ade75ef0464085da8378cdae6299","523937b7bdab477fa385762cf8b5e6a1","ebee22d7f39a43588a2b43f167209c41","f244b1ed872d4ee7b00bb1916ae922a7","d94001953be1409b8f0279a1e46d3097","63af27df613945df93f16c9e27045cb3","45ce41592a4241898225e5862aec07bc","3f789738af104506a2ad68171dba7c3d","18cecac2b19042849ac9f867c9b5b61c","2655399b44d8469a82f0b9511829baa7","519844e5030d42a0b09af18d2531c104","c151308281ce434497d0db6a9669da72","4148413c715e44ce8239e6ea06922b37","f56e70b6bb14449aa303963d405fdb6c","c68896965a784ca390fcf475c8d41e8e","0aaee3dfe07f4a4b8b4f53156e9b47b2","a28340861de844afabc80919d373c5dc","b59770fdcbeb4a5098152be453ee6054","9488291c7fc3412eafa2e0d2ba7fff62"]},"id":"ZSmGnVY92NgR","executionInfo":{"status":"ok","timestamp":1724779266251,"user_tz":-60,"elapsed":45325,"user":{"displayName":"Deepak Prajapati","userId":"17598353147510010387"}},"outputId":"efa6d437-44fd-4ea1-9831-29dcdce66400"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c7934460eb64f489516442ea240dc5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c7251c4e2ff46fb8cd78980dc472f0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d5b71f37cdf4809ac595f795e36828c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1ff224f118e4769a96c9f4478b59d4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d52c1e5cae6a41678bda6f3b84f2fe24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f90f653ef38415f8635bc0aa0524269"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["calculating scores...\n","computing bert embedding.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f18bbc3f864296a598888a986c1d97"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["computing greedy matching.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18cecac2b19042849ac9f867c9b5b61c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["done in 11.10 seconds, 0.09 sentences/sec\n","BERTScore Precision: 0.6273438930511475\n","BERTScore Recall: 0.7395058870315552\n","BERTScore F1: 0.678822934627533\n"]}]},{"cell_type":"markdown","source":["**This is a basic model which extracts information from Introduction ref bold text- Yuan, W., Liu, P. and Neubig, G., 2022. Can we automate scientific reviewing?**"],"metadata":{"id":"q0LoevE-1tMY"}},{"cell_type":"code","source":[],"metadata":{"id":"2ZOiZEig0Rbd"},"execution_count":null,"outputs":[]}]}