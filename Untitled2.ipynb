{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9719cb8ed07044ecb14b0160e36a43e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d74816b1e514103aaf21092fb0c4f17",
              "IPY_MODEL_d2be22cb459e44aea50a1e7916417a48",
              "IPY_MODEL_482b4c305cc44f59adbf60a96cf82667"
            ],
            "layout": "IPY_MODEL_829a28744c8c45bab588b0d962bc4aa3"
          }
        },
        "9d74816b1e514103aaf21092fb0c4f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aa533bf594d4bc5b4b585a1723489f6",
            "placeholder": "​",
            "style": "IPY_MODEL_fdc8fb671bfe498cb9e16f96076dd665",
            "value": "100%"
          }
        },
        "d2be22cb459e44aea50a1e7916417a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_816efb1e7ffa4eb29549b8557c5bca8c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ef595a72afe423686b66a480a3d29cc",
            "value": 1
          }
        },
        "482b4c305cc44f59adbf60a96cf82667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c07390c19895456a82e3bf29c85520a5",
            "placeholder": "​",
            "style": "IPY_MODEL_620d6ca3f12d4c769666b3a2cebaa90e",
            "value": " 1/1 [00:09&lt;00:00,  9.72s/it]"
          }
        },
        "829a28744c8c45bab588b0d962bc4aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aa533bf594d4bc5b4b585a1723489f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc8fb671bfe498cb9e16f96076dd665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "816efb1e7ffa4eb29549b8557c5bca8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef595a72afe423686b66a480a3d29cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c07390c19895456a82e3bf29c85520a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "620d6ca3f12d4c769666b3a2cebaa90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd24c904603d451e9987f322676f0805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5bc0c5ee35146bf9f478ee3088a1812",
              "IPY_MODEL_bd4019e1529d4ffea435491fb1960fd2",
              "IPY_MODEL_20acb52e80ac4ea2bf419bb73798ad40"
            ],
            "layout": "IPY_MODEL_cf1ac15d2bf44cf5ababafc9c8553e7f"
          }
        },
        "a5bc0c5ee35146bf9f478ee3088a1812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_091df882f9624db19663ff7291176020",
            "placeholder": "​",
            "style": "IPY_MODEL_3f8e38b9093248b9a60d42fc4e828f0f",
            "value": "100%"
          }
        },
        "bd4019e1529d4ffea435491fb1960fd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a8c8c48767b43c59a1de421c6019040",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cabd7e71cc594cb98a29c30894a667ab",
            "value": 1
          }
        },
        "20acb52e80ac4ea2bf419bb73798ad40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1786530cbc054459b227aea63071d943",
            "placeholder": "​",
            "style": "IPY_MODEL_07eae1b6bd3443ae94b27aec390a7cee",
            "value": " 1/1 [00:00&lt;00:00, 18.44it/s]"
          }
        },
        "cf1ac15d2bf44cf5ababafc9c8553e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "091df882f9624db19663ff7291176020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f8e38b9093248b9a60d42fc4e828f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a8c8c48767b43c59a1de421c6019040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cabd7e71cc594cb98a29c30894a667ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1786530cbc054459b227aea63071d943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07eae1b6bd3443ae94b27aec390a7cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c55e25aaa1148429ec7e527a9f9bb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d8a997c540e4beeaee6d0976c3a938d",
              "IPY_MODEL_244a55f22ace4dd2aa20772084b8af49",
              "IPY_MODEL_cc245850ec6d4959a811971611820367"
            ],
            "layout": "IPY_MODEL_d5de4be17281400a8954945afde5f5bf"
          }
        },
        "7d8a997c540e4beeaee6d0976c3a938d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7439b1a3ae4649678699b21004ec3dfe",
            "placeholder": "​",
            "style": "IPY_MODEL_37d06cdd898646b8af892e039f30e2e7",
            "value": "100%"
          }
        },
        "244a55f22ace4dd2aa20772084b8af49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aad42cf841b74867bcc3e8c3b77c2dc0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_180d495df33740629155f6cf51a5afd1",
            "value": 1
          }
        },
        "cc245850ec6d4959a811971611820367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8476f07b70943719fa701fa5f5075e9",
            "placeholder": "​",
            "style": "IPY_MODEL_3fd1d623fb0342f891b62465a26e9260",
            "value": " 1/1 [00:09&lt;00:00,  9.56s/it]"
          }
        },
        "d5de4be17281400a8954945afde5f5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7439b1a3ae4649678699b21004ec3dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d06cdd898646b8af892e039f30e2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aad42cf841b74867bcc3e8c3b77c2dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "180d495df33740629155f6cf51a5afd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8476f07b70943719fa701fa5f5075e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd1d623fb0342f891b62465a26e9260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "214f43c4748d43d1a6df5379eb474872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5135569001134cbfb5c488f7de44432c",
              "IPY_MODEL_c459214333064e98bae82f4614c55855",
              "IPY_MODEL_dc79c2c7920445a8acdd201033d2281b"
            ],
            "layout": "IPY_MODEL_299dbd4e02a1404fb9a63e592f63cf48"
          }
        },
        "5135569001134cbfb5c488f7de44432c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a7304b0e2d40318365893a56092cd1",
            "placeholder": "​",
            "style": "IPY_MODEL_fd94b372f92a45d9b52daeaccc9c63e5",
            "value": "100%"
          }
        },
        "c459214333064e98bae82f4614c55855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f8279766e6f49a58d6af41da6eaeae7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a63e375376184ded91010c2825992365",
            "value": 1
          }
        },
        "dc79c2c7920445a8acdd201033d2281b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0df84cb7aea45bc915b55826d212194",
            "placeholder": "​",
            "style": "IPY_MODEL_feed17b02ead4320816568b0e4171e3d",
            "value": " 1/1 [00:00&lt;00:00, 24.27it/s]"
          }
        },
        "299dbd4e02a1404fb9a63e592f63cf48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a7304b0e2d40318365893a56092cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd94b372f92a45d9b52daeaccc9c63e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f8279766e6f49a58d6af41da6eaeae7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63e375376184ded91010c2825992365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0df84cb7aea45bc915b55826d212194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feed17b02ead4320816568b0e4171e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "393ac9c4146b4960a95738b4d34aa05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b56620ce7f3497dacc828b048b73f89",
              "IPY_MODEL_f3304d2216cb45358595ce0a82e3909b",
              "IPY_MODEL_d9dedd3e911d4f8daa9252a33dd2158a"
            ],
            "layout": "IPY_MODEL_10932a95e19c461996780956f8630939"
          }
        },
        "8b56620ce7f3497dacc828b048b73f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3167002fbf84a518aa584ea61bbbee0",
            "placeholder": "​",
            "style": "IPY_MODEL_42b0e5a1d58244108e0c7aedd9ec04ca",
            "value": "100%"
          }
        },
        "f3304d2216cb45358595ce0a82e3909b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ef565883d24b9bbfcf88469f9c35d0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfe81befd9fa434baff33947f279ae0f",
            "value": 1
          }
        },
        "d9dedd3e911d4f8daa9252a33dd2158a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af6c496f1a3a45c8b34e877a64a8c07e",
            "placeholder": "​",
            "style": "IPY_MODEL_e83b5e9532984cc9997e70e1a932459d",
            "value": " 1/1 [00:11&lt;00:00, 11.08s/it]"
          }
        },
        "10932a95e19c461996780956f8630939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3167002fbf84a518aa584ea61bbbee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42b0e5a1d58244108e0c7aedd9ec04ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38ef565883d24b9bbfcf88469f9c35d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe81befd9fa434baff33947f279ae0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af6c496f1a3a45c8b34e877a64a8c07e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e83b5e9532984cc9997e70e1a932459d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97659cee00e74622beb4db2d8febe9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_375f650cc9ad4417a89b8b4fc11a6499",
              "IPY_MODEL_fa065d3b1a61496da5e2867d8f519395",
              "IPY_MODEL_78206f8d293e47eb85e69395a10cabe5"
            ],
            "layout": "IPY_MODEL_a0a3b6685aef45758474efdc867bed13"
          }
        },
        "375f650cc9ad4417a89b8b4fc11a6499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e81cf133aa24738886618e041539c7b",
            "placeholder": "​",
            "style": "IPY_MODEL_38cdc818925a4ad6a92ef538bd789647",
            "value": "100%"
          }
        },
        "fa065d3b1a61496da5e2867d8f519395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_125bd0ceb3884be5ba86f5c1b5bd4f2b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_288327c915814996b327acd9b2ea0e8f",
            "value": 1
          }
        },
        "78206f8d293e47eb85e69395a10cabe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_798934c46d9c4a85a37e0d1f8dddb172",
            "placeholder": "​",
            "style": "IPY_MODEL_753bdc41451241798311dcddc2bd6ed2",
            "value": " 1/1 [00:00&lt;00:00, 25.41it/s]"
          }
        },
        "a0a3b6685aef45758474efdc867bed13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e81cf133aa24738886618e041539c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38cdc818925a4ad6a92ef538bd789647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "125bd0ceb3884be5ba86f5c1b5bd4f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288327c915814996b327acd9b2ea0e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "798934c46d9c4a85a37e0d1f8dddb172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753bdc41451241798311dcddc2bd6ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15958307b4894f05a30cddadd734488a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cf6573bd74a4646a20b368563dee21f",
              "IPY_MODEL_b680e3bb97a14b1d9bc0f04f24c9da57",
              "IPY_MODEL_4ab1dca0fca645a095663cfdfcfd28c6"
            ],
            "layout": "IPY_MODEL_17e4cde492024be58b8bed0a97e4c365"
          }
        },
        "9cf6573bd74a4646a20b368563dee21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ad3223a8e3a49dd80562878688239e1",
            "placeholder": "​",
            "style": "IPY_MODEL_8c1f15b43bcf4899a33b6dc92340873c",
            "value": "100%"
          }
        },
        "b680e3bb97a14b1d9bc0f04f24c9da57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db12b93007d248109663c85ae3e26bd8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97f53cde218d4f6f94a09f6479790104",
            "value": 1
          }
        },
        "4ab1dca0fca645a095663cfdfcfd28c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d9bcfa0f9d74a6fa82d9bc14fc979b8",
            "placeholder": "​",
            "style": "IPY_MODEL_215e846cb78842a1b2e592a65752a3d1",
            "value": " 1/1 [00:11&lt;00:00, 11.06s/it]"
          }
        },
        "17e4cde492024be58b8bed0a97e4c365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ad3223a8e3a49dd80562878688239e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1f15b43bcf4899a33b6dc92340873c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db12b93007d248109663c85ae3e26bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f53cde218d4f6f94a09f6479790104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d9bcfa0f9d74a6fa82d9bc14fc979b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "215e846cb78842a1b2e592a65752a3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12f0c0ebf68244958f398ae54585f4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d7c0bef62994dc8bee9964eb68e4206",
              "IPY_MODEL_01e7882812724661bac8decc3d057342",
              "IPY_MODEL_91faa008f56a4e40b87b16483c40b247"
            ],
            "layout": "IPY_MODEL_a2045b6796fe4a9b8c769af674f71507"
          }
        },
        "2d7c0bef62994dc8bee9964eb68e4206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9555488f043540c38144486643955fbb",
            "placeholder": "​",
            "style": "IPY_MODEL_699c33ec96a54db496c3628f8499552e",
            "value": "100%"
          }
        },
        "01e7882812724661bac8decc3d057342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e80714bb08874a0ca3a1d32a9cf77702",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02655cf4edc54b2aa583fe291c97d219",
            "value": 1
          }
        },
        "91faa008f56a4e40b87b16483c40b247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e47f2263df647edaf977dc5159481ef",
            "placeholder": "​",
            "style": "IPY_MODEL_d2c75b388c734056a5e26fc2bcd37c45",
            "value": " 1/1 [00:00&lt;00:00, 21.67it/s]"
          }
        },
        "a2045b6796fe4a9b8c769af674f71507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9555488f043540c38144486643955fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "699c33ec96a54db496c3628f8499552e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e80714bb08874a0ca3a1d32a9cf77702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02655cf4edc54b2aa583fe291c97d219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e47f2263df647edaf977dc5159481ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2c75b388c734056a5e26fc2bcd37c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4111fe5e656a4aeca9578aa40934287a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_051edaa30df040d2ba77058a7a9e5896",
              "IPY_MODEL_bf8588329ebf4623a64e88174f3fdd0d",
              "IPY_MODEL_e3b053b460724cb38e5f9d2de0e9ad89"
            ],
            "layout": "IPY_MODEL_95d4798c2a004bf6ae37300e1fb5ac60"
          }
        },
        "051edaa30df040d2ba77058a7a9e5896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c1a629a5bd6484e8d7897bea6050679",
            "placeholder": "​",
            "style": "IPY_MODEL_89f3a5099fa046bcb07c7a2dfef2e707",
            "value": "100%"
          }
        },
        "bf8588329ebf4623a64e88174f3fdd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521134427e204015ba4854ae27bcdbee",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f14c113f82b5424db3a6769d8b5af711",
            "value": 1
          }
        },
        "e3b053b460724cb38e5f9d2de0e9ad89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c613e616e52a412cb12b75204c4bb719",
            "placeholder": "​",
            "style": "IPY_MODEL_4a956eb5660d4339857c1d0ce183267e",
            "value": " 1/1 [00:10&lt;00:00, 10.60s/it]"
          }
        },
        "95d4798c2a004bf6ae37300e1fb5ac60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c1a629a5bd6484e8d7897bea6050679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f3a5099fa046bcb07c7a2dfef2e707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521134427e204015ba4854ae27bcdbee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14c113f82b5424db3a6769d8b5af711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c613e616e52a412cb12b75204c4bb719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a956eb5660d4339857c1d0ce183267e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6950c4e78364148a4da59292b145f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d965b538ff484aae82530c87f606a127",
              "IPY_MODEL_00416faec7c84b05950e7d52a2d6cec3",
              "IPY_MODEL_8084a48832b241eb9670ca92d6d96f4a"
            ],
            "layout": "IPY_MODEL_243c48b86bbe42a0ae0c5ff7100e61fb"
          }
        },
        "d965b538ff484aae82530c87f606a127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a14f32c4e84b42ec8217e930f545adbf",
            "placeholder": "​",
            "style": "IPY_MODEL_529adaa591c845e999886b0db4632f08",
            "value": "100%"
          }
        },
        "00416faec7c84b05950e7d52a2d6cec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9607b48cb1c40b4ab17b6fdbf5f224f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f0e11f1c9ff4f88b2e01e5442aa00d4",
            "value": 1
          }
        },
        "8084a48832b241eb9670ca92d6d96f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_910bf26128fe4ebbbc141a94d9aba409",
            "placeholder": "​",
            "style": "IPY_MODEL_4093ba5893b64409bfb6efda17997d48",
            "value": " 1/1 [00:00&lt;00:00, 21.26it/s]"
          }
        },
        "243c48b86bbe42a0ae0c5ff7100e61fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a14f32c4e84b42ec8217e930f545adbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529adaa591c845e999886b0db4632f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9607b48cb1c40b4ab17b6fdbf5f224f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f0e11f1c9ff4f88b2e01e5442aa00d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "910bf26128fe4ebbbc141a94d9aba409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4093ba5893b64409bfb6efda17997d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kGAtfVFSGsQd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = pd.read_json('/content/drive/MyDrive/Dissertation_review/merged/final_data-review.json')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline model 1\n"
      ],
      "metadata": {
        "id": "Ndu138JLphsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(n=5, random_state=42)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "R9PcdwV12GsH",
        "outputId": "0449ac51-349d-44b8-b0d8-133c0d780d13"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  id conference            decision  \\\n",
              "1420    ICLR_2019_47       ICLR     Accept (Poster)   \n",
              "5910   NIPS_2017_300       NIPS              Accept   \n",
              "5156  ICLR_2020_1491       ICLR              Reject   \n",
              "3132  ICLR_2020_1571       ICLR              Reject   \n",
              "4055   ICLR_2020_585       ICLR  Accept (Spotlight)   \n",
              "\n",
              "                                                    url hasContent hasReview  \\\n",
              "1420  http://openreview.net/pdf/89825a97bda724af6db0...       true      true   \n",
              "5910  http://papers.nips.cc/paper/6906-shallow-updat...       true      true   \n",
              "5156  http://openreview.net/pdf/dc087b6bfae5b63d25cd...       true      true   \n",
              "3132  http://openreview.net/pdf/3b10bc68a8ccf2d2e991...       true      true   \n",
              "4055  http://openreview.net/pdf/42ef4a12b464ee694dcd...       true      true   \n",
              "\n",
              "                                                  title  \\\n",
              "1420  Woulda, Coulda, Shoulda: Counterfactually-Guid...   \n",
              "5910    Shallow Updates for Deep Reinforcement Learning   \n",
              "5156  CURSOR-BASED ADAPTIVE QUANTIZATION FOR DEEP NE...   \n",
              "3132  The Generalization-Stability Tradeoff in Neura...   \n",
              "4055             Real or Not Real, that is the Question   \n",
              "\n",
              "                                                authors  \\\n",
              "1420  [Lars Buesing, Theophane Weber, Yori Zwols, Ni...   \n",
              "5910  [Nir Levine, Tom Zahavy, Daniel J. Mankowitz, ...   \n",
              "5156  [Bapu Li(*), Yanwen Fan(*), Zhiyu Cheng, Yingz...   \n",
              "3132  [Brian R. Bartoldson, Ari S. Morcos, Adrian Ba...   \n",
              "4055  [Yuanbo Xiangli*, Yubin Deng*, Bo Dai*, Chen C...   \n",
              "\n",
              "                                                reviews  \\\n",
              "1420  [{'review': 'Summary:\n",
              "\n",
              "This paper proposes a p...   \n",
              "5910  [{'review': 'The paper proposes an add on to D...   \n",
              "5156  [{'review': 'The authors developed a novel qua...   \n",
              "3132  [{'review': 'This paper mainly studies the rel...   \n",
              "4055  [{'review': 'Update: I raised my score from 3 ...   \n",
              "\n",
              "                                             metaReview                name  \\\n",
              "1420                see my comment to the authors below    ICLR_2019_47.pdf   \n",
              "5910                                               None   NIPS_2017_300.pdf   \n",
              "5156  This paper presents a method to compress DNNs ...  ICLR_2020_1491.pdf   \n",
              "3132  The authors introduce a notion of stability to...  ICLR_2020_1571.pdf   \n",
              "4055  The paper proposes a novel GAN formulation whe...   ICLR_2020_585.pdf   \n",
              "\n",
              "                                               metadata  \n",
              "1420  {'source': 'CRF', 'title': None, 'authors': ['...  \n",
              "5910  {'source': 'META', 'title': 'Shallow Updates f...  \n",
              "5156  {'source': 'CRF', 'title': None, 'authors': []...  \n",
              "3132  {'source': 'CRF', 'title': 'THE GENERALIZATION...  \n",
              "4055  {'source': 'CRF', 'title': None, 'authors': ['...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec9e283b-289e-4825-9602-528e1215d2d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>conference</th>\n",
              "      <th>decision</th>\n",
              "      <th>url</th>\n",
              "      <th>hasContent</th>\n",
              "      <th>hasReview</th>\n",
              "      <th>title</th>\n",
              "      <th>authors</th>\n",
              "      <th>reviews</th>\n",
              "      <th>metaReview</th>\n",
              "      <th>name</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1420</th>\n",
              "      <td>ICLR_2019_47</td>\n",
              "      <td>ICLR</td>\n",
              "      <td>Accept (Poster)</td>\n",
              "      <td>http://openreview.net/pdf/89825a97bda724af6db0...</td>\n",
              "      <td>true</td>\n",
              "      <td>true</td>\n",
              "      <td>Woulda, Coulda, Shoulda: Counterfactually-Guid...</td>\n",
              "      <td>[Lars Buesing, Theophane Weber, Yori Zwols, Ni...</td>\n",
              "      <td>[{'review': 'Summary:\n",
              "\n",
              "This paper proposes a p...</td>\n",
              "      <td>see my comment to the authors below</td>\n",
              "      <td>ICLR_2019_47.pdf</td>\n",
              "      <td>{'source': 'CRF', 'title': None, 'authors': ['...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5910</th>\n",
              "      <td>NIPS_2017_300</td>\n",
              "      <td>NIPS</td>\n",
              "      <td>Accept</td>\n",
              "      <td>http://papers.nips.cc/paper/6906-shallow-updat...</td>\n",
              "      <td>true</td>\n",
              "      <td>true</td>\n",
              "      <td>Shallow Updates for Deep Reinforcement Learning</td>\n",
              "      <td>[Nir Levine, Tom Zahavy, Daniel J. Mankowitz, ...</td>\n",
              "      <td>[{'review': 'The paper proposes an add on to D...</td>\n",
              "      <td>None</td>\n",
              "      <td>NIPS_2017_300.pdf</td>\n",
              "      <td>{'source': 'META', 'title': 'Shallow Updates f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5156</th>\n",
              "      <td>ICLR_2020_1491</td>\n",
              "      <td>ICLR</td>\n",
              "      <td>Reject</td>\n",
              "      <td>http://openreview.net/pdf/dc087b6bfae5b63d25cd...</td>\n",
              "      <td>true</td>\n",
              "      <td>true</td>\n",
              "      <td>CURSOR-BASED ADAPTIVE QUANTIZATION FOR DEEP NE...</td>\n",
              "      <td>[Bapu Li(*), Yanwen Fan(*), Zhiyu Cheng, Yingz...</td>\n",
              "      <td>[{'review': 'The authors developed a novel qua...</td>\n",
              "      <td>This paper presents a method to compress DNNs ...</td>\n",
              "      <td>ICLR_2020_1491.pdf</td>\n",
              "      <td>{'source': 'CRF', 'title': None, 'authors': []...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3132</th>\n",
              "      <td>ICLR_2020_1571</td>\n",
              "      <td>ICLR</td>\n",
              "      <td>Reject</td>\n",
              "      <td>http://openreview.net/pdf/3b10bc68a8ccf2d2e991...</td>\n",
              "      <td>true</td>\n",
              "      <td>true</td>\n",
              "      <td>The Generalization-Stability Tradeoff in Neura...</td>\n",
              "      <td>[Brian R. Bartoldson, Ari S. Morcos, Adrian Ba...</td>\n",
              "      <td>[{'review': 'This paper mainly studies the rel...</td>\n",
              "      <td>The authors introduce a notion of stability to...</td>\n",
              "      <td>ICLR_2020_1571.pdf</td>\n",
              "      <td>{'source': 'CRF', 'title': 'THE GENERALIZATION...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4055</th>\n",
              "      <td>ICLR_2020_585</td>\n",
              "      <td>ICLR</td>\n",
              "      <td>Accept (Spotlight)</td>\n",
              "      <td>http://openreview.net/pdf/42ef4a12b464ee694dcd...</td>\n",
              "      <td>true</td>\n",
              "      <td>true</td>\n",
              "      <td>Real or Not Real, that is the Question</td>\n",
              "      <td>[Yuanbo Xiangli*, Yubin Deng*, Bo Dai*, Chen C...</td>\n",
              "      <td>[{'review': 'Update: I raised my score from 3 ...</td>\n",
              "      <td>The paper proposes a novel GAN formulation whe...</td>\n",
              "      <td>ICLR_2020_585.pdf</td>\n",
              "      <td>{'source': 'CRF', 'title': None, 'authors': ['...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec9e283b-289e-4825-9602-528e1215d2d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec9e283b-289e-4825-9602-528e1215d2d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec9e283b-289e-4825-9602-528e1215d2d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ee9ce88e-1ac8-4128-b989-77b1c2b160ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee9ce88e-1ac8-4128-b989-77b1c2b160ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ee9ce88e-1ac8-4128-b989-77b1c2b160ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"NIPS_2017_300\",\n          \"ICLR_2020_585\",\n          \"ICLR_2020_1491\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conference\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NIPS\",\n          \"ICLR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"decision\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Accept\",\n          \"Accept (Spotlight)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"http://papers.nips.cc/paper/6906-shallow-updates-for-deep-reinforcement-learning.pdf\",\n          \"http://openreview.net/pdf/42ef4a12b464ee694dcdcc0c7b25c618f8f014ea.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hasContent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"true\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hasReview\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"true\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Shallow Updates for Deep Reinforcement Learning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviews\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metaReview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"This paper presents a method to compress DNNs by quantization. The core idea is to use NAS techniques to adaptively set quantization bits at each layer. The proposed method is shown to achieved good results on the standard benchmarks. \\nThrough our final discussion, one reviewer agreed to raise the score from \\u2018Reject\\u2019 to \\u2018Weak Reject\\u2019,  but still on negative side. Another reviewer was not satisfied with the author\\u2019s rebuttal, particularly regarding the appropriateness of training strategy and evaluation. Moreover, as reviewers pointed out, there were so many unclear writings and explanations in the original manuscript. Although we admit that authors made great effort to address the comments, the revision seems too major and need to go through another complete peer reviewing. As there was no strong opinion to push this paper, I\\u2019d like to recommend rejection. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"NIPS_2017_300.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "has_none_string = data['metadata'].apply(lambda x: x == \"None\").any()\n",
        "print(has_none_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jccAe9odmZke",
        "outputId": "ffba7161-35e9-4d30-ee40-7238cd8a853c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['metadata'].iloc[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0UDQXpvmtOR",
        "outputId": "375e28e5-a85d-4550-83a2-77aab24eedc0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'CRF',\n",
              " 'title': 'Transfer Learning with Neural AutoML',\n",
              " 'authors': ['Catherine Wong', 'Neil Houlsby', 'Yifeng Lu'],\n",
              " 'emails': ['catwong@mit.edu',\n",
              "  'neilhoulsby@google.com',\n",
              "  'yifenglu@google.com',\n",
              "  'agesmundo@google.com'],\n",
              " 'sections': [{'heading': None,\n",
              "   'text': 'We reduce the computational cost of Neural AutoML with transfer learning. AutoML relieves human effort by automating the design of ML algorithms. Neural AutoML has become popular for the design of deep learning architectures, however, this method has a high computation cost. To address this we propose Transfer Neural AutoML that uses knowledge from prior tasks to speed up network design. We extend RL-based architecture search methods to support parallel training on multiple tasks and then transfer the search strategy to new tasks. On language and image classification tasks, Transfer Neural AutoML reduces convergence time over single-task training by over an order of magnitude on many tasks.'},\n",
              "  {'heading': '1 Introduction',\n",
              "   'text': 'Automatic Machine Learning (AutoML) aims to find the best performing learning algorithms with minimal human intervention. Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8]. We focus on neural AutoML, that uses deep RL to optimize architectures. These methods have shown promising results. For example, Neural Architecture Search has discovered novel networks that rival the best human-designed architectures on challenging image classification tasks [9, 10].\\nHowever, neural AutoML is expensive because it requires training many networks. This may require vast computations resources; Zoph and Le [8] report 800 concurrent GPUs to train on Cifar-10. Further, training needs to be repeated for every new task. Some methods have been proposed to address this cost, such as using a progressive search space [11], or by sharing weights among generated networks [12, 13]. We propose a complementary solution, applicable when one has multiple ML tasks to solve. Humans can tune networks based on knowledge gained from prior tasks. We aim to leverage the same information using transfer learning.\\nWe exploit the fact that deep RL-based AutoML algorithms learn an explicit parameterization of the distribution over performant models. We present Transfer Neural AutoML, a method to accelerate network design on new tasks based on priors learned on previous tasks. To do this we design a network that performs neural AutoML on multiple tasks simultaneously. Our method for multitask neural AutoML learns both hyperparameter choices common to multiple tasks and specific choices for individual tasks. We then transfer this controller to new tasks and leverage the learned priors over performant models. We reduce the time to converge in both text and image domains by over an order of magnitude in most tasks. In our experiments we save 10s of CPU hours for every task that we transfer to. 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montréal, Canada.'},\n",
              "  {'heading': '2 Methods', 'text': ''},\n",
              "  {'heading': '2.1 Neural Architecture Search',\n",
              "   'text': 'Transfer Neural AutoML is based on Neural Architecture Search (NAS) [8]. NAS uses deep RL to generate models that maximize performance on a given task. The framework consists of two components: a controller model and child models.\\nThe controller is an RNN that generates a sequence of discrete actions. Each action specifies a design choice; for example, if the child models are CNNs, these choices could include the filter heights, widths, and strides. The controller is an autoregressive model, like a language model: the action taken at each time step is fed into the RNN as input for the next time step. The recurrent state of the RNN maintains a history of the design choices taken so far. The use of an RNN allows dependencies between the design choices to be learned. The sequence of design choices define a child model that is trained and evaluated on the ML task at hand. The performance of the child network on the validation set is used as a reward to update the controller via a policy gradient algorithm.'},\n",
              "  {'heading': '2.2 Multitask Training',\n",
              "   'text': 'We propose Multitask Neural AutoML, that searches for model on multiple tasks simultaneously. It requires defining a generic search space that is shared across tasks. Many deep learning models require the same common design decisions, such as choice of network depth, learning rate, and number of training iterations. By defining a generic search space that contains common architecture and hyperparameter choices, the controller can generate a wide range of models applicable to many common problems. Multitask training allows the controller to learn a broadly applicable prior over the search space by observing shared behaviour across tasks. The proposed multitask controller has two key features: learned task representations, and advantage normalization.\\nLearned task representations The multitask AutoML controller characterizes the tasks by learning a unique embedding vector for each task. This task-embedding allows to condition model generation on the task ID. The task-embeddings are analogous to word-embeddings commonly used for NLP, where each word is associated to a trainable vector [14].\\nFigure 1 (left) shows the architecture of the multitask controller at each time step. The task embedding is fed into the RNN at every time step. In standard single-task training of NAS, only the embedding of the previous action is fed into the RNN. In multitask training, the task embedding is concatenated to the action embedding. We also add a skip connection across the RNN cell to ease the learning of action marginal distributions. The task embeddings are the only task-specific parameters. One embedding is assigned to each task; these are randomly initialized and trained jointly with the controller.\\nAt each iteration of multitask training, a task is sampled at random. This task’s embedding is fed to the controller, which generates a sequence of actions conditioned on this embedding. The child model defined by these actions is trained and evaluated on the task, and the reward is used to update the task-agnostic parameters and the corresponding task embedding.\\nTask-specific advantage normalization We train the controller using policy gradient. Each task defines a different performance metric which we use as reward. The reward affects the amplitude of the gradients applied to update the controller’s policy, π . To maintain a balanced gradient updates across tasks, we ensure that the distribution of each task’s rewards are scaled to have same mean and variance.\\nThe mean of each task’s reward distribution is centered on zero by subtracting the expected reward for the given task. The centered reward, or advantage, Aτ (m), of a model, m, applied to a task, τ , is defined as the difference between the reward obtained by the model, Rτ (m), and the expected reward for the given task, bτ = Em∼π[Rτ (m)]: Aτ (m) = Rτ (m) − bτ . bτ . Subtracting such a baseline is a standard technique in policy gradient algorithms used to reduce the variance of the parameter updates [15].\\nThe variance of each task’s reward distribution is normalized by dividing the advantage by the standard deviation of the reward: A′τ (m) = (Rτ (m)− bτ )σ−1τ . Where στ = √ Em∼π[(Rτ (m)− bτ )2]. We\\nRNN Cell\\nFFNN\\nState\\nTask embedding\\nPrev. action\\nPrev. state\\nSample action\\nAction distribution\\nFFNN\\nTask\\nAction embedding\\nC o m\\np la\\nin ts\\nN e w\\ns A\\ng g re\\ng a to\\nr\\nA ir\\nlin e\\nP ri\\nm a ry\\nE m\\no ti\\no n\\nE co\\nn o m\\nic N\\ne w\\ns\\nP o lit\\nic a l M\\ne ss\\na g e\\nS e n ti\\nm e n t\\nS S T\\nU S E\\nco n o m\\ny\\nComplaints\\nNews Aggregator\\nAirline\\nPrimary Emotion\\nEconomic News\\nPolitical Message\\nSentiment SST\\nUS Economy 0.8\\n0.4\\n0.0\\n0.4\\n0.8\\nFigure 1: Left:A single time step of the recurrent multitask AutoML controller, in which a single action is taken. The task embedding is concatenated with the embedding of the action sampled at the previous timestep and passed into the controller RNN. All parameters, other than the task embeddings, are shared across tasks. Right: Cosine similarity between the task embeddings learned by the multitask neural AutoML model.\\nrefer to A′ as the normalized advantage. The gradient update to the parameters of the policy θ is the product of the advantage and expected derivative of the log probability of sampling an action: A′τ (m)Eπ[∇θ log πθ(m)]. Thus, normalizing the advantage may also be seen as adapting the learning rate for each task.\\nIn practice, we compute bτ and στ using exponential moving averages over the sequence of rewards: btτ = (1− α)bt−1τ + αRτ (m), σ2,tτ = (1− α)σ2,t−1τ + α(Rτ (m)− btτ )2, where t indexes the trial, and α = 0.01 is the decay factor.'},\n",
              "  {'heading': '2.3 Transfer Learning',\n",
              "   'text': 'The multitask controller is pretrained on a set of tasks and learns a prior over generic architectural and parameter choices, along with task-specific decisions encoded in the task embeddings. Given a new task, we can perform transfer of the controller by: 1) reloading the parameters of the pretrained multitask controller, 2) adding a new randomly initialized task embedding for the new task. Then, architecture search is resumed, and the controller’s parameters are updated jointly with the new task embedding. By learning an embedding for the new task, the controller learns a representation that biases towards actions that performed well on similar tasks.'},\n",
              "  {'heading': '3 Related Work',\n",
              "   'text': 'A variety of optimization methods have been proposed to search over architectures, hyperparameters, and learning algorithms. These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19]. An emerging body of neuro-evolution research has adapted genetic algorithms for these complex optimization problems [20], including to set the parameters of existing deep networks [21], evolve image classifiers [5], and evolve generic deep neural networks [6].\\nOur work relates closest to NAS [8]. NAS was applied to construct CNNs for the CIFAR-10 image classification and RNNs for the Penn Treebank language modelling. Subsequent work reduces the computational cost for more challenging tasks [10]. To engineer an architecture for ImageNet classification, Zoph et al. [10] train the NAS controller on the simpler CIFAR-10 task and then transfer the child architecture to ImageNet by stacking it. However, they did not transfer the controller model itself, relying instead on the intuition that additional depth is necessary for the more challenging task. Other works apply RL to automate architecture generation and also reduce the computation cost. MetaQNN sequentially chooses CNN layers using Q-learning [22]. MetaQNN uses an aggressive exploration to reduce search time, though it can cause the resulting architectures to underperform.\\nCai et al. [23] transform existing architectures incrementally to avoid generating entire networks from scratch. Liu et al. [11] reduce search time by progressively increasing architecture complexity, and [12] propose child-model weight sharing to reduce child training time.\\nTransfer learning has achieved excellent results as an initialization method for deep networks, including for models trained using RL [24, 25, 26]. Recent meta-learning research has broadened this concept to learn generalizable representations across classes of tasks [27, 28]. Simultaneous multitask training can facilitate learning between tasks with a common structure, though retaining knowledge effectively across tasks is still an active area of research [29, 30]. There is also prior research on transfer of optimizers for Neural AutoML; Sequential Model-based Optimizers have been transferred across tasks to improve hyperparameter tuning [31, 32], we propose a parallel solution for neural methods.'},\n",
              "  {'heading': '4 Experiments',\n",
              "   'text': 'Child models Constructing the search space needs human input, so we choose wide parameter ranges to minimize injected domain expertise. Our search space for child models contains two-tower feedforward neural networks (FFNN), similar to the wide and deep models in Cheng et al. [33]. One tower is a deep FFNN, containing an input embedding module, fully connected layers and a softmax classification layer. This tower is regularized with an L2 loss. The other is a wide-shallow layer that directly connects the one-hot token encodings to the softmax classification layer with a linear projection. This tower is regularized with a sparse L1 loss. The wide layer allows the model to learn task-specific biases for each token directly. The deep FFNN’s embedding modules are pretrained1.This results in child models with higher quality and faster convergence.\\nThe single search space for all tasks is defined by the following sequence of choices: 1) Pretrained embedding module. 2) Whether to fine-tune the embedding module. 3) Number of hidden layers (HL). 4) HL size. 5) HL activation function. 6) HL normalization scheme to use. 7) HL dropout rate. 8) Deep column learning rate. 9) Deep column regularization weight. 10) Wide layer learning rate. 11) Wide layer regularization weight. 12) Training steps. The Appendix contains the exact specification. The search space is much larger than the number of possible trials, containing 1.1B configurations. All models are trained using Proximal Adagrad with batch size 100. Notice that this search space aims to optimize jointly the architecture and hyperparameters. While standard NAS search spaces are defined strictly over architectural parameters.\\nController models The controller is a 2-layer LSTM with 50 units. The action and task embeddings have size 25. The controller and embedding weights are initialized uniformly at random, yielding an approximate uniform initial distribution over actions. The learning rate is set to 10−4 and it receives gradient updates after every child completes. We tried four variants of policy gradient to train the controller: REINFORCE [34], TRPO [35], UREX [36] and PPO [37]. In preliminary experiments on four NLP tasks, we found REINFORCE and TRPO to perform best and selected REINFORCE for the following experiments.\\nWe evaluate three controllers. First, Transfer Neural AutoML, our neural controller that transfers from multitask pre-training. Second, Single-task AutoML, which is trained from scratch on each task. Finally, a baseline, Random Search (RS), that selects action uniformly at random.\\nMetrics To measure the ability of the different AutoML controllers to find good models, we compute the average accuracy of the topN (accuracy-topN) child models generated during the search. We select the best topN models according to accuracy on the validation set. We then report the validation and test performance of these models.\\nWe assess convergence rates with two metrics: 1) accuracy-topN achieved with a fixed budget of trials, 2) the number of trials required to attain a certain reward. The latter can only be used with validation accuracy-topN since test accuracy-topN does not necessarily increase monotonically with the number of trials.\\n1The pretrained modules are distributed via TensorFlow Hub: https://www.tensorflow.org/hub .'},\n",
              "  {'heading': '4.1 Natural Language Processing',\n",
              "   'text': 'Data We evaluate using 21 text classification tasks with varied statistics. The dataset sizes range from 500 to 420k datapoints. The number of classes range from 2 to 157, and the mean length of the texts, in characters, range from 19 to 20k. The Appendix contains full statistics and references.\\nEach child model is trained on the training set. The accuracy on the validation set is used as reward for the controller. The topN child models, selected on the validation set, are evaluated on the test set. Datasets without a pre-defined train/validation/test split, are split randomly 80/10/10.\\nThe multitask controller is pretrained on 8 randomly sampled tasks: Airline, Complaints, Economic News, News Aggregator, Political Message, Primary Emotion, Sentiment SST, US Economy. We then transfer from this controller to each of the remaining 13 tasks.\\nResults To assess the controllers’ ability to optimize the reward (validation set accuracy) we compute the speed-up versus the baseline, RS. We first compute accuracy-top10 on the validation set for RS given a fixed budget of B trials. We use B = 5000, except for the Brown Corpus and 20 Newsgroups where we can only use a B = 500, 3500, respectively, because these datasets were slower to train. We then report the number of trials required by AutoML and T-AutoML to achieve the same validation accuracy-top10 as RS with B trials. Table 1 (left) shows the results. Note that RS may exhibit fewer than B = 5000 trials if it converged earlier. These results shows that T-AutoML is effective at optimizing validation accuracy, offering a large reduction in time to attain a fixed reward. In 12 of the 13 datasets T-AutoML achieves the desired reward fastest, and in 9 cases achieves an order of magnitude speed-up.\\nNext, we assess the quality of the models on the test set. Table 1 (right) shows test accuracy-top10 with a budget of 500 trials (250 for Brown Corpus). Within this budget, T-AutoML performs best on all but one dataset. T-AutoML outperforms single-task AutoML on 10 out of the 13 datasets, ties on one, and loses on two. On the datasets where T-AutoML does not produce the best final model at 500 trials, it often produces better models at earlier iterations. Figure 2 shows the full learning curves of test set accuracy-top10 versus number of trials. Figure 2 shows that in most cases the controller with transfer starts with a much better prior over good models. On some datasets the quality is improved with further training e.g. Emotion, Corp Messaging, but in others the initial configurations learned from the multitask model are not improved.\\nFor reference, we put the learning curves for the initial multitask training phase in the Appendix. We also ran RS and single-task AutoML on these datasets. Slightly disappointingly, multitask training\\ndid not in itself yield substantial improvements over single-task; it attains a higher accuracy on two datasets, and in similar on the other six.\\nWe aim to to attain good performance with fewest possible trials. We do not seek to beat state-of-theart all datasets because first, although our search space is large, it does not contain all performant model components (e.g. convolutions). Second, we use embedding modules pretrained on large datasets which makes the results incomparable to those that only uses in-domain training data.\\nHowever, to confirm that Neural AutoML generates good models we compare to some previous published results where available. Overall we find that Transfer AutoML with the search space described above yields models competitive with the state-of-the-art. For example, Almeida et al. [38] use classical ML classifiers (Logistic Regression, SVMs, etc.) on SMS Spam and report best accuracy of 97.59%. Transfer AutoML gets accuracy-top10 of 98.1%. Le and Mikolov [39] report 92.58% accuracy on Sentiment IMDB with more complex architectures, Transfer AutoML’s is a little behind, accuracy top-10 is 88.1%. Li et al. [40] report 86.8% accuracy using an ensemble of weighted neural BOWs on MPQA. Transfer AutoML achieve accuracy-top10 of 88.6%. Li et al. [40] also evaluate their ensemble of weighted neural BOW models on Customer Reviews, and achieve 82.5% best accuracy, though the best accuracy of any single model is 81.1%. Comparably, T-AutoML gets an accuracy-top10 of 81.4%. Barnes et al. [41] compare many algorithms and report best accuracy on Sentiment-SST of 83.1% using LSTMs. Multitask AutoML gets an accuracy-Top10 of 83.4%. The best performance achieved with a more complex architecture that is not in our search space is: 87.8% [39]. Maas et al. [42] report 88.1% on Movie Subj, Transfer AutoML gets accuracy-top10 of 93.4%.\\nComputational Cost and Savings The median cost to perform a single trial across all 21 datasets in our experiments is T = 268s. If we run B trials with a speedup factor of S, we save BT (1 − S−1)/3600CPU-h per task to attain a fixed reward (validation accuracy-top10). Estimating the speedup factors from Table 1 (left) for transfer over single-task, we attain a median computational saving of 30CPU-h per task when performing B = 500 trials. The mean is 89CPU-h, but this is heavily influenced by the slow Brown Corpus. The time to train the multitask controller is 15h on\\n100 CPUs. If we do not need the M models for the tasks used to train the multitask controller, then we must run > (1 − 1/S)−1M new tasks to amortize this cost. For the median speedup in our experiments S = 22 that is > 1.05M new tasks.'},\n",
              "  {'heading': '4.2 Image classification',\n",
              "   'text': 'To validate the generality of our approach we evaluate on image classification task: Cifar-10. We compare the same three controllers: RS, AutoML trained from scratch, and Transfer AutoML pretrained on MNIST and Flowers2. Figure 3 shows the mean accuracy-top-10 on the test set. The transferred controller attains an accuracy-top-10 of 96.5%, similar to the other methods, but converges much faster as in the NLP tasks. The best models embed images with a finetuned Inception v3 network, pretrained on ImageNet. Relu activations are preferred over Swish [43] and the dropout rate of converges to 0.3.'},\n",
              "  {'heading': '4.3 Analysis',\n",
              "   'text': 'Meta overfitting The controller is trained on the tasks’ validation sets. Overfitting of AutoML to the validation set is not often addressed. This type of overfitting may seem unlikely because each trial is expensive, and many trials may be required to overfit. However, we observe it in some cases.\\nFigure 4 (left, center) shows the accuracy-top10 on the validation and test sets on the Prog Opinion dataset. Transfer Neural AutoML attains good solutions in the first few trials, but afterwards its validation performance grows while test performance does not. The generalization gap between the validation and test accuracy increases over time. This is the most extreme case we observed, but some other datasets exhibit some generalization gap also (see Appendix for all validation curves). This effect is largest on Prog Opinion because the validation set is tiny, with only 116 examples.\\nOverfitting arises from bias due to selecting the best models on the validation set. Child evaluation contains randomness due to the stochastic training procedure. Therefore, over time we see an improved validation score, even after convergence, due to lucky evaluations. However, those apparent improvements are not reflected on the test set. Transfer AutoML exhibits more overfitting than single-task because it converges earlier. We confirmed this effect; if we ‘cheat’ and select models by their test-set performance, we observe the same artificial improvement on the test score as on the validation score. Other than entropy regularization, we do not combat overfitting extensively. Here, we simply emphasize that because our Transfer Neural AutoML model observes many trials in total, meta-overfitting becomes a bigger issue. We leave combatting this effect to future research.\\nDistant transfer: across languages The more distant the tasks, the harder it is to perform transfer learning. The Sentiment Cine task is an outlier because it is the only Spanish task. Figure 2 and Table 1 show poorer performance of transfer on this task.\\nThe most language-sensitive parameters are the pretrained word embeddings. The controller selects from eight pretrained embeddings (see Appendix), six of which are English, and two Spanish. In the first 1500 iterations, the transferred controller chooses English embeddings, limiting the performance. However, after further training, the controller switches to Spanish tables at around 2000th trial, Figure 4 (right). At trial 2000, T-AutoML attains a test accuracy-top10 of 79.8%, approximately equal to that or random search with 79.4%, and greater than single-task with 78.1%. This indicates that although transfer works best on similar tasks, the controller is still able to adapt to outliers given sufficient training time.\\n2goo.gl/tpzfR1\\nTask representations and learned models We inspect the learned task similarities via the embeddings. Figure 1 (right) shows the cosine similarity between the task embeddings learned during multitask training. The model assigns most tasks to two clusters. It is hard to guess a priori which tasks require similar models; the dataset sizes, number of classes and text lengths differ greatly. However, the controller assigns the same model to tasks within the same cluster. At convergence, the cluster {Complaints, New Agg, Airline, Primary Emotion} is assigned (with high probability) a 1-layer networks with 256 units, Swish activation function, wide-layer learning rate 0.01, and dropout rate 0.2. The cluster {Economic News, Political Emotion, Sentiment SST} is assigned 2-layer networks with 64 units, Relu activation, wide-layer learning rate 0.003, and dropout rate 0.3.\\nOther choices follow similar distributions for each cluster. For example, the same 128D word embeddings, trained using a Neural Language Model are chosen. The controller also always chooses to fine-tune these embeddings. The controller may remove either the deep or wide tower by setting the regularization very high, but in all cases it chooses to keep both active.\\nAblation We consider two ablations of T-NAML. First, we remove the task embeddings. For this, we train a task-agnostic multitask controller without task embeddings, then transfer this controller as for T-NAML. Second, we transfer a single architecture rather than the controller parameters. For this, we train the task-agnostic multitask controller to convergence, and select the final child model. We then re-train this single architecture on each new task. Omitting task embeddings performs well on some tasks, but poorly on those that require a model different to the mode. Overall, according to accuracy-top10 at 500 trials, T-NAML outperforms the version without task embeddings on 8 tasks, loses 4, and draws on 1. The mean performance drop when ablating task embeddings is 1.8%. Using just a single model performs very poorly on many tasks, T-NAML wins 8 cases, loses 2, and draws 3, with a mean performance increase of 4.8%.'},\n",
              "  {'heading': '5 Conclusion',\n",
              "   'text': 'Neural AutoML, whilst becoming popular, comes with a high computational cost. To address this we propose transfer learning of the controller and show a large reductions in convergence time across many datasets. Extensions to this work include: Broadening the search space to contain more models classes. Attempting transfer across modalities; some priors over hyperparameter combinations learned on NLP tasks may be useful for images or other domains. Making the controller more robust to evaluation noise, and addressing the potential to meta overfit on small datasets.'},\n",
              "  {'heading': 'Acknowledgments',\n",
              "   'text': 'We are very grateful to Quentin de Laroussilhe, Andrey Khorlin, Quoc Le, Sylvain Gelly, the Tensorflow Hub team and the Google Brain team Zurich for developing software frameworks and many useful discussions.'}],\n",
              " 'references': [{'title': 'Random search for hyper-parameter optimization',\n",
              "   'author': ['James Bergstra', 'Yoshua Bengio'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': '1',\n",
              "   'shortCiteRegEx': '1',\n",
              "   'year': 2012},\n",
              "  {'title': 'Algorithms for hyper-parameter optimization',\n",
              "   'author': ['James S Bergstra',\n",
              "    'Rémi Bardenet',\n",
              "    'Yoshua Bengio',\n",
              "    'Balázs Kégl'],\n",
              "   'venue': 'In NIPS,',\n",
              "   'citeRegEx': '2',\n",
              "   'shortCiteRegEx': '2',\n",
              "   'year': 2011},\n",
              "  {'title': 'Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures',\n",
              "   'author': ['James Bergstra', 'Daniel Yamins', 'David Cox'],\n",
              "   'venue': 'In ICML,',\n",
              "   'citeRegEx': '3',\n",
              "   'shortCiteRegEx': '3',\n",
              "   'year': 2013},\n",
              "  {'title': 'Practical bayesian optimization of machine learning algorithms',\n",
              "   'author': ['Jasper Snoek', 'Hugo Larochelle', 'Ryan P Adams'],\n",
              "   'venue': 'In NIPS,',\n",
              "   'citeRegEx': '4',\n",
              "   'shortCiteRegEx': '4',\n",
              "   'year': 2012},\n",
              "  {'title': 'Large-scale evolution of image classifiers',\n",
              "   'author': ['Esteban Real',\n",
              "    'Sherry Moore',\n",
              "    'Andrew Selle',\n",
              "    'Saurabh Saxena',\n",
              "    'Yutaka Leon Suematsu',\n",
              "    'Quoc Le',\n",
              "    'Alex Kurakin'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': '5',\n",
              "   'shortCiteRegEx': '5',\n",
              "   'year': 2017},\n",
              "  {'title': 'Designing neural network architectures using reinforcement learning',\n",
              "   'author': ['Bowen Baker', 'Otkrist Gupta', 'Nikhil Naik', 'Ramesh Raskar'],\n",
              "   'venue': 'In ICLR,',\n",
              "   'citeRegEx': '7',\n",
              "   'shortCiteRegEx': '7',\n",
              "   'year': 2017},\n",
              "  {'title': 'Neural architecture search with reinforcement learning',\n",
              "   'author': ['Barret Zoph', 'Quoc V. Le'],\n",
              "   'venue': 'In ICLR,',\n",
              "   'citeRegEx': '8',\n",
              "   'shortCiteRegEx': '8',\n",
              "   'year': 2017},\n",
              "  {'title': 'Practical network blocks design with q-learning',\n",
              "   'author': ['Zhao Zhong', 'Junjie Yan', 'Cheng-Lin Liu'],\n",
              "   'venue': 'In AAAI,',\n",
              "   'citeRegEx': '9',\n",
              "   'shortCiteRegEx': '9',\n",
              "   'year': 2018},\n",
              "  {'title': 'Learning transferable architectures for scalable image recognition',\n",
              "   'author': ['Barret Zoph',\n",
              "    'Vijay Vasudevan',\n",
              "    'Jonathon Shlens',\n",
              "    'Quoc V. Le'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': '10',\n",
              "   'shortCiteRegEx': '10',\n",
              "   'year': 2017},\n",
              "  {'title': 'Progressive neural architecture search',\n",
              "   'author': ['Chenxi Liu',\n",
              "    'Barret Zoph',\n",
              "    'Jonathon Shlens',\n",
              "    'Wei Hua',\n",
              "    'Li-Jia Li',\n",
              "    'Li Fei-Fei',\n",
              "    'Alan Yuille',\n",
              "    'Jonathan Huang',\n",
              "    'Kevin Murphy'],\n",
              "   'venue': 'arXiv preprint arXiv:1712.00559,',\n",
              "   'citeRegEx': '11',\n",
              "   'shortCiteRegEx': '11',\n",
              "   'year': 2017},\n",
              "  {'title': 'Efficient neural architecture search via parameter sharing',\n",
              "   'author': ['Hieu Pham',\n",
              "    'Melody Y Guan',\n",
              "    'Barret Zoph',\n",
              "    'Quoc V Le',\n",
              "    'Jeff Dean'],\n",
              "   'venue': 'arXiv preprint arXiv:1802.03268,',\n",
              "   'citeRegEx': '12',\n",
              "   'shortCiteRegEx': '12',\n",
              "   'year': 2018},\n",
              "  {'title': 'Darts: Differentiable architecture search',\n",
              "   'author': ['Hanxiao Liu', 'Karen Simonyan', 'Yiming Yang'],\n",
              "   'venue': 'arXiv preprint arXiv:1806.09055,',\n",
              "   'citeRegEx': '13',\n",
              "   'shortCiteRegEx': '13',\n",
              "   'year': 2018},\n",
              "  {'title': 'Distributed representations of words and phrases and their compositionality',\n",
              "   'author': ['Tomas Mikolov',\n",
              "    'Ilya Sutskever',\n",
              "    'Kai Chen',\n",
              "    'Greg S Corrado',\n",
              "    'Jeff Dean'],\n",
              "   'venue': 'In NIPS,',\n",
              "   'citeRegEx': '14',\n",
              "   'shortCiteRegEx': '14',\n",
              "   'year': 2013},\n",
              "  {'title': 'Variance reduction techniques for gradient estimates in reinforcement learning',\n",
              "   'author': ['Evan Greensmith', 'Peter L Bartlett', 'Jonathan Baxter'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': '15',\n",
              "   'shortCiteRegEx': '15',\n",
              "   'year': 2004},\n",
              "  {'title': 'Initializing bayesian hyperparameter optimization via meta-learning',\n",
              "   'author': ['Matthias Feurer', 'Jost Tobias Springenberg', 'Frank Hutter'],\n",
              "   'venue': 'In AAAI,',\n",
              "   'citeRegEx': '16',\n",
              "   'shortCiteRegEx': '16',\n",
              "   'year': 2015},\n",
              "  {'title': 'Deeparchitect: Automatically designing and training deep architectures',\n",
              "   'author': ['Renato Negrinho', 'Geoff Gordon'],\n",
              "   'venue': 'arXiv preprint arXiv:1704.08792,',\n",
              "   'citeRegEx': '17',\n",
              "   'shortCiteRegEx': '17',\n",
              "   'year': 2017},\n",
              "  {'title': 'Learned optimizers that scale and generalize',\n",
              "   'author': ['Olga Wichrowska',\n",
              "    'Niru Maheswaranathan',\n",
              "    'Matthew W Hoffman',\n",
              "    'Sergio Gomez Colmenarejo',\n",
              "    'Misha Denil',\n",
              "    'Nando de Freitas',\n",
              "    'Jascha Sohl-Dickstein'],\n",
              "   'venue': 'arXiv preprint arXiv:1703.04813,',\n",
              "   'citeRegEx': '18',\n",
              "   'shortCiteRegEx': '18',\n",
              "   'year': 2017},\n",
              "  {'title': 'Neural optimizer search with reinforcement learning',\n",
              "   'author': ['Irwan Bello', 'Barret Zoph', 'Vijay Vasudevan', 'Quoc V. Le'],\n",
              "   'venue': 'In ICML,',\n",
              "   'citeRegEx': '19',\n",
              "   'shortCiteRegEx': '19',\n",
              "   'year': 2017},\n",
              "  {'title': 'Improving exploration in evolution strategies for deep reinforcement learning via a population of novelty-seeking agents',\n",
              "   'author': ['Edoardo Conti',\n",
              "    'Vashisht Madhavan',\n",
              "    'Felipe Petroski Such',\n",
              "    'Joel Lehman',\n",
              "    'Kenneth O Stanley',\n",
              "    'Jeff Clune'],\n",
              "   'venue': 'arXiv preprint arXiv:1712.06560,',\n",
              "   'citeRegEx': '20',\n",
              "   'shortCiteRegEx': '20',\n",
              "   'year': 2017},\n",
              "  {'title': 'Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning',\n",
              "   'author': ['Felipe Petroski Such',\n",
              "    'Vashisht Madhavan',\n",
              "    'Edoardo Conti',\n",
              "    'Joel Lehman',\n",
              "    'Kenneth O Stanley',\n",
              "    'Jeff Clune'],\n",
              "   'venue': 'arXiv preprint arXiv:1712.06567,',\n",
              "   'citeRegEx': '21',\n",
              "   'shortCiteRegEx': '21',\n",
              "   'year': 2017},\n",
              "  {'title': 'Designing neural network architectures using reinforcement learning',\n",
              "   'author': ['Bowen Baker', 'Otkrist Gupta', 'Nikhil Naik', 'Ramesh Raskar'],\n",
              "   'venue': 'arXiv preprint arXiv:1611.02167,',\n",
              "   'citeRegEx': '22',\n",
              "   'shortCiteRegEx': '22',\n",
              "   'year': 2016},\n",
              "  {'title': 'Reinforcement learning for architecture search by network transformation',\n",
              "   'author': ['Han Cai',\n",
              "    'Tianyao Chen',\n",
              "    'Weinan Zhang',\n",
              "    'Yong Yu',\n",
              "    'Jun Wang'],\n",
              "   'venue': 'arXiv preprint arXiv:1707.04873,',\n",
              "   'citeRegEx': '23',\n",
              "   'shortCiteRegEx': '23',\n",
              "   'year': 2017},\n",
              "  {'title': 'How transferable are features in deep neural networks',\n",
              "   'author': ['Jason Yosinski', 'Jeff Clune', 'Yoshua Bengio', 'Hod Lipson'],\n",
              "   'venue': 'In NIPS,',\n",
              "   'citeRegEx': '24',\n",
              "   'shortCiteRegEx': '24',\n",
              "   'year': 2014},\n",
              "  {'title': 'Cnn features off-the-shelf: an astounding baseline for recognition',\n",
              "   'author': ['Ali Sharif Razavian',\n",
              "    'Hossein Azizpour',\n",
              "    'Josephine Sullivan',\n",
              "    'Stefan Carlsson'],\n",
              "   'venue': 'In CVPR workshops,',\n",
              "   'citeRegEx': '25',\n",
              "   'shortCiteRegEx': '25',\n",
              "   'year': 2014},\n",
              "  {'title': 'Online transfer learning in reinforcement learning domains',\n",
              "   'author': ['Yusen Zhan', 'Matthew E Taylor'],\n",
              "   'venue': 'arXiv preprint arXiv:1507.00436,',\n",
              "   'citeRegEx': '26',\n",
              "   'shortCiteRegEx': '26',\n",
              "   'year': 2015},\n",
              "  {'title': 'Model-agnostic meta-learning for fast adaptation of deep networks',\n",
              "   'author': ['Chelsea Finn', 'Pieter Abbeel', 'Sergey Levine'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': '27',\n",
              "   'shortCiteRegEx': '27',\n",
              "   'year': 2017},\n",
              "  {'title': 'A simple neural attentive meta-learner',\n",
              "   'author': ['Nikhil Mishra',\n",
              "    'Mostafa Rohaninejad',\n",
              "    'Xi Chen',\n",
              "    'Pieter Abbeel'],\n",
              "   'venue': 'In NIPS 2017 Workshop on Meta-Learning,',\n",
              "   'citeRegEx': '28',\n",
              "   'shortCiteRegEx': '28',\n",
              "   'year': 2017},\n",
              "  {'title': 'Overcoming catastrophic forgetting in neural networks',\n",
              "   'author': ['James Kirkpatrick',\n",
              "    'Razvan Pascanu',\n",
              "    'Neil Rabinowitz',\n",
              "    'Joel Veness',\n",
              "    'Guillaume Desjardins',\n",
              "    'Andrei A Rusu',\n",
              "    'Kieran Milan',\n",
              "    'John Quan',\n",
              "    'Tiago Ramalho',\n",
              "    'Agnieszka Grabska-Barwinska'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': '29',\n",
              "   'shortCiteRegEx': '29',\n",
              "   'year': 2017},\n",
              "  {'title': 'Distral: Robust multitask reinforcement learning',\n",
              "   'author': ['Yee Whye Teh',\n",
              "    'Victor Bapst',\n",
              "    'Wojciech Marian Czarnecki',\n",
              "    'John Quan',\n",
              "    'James Kirkpatrick',\n",
              "    'Raia Hadsell',\n",
              "    'Nicolas Heess',\n",
              "    'Razvan Pascanu'],\n",
              "   'venue': 'arXiv preprint arXiv:1707.04175,',\n",
              "   'citeRegEx': '30',\n",
              "   'shortCiteRegEx': '30',\n",
              "   'year': 2017},\n",
              "  {'title': 'Collaborative hyperparameter tuning',\n",
              "   'author': ['Rémi Bardenet',\n",
              "    'Mátyás Brendel',\n",
              "    'Balázs Kégl',\n",
              "    'Michele Sebag'],\n",
              "   'venue': 'In ICML,',\n",
              "   'citeRegEx': '31',\n",
              "   'shortCiteRegEx': '31',\n",
              "   'year': 2013},\n",
              "  {'title': 'Efficient transfer learning method for automatic hyperparameter tuning',\n",
              "   'author': ['Dani Yogatama', 'Gideon Mann'],\n",
              "   'venue': 'In AISTATS,',\n",
              "   'citeRegEx': '32',\n",
              "   'shortCiteRegEx': '32',\n",
              "   'year': 2014},\n",
              "  {'title': 'Simple statistical gradient-following algorithms for connectionist reinforcement learning',\n",
              "   'author': ['Ronald J Williams'],\n",
              "   'venue': 'In Reinforcement Learning. Springer,',\n",
              "   'citeRegEx': '34',\n",
              "   'shortCiteRegEx': '34',\n",
              "   'year': 1992},\n",
              "  {'title': 'Trust region policy optimization',\n",
              "   'author': ['John Schulman',\n",
              "    'Sergey Levine',\n",
              "    'Pieter Abbeel',\n",
              "    'Michael Jordan',\n",
              "    'Philipp Moritz'],\n",
              "   'venue': 'In ICML,',\n",
              "   'citeRegEx': '35',\n",
              "   'shortCiteRegEx': '35',\n",
              "   'year': 2015},\n",
              "  {'title': 'Improving policy gradient by exploring under-appreciated rewards',\n",
              "   'author': ['Ofir Nachum', 'Mohammad Norouzi', 'Dale Schuurmans'],\n",
              "   'venue': 'In ICLR,',\n",
              "   'citeRegEx': '36',\n",
              "   'shortCiteRegEx': '36',\n",
              "   'year': 2017},\n",
              "  {'title': 'Proximal policy optimization algorithms',\n",
              "   'author': ['John Schulman',\n",
              "    'Filip Wolski',\n",
              "    'Prafulla Dhariwal',\n",
              "    'Alec Radford',\n",
              "    'Oleg Klimov'],\n",
              "   'venue': 'arXiv preprint arXiv:1707.06347,',\n",
              "   'citeRegEx': '37',\n",
              "   'shortCiteRegEx': '37',\n",
              "   'year': 2017},\n",
              "  {'title': 'Towards sms spam filtering: Results under a new dataset',\n",
              "   'author': ['Tiago Almeida',\n",
              "    'José María Gómez Hidalgo',\n",
              "    'Tiago Pasqualini Silva'],\n",
              "   'venue': 'International Journal of Information Security Science,',\n",
              "   'citeRegEx': '38',\n",
              "   'shortCiteRegEx': '38',\n",
              "   'year': 2013},\n",
              "  {'title': 'Distributed representations of sentences and documents',\n",
              "   'author': ['Quoc Le', 'Tomas Mikolov'],\n",
              "   'venue': 'In ICML,',\n",
              "   'citeRegEx': '39',\n",
              "   'shortCiteRegEx': '39',\n",
              "   'year': 2014},\n",
              "  {'title': 'Weighted neural bag-of-n-grams model: New baselines for text classification',\n",
              "   'author': ['Bofang Li', 'Zhe Zhao', 'Tao Liu', 'Puwei Wang', 'Xiaoyong Du'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': '40',\n",
              "   'shortCiteRegEx': '40',\n",
              "   'year': 2016},\n",
              "  {'title': 'Assessing state-of-the-art sentiment models on state-of-the-art sentiment datasets',\n",
              "   'author': ['Jeremy Barnes', 'Roman Klinger', 'Sabine Schulte im Walde'],\n",
              "   'venue': 'In Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis',\n",
              "   'citeRegEx': '41',\n",
              "   'shortCiteRegEx': '41',\n",
              "   'year': 2017},\n",
              "  {'title': 'Learning word vectors for sentiment analysis',\n",
              "   'author': ['Andrew L. Maas',\n",
              "    'Raymond E. Daly',\n",
              "    'Peter T. Pham',\n",
              "    'Dan Huang',\n",
              "    'Andrew Y. Ng',\n",
              "    'Christopher Potts'],\n",
              "   'venue': 'In ACL: Human Language Technologies. ACL,',\n",
              "   'citeRegEx': '42',\n",
              "   'shortCiteRegEx': '42',\n",
              "   'year': 2011},\n",
              "  {'title': 'Swish: a self-gated activation function',\n",
              "   'author': ['Prajit Ramachandran', 'Barret Zoph', 'Quoc V Le'],\n",
              "   'venue': 'arXiv preprint arXiv:1710.05941,',\n",
              "   'citeRegEx': '43',\n",
              "   'shortCiteRegEx': '43',\n",
              "   'year': 2017}],\n",
              " 'referenceMentions': [{'referenceID': 0,\n",
              "   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n",
              "   'startOffset': 51,\n",
              "   'endOffset': 54},\n",
              "  {'referenceID': 1,\n",
              "   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n",
              "   'startOffset': 78,\n",
              "   'endOffset': 84},\n",
              "  {'referenceID': 2,\n",
              "   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n",
              "   'startOffset': 78,\n",
              "   'endOffset': 84},\n",
              "  {'referenceID': 3,\n",
              "   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n",
              "   'startOffset': 108,\n",
              "   'endOffset': 111},\n",
              "  {'referenceID': 4,\n",
              "   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n",
              "   'startOffset': 132,\n",
              "   'endOffset': 138},\n",
              "  {'referenceID': 5,\n",
              "   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n",
              "   'startOffset': 146,\n",
              "   'endOffset': 152},\n",
              "  {'referenceID': 6,\n",
              "   'context': 'Many AutoML methods exist, including random search [1], performance modelling [2, 3], Bayesian optimization [4], genetic algorithms [5, 6] and RL [7, 8].',\n",
              "   'startOffset': 146,\n",
              "   'endOffset': 152},\n",
              "  {'referenceID': 7,\n",
              "   'context': 'For example, Neural Architecture Search has discovered novel networks that rival the best human-designed architectures on challenging image classification tasks [9, 10].',\n",
              "   'startOffset': 161,\n",
              "   'endOffset': 168},\n",
              "  {'referenceID': 8,\n",
              "   'context': 'For example, Neural Architecture Search has discovered novel networks that rival the best human-designed architectures on challenging image classification tasks [9, 10].',\n",
              "   'startOffset': 161,\n",
              "   'endOffset': 168},\n",
              "  {'referenceID': 6,\n",
              "   'context': 'This may require vast computations resources; Zoph and Le [8] report 800 concurrent GPUs to train on Cifar-10.',\n",
              "   'startOffset': 58,\n",
              "   'endOffset': 61},\n",
              "  {'referenceID': 9,\n",
              "   'context': 'Some methods have been proposed to address this cost, such as using a progressive search space [11], or by sharing weights among generated networks [12, 13].',\n",
              "   'startOffset': 95,\n",
              "   'endOffset': 99},\n",
              "  {'referenceID': 10,\n",
              "   'context': 'Some methods have been proposed to address this cost, such as using a progressive search space [11], or by sharing weights among generated networks [12, 13].',\n",
              "   'startOffset': 148,\n",
              "   'endOffset': 156},\n",
              "  {'referenceID': 11,\n",
              "   'context': 'Some methods have been proposed to address this cost, such as using a progressive search space [11], or by sharing weights among generated networks [12, 13].',\n",
              "   'startOffset': 148,\n",
              "   'endOffset': 156},\n",
              "  {'referenceID': 6,\n",
              "   'context': 'Transfer Neural AutoML is based on Neural Architecture Search (NAS) [8].',\n",
              "   'startOffset': 68,\n",
              "   'endOffset': 71},\n",
              "  {'referenceID': 12,\n",
              "   'context': 'The task-embeddings are analogous to word-embeddings commonly used for NLP, where each word is associated to a trainable vector [14].',\n",
              "   'startOffset': 128,\n",
              "   'endOffset': 132},\n",
              "  {'referenceID': 13,\n",
              "   'context': 'Subtracting such a baseline is a standard technique in policy gradient algorithms used to reduce the variance of the parameter updates [15].',\n",
              "   'startOffset': 135,\n",
              "   'endOffset': 139},\n",
              "  {'referenceID': 0,\n",
              "   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n",
              "   'startOffset': 28,\n",
              "   'endOffset': 31},\n",
              "  {'referenceID': 2,\n",
              "   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n",
              "   'startOffset': 52,\n",
              "   'endOffset': 55},\n",
              "  {'referenceID': 14,\n",
              "   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n",
              "   'startOffset': 99,\n",
              "   'endOffset': 103},\n",
              "  {'referenceID': 15,\n",
              "   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n",
              "   'startOffset': 186,\n",
              "   'endOffset': 190},\n",
              "  {'referenceID': 16,\n",
              "   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n",
              "   'startOffset': 236,\n",
              "   'endOffset': 244},\n",
              "  {'referenceID': 17,\n",
              "   'context': 'These include random search [1], parameter modeling [3], metalearned hyperparameter initialization [16], deep-learning based tree searches over a predefined model-specification language [17], and learning of gradient descent optimizers [18, 19].',\n",
              "   'startOffset': 236,\n",
              "   'endOffset': 244},\n",
              "  {'referenceID': 18,\n",
              "   'context': 'An emerging body of neuro-evolution research has adapted genetic algorithms for these complex optimization problems [20], including to set the parameters of existing deep networks [21], evolve image classifiers [5], and evolve generic deep neural networks [6].',\n",
              "   'startOffset': 116,\n",
              "   'endOffset': 120},\n",
              "  {'referenceID': 19,\n",
              "   'context': 'An emerging body of neuro-evolution research has adapted genetic algorithms for these complex optimization problems [20], including to set the parameters of existing deep networks [21], evolve image classifiers [5], and evolve generic deep neural networks [6].',\n",
              "   'startOffset': 180,\n",
              "   'endOffset': 184},\n",
              "  {'referenceID': 4,\n",
              "   'context': 'An emerging body of neuro-evolution research has adapted genetic algorithms for these complex optimization problems [20], including to set the parameters of existing deep networks [21], evolve image classifiers [5], and evolve generic deep neural networks [6].',\n",
              "   'startOffset': 211,\n",
              "   'endOffset': 214},\n",
              "  {'referenceID': 8,\n",
              "   'context': 'Subsequent work reduces the computational cost for more challenging tasks [10].',\n",
              "   'startOffset': 74,\n",
              "   'endOffset': 78},\n",
              "  {'referenceID': 8,\n",
              "   'context': '[10] train the NAS controller on the simpler CIFAR-10 task and then transfer the child architecture to ImageNet by stacking it.',\n",
              "   'startOffset': 0,\n",
              "   'endOffset': 4},\n",
              "  {'referenceID': 20,\n",
              "   'context': 'MetaQNN sequentially chooses CNN layers using Q-learning [22].',\n",
              "   'startOffset': 57,\n",
              "   'endOffset': 61},\n",
              "  {'referenceID': 21,\n",
              "   'context': '[23] transform existing architectures incrementally to avoid generating entire networks from scratch.',\n",
              "   'startOffset': 0,\n",
              "   'endOffset': 4},\n",
              "  {'referenceID': 9,\n",
              "   'context': '[11] reduce search time by progressively increasing architecture complexity, and [12] propose child-model weight sharing to reduce child training time.',\n",
              "   'startOffset': 0,\n",
              "   'endOffset': 4},\n",
              "  {'referenceID': 10,\n",
              "   'context': '[11] reduce search time by progressively increasing architecture complexity, and [12] propose child-model weight sharing to reduce child training time.',\n",
              "   'startOffset': 81,\n",
              "   'endOffset': 85},\n",
              "  {'referenceID': 22,\n",
              "   'context': 'Transfer learning has achieved excellent results as an initialization method for deep networks, including for models trained using RL [24, 25, 26].',\n",
              "   'startOffset': 134,\n",
              "   'endOffset': 146},\n",
              "  {'referenceID': 23,\n",
              "   'context': 'Transfer learning has achieved excellent results as an initialization method for deep networks, including for models trained using RL [24, 25, 26].',\n",
              "   'startOffset': 134,\n",
              "   'endOffset': 146},\n",
              "  {'referenceID': 24,\n",
              "   'context': 'Transfer learning has achieved excellent results as an initialization method for deep networks, including for models trained using RL [24, 25, 26].',\n",
              "   'startOffset': 134,\n",
              "   'endOffset': 146},\n",
              "  {'referenceID': 25,\n",
              "   'context': 'Recent meta-learning research has broadened this concept to learn generalizable representations across classes of tasks [27, 28].',\n",
              "   'startOffset': 120,\n",
              "   'endOffset': 128},\n",
              "  {'referenceID': 26,\n",
              "   'context': 'Recent meta-learning research has broadened this concept to learn generalizable representations across classes of tasks [27, 28].',\n",
              "   'startOffset': 120,\n",
              "   'endOffset': 128},\n",
              "  {'referenceID': 27,\n",
              "   'context': 'Simultaneous multitask training can facilitate learning between tasks with a common structure, though retaining knowledge effectively across tasks is still an active area of research [29, 30].',\n",
              "   'startOffset': 183,\n",
              "   'endOffset': 191},\n",
              "  {'referenceID': 28,\n",
              "   'context': 'Simultaneous multitask training can facilitate learning between tasks with a common structure, though retaining knowledge effectively across tasks is still an active area of research [29, 30].',\n",
              "   'startOffset': 183,\n",
              "   'endOffset': 191},\n",
              "  {'referenceID': 29,\n",
              "   'context': 'There is also prior research on transfer of optimizers for Neural AutoML; Sequential Model-based Optimizers have been transferred across tasks to improve hyperparameter tuning [31, 32], we propose a parallel solution for neural methods.',\n",
              "   'startOffset': 176,\n",
              "   'endOffset': 184},\n",
              "  {'referenceID': 30,\n",
              "   'context': 'There is also prior research on transfer of optimizers for Neural AutoML; Sequential Model-based Optimizers have been transferred across tasks to improve hyperparameter tuning [31, 32], we propose a parallel solution for neural methods.',\n",
              "   'startOffset': 176,\n",
              "   'endOffset': 184},\n",
              "  {'referenceID': 31,\n",
              "   'context': 'We tried four variants of policy gradient to train the controller: REINFORCE [34], TRPO [35], UREX [36] and PPO [37].',\n",
              "   'startOffset': 77,\n",
              "   'endOffset': 81},\n",
              "  {'referenceID': 32,\n",
              "   'context': 'We tried four variants of policy gradient to train the controller: REINFORCE [34], TRPO [35], UREX [36] and PPO [37].',\n",
              "   'startOffset': 88,\n",
              "   'endOffset': 92},\n",
              "  {'referenceID': 33,\n",
              "   'context': 'We tried four variants of policy gradient to train the controller: REINFORCE [34], TRPO [35], UREX [36] and PPO [37].',\n",
              "   'startOffset': 99,\n",
              "   'endOffset': 103},\n",
              "  {'referenceID': 34,\n",
              "   'context': 'We tried four variants of policy gradient to train the controller: REINFORCE [34], TRPO [35], UREX [36] and PPO [37].',\n",
              "   'startOffset': 112,\n",
              "   'endOffset': 116},\n",
              "  {'referenceID': 35,\n",
              "   'context': '[38] use classical ML classifiers (Logistic Regression, SVMs, etc.',\n",
              "   'startOffset': 0,\n",
              "   'endOffset': 4},\n",
              "  {'referenceID': 37,\n",
              "   'context': '[40] also evaluate their ensemble of weighted neural BOW models on Customer Reviews, and achieve 82.',\n",
              "   'startOffset': 0,\n",
              "   'endOffset': 4},\n",
              "  {'referenceID': 38,\n",
              "   'context': '[41] compare many algorithms and report best accuracy on Sentiment-SST of 83.',\n",
              "   'startOffset': 0,\n",
              "   'endOffset': 4},\n",
              "  {'referenceID': 40,\n",
              "   'context': 'Relu activations are preferred over Swish [43] and the dropout rate of converges to 0.',\n",
              "   'startOffset': 42,\n",
              "   'endOffset': 46}],\n",
              " 'year': 2018,\n",
              " 'abstractText': 'We reduce the computational cost of Neural AutoML with transfer learning. AutoML relieves human effort by automating the design of ML algorithms. Neural AutoML has become popular for the design of deep learning architectures, however, this method has a high computation cost. To address this we propose Transfer Neural AutoML that uses knowledge from prior tasks to speed up network design. We extend RL-based architecture search methods to support parallel training on multiple tasks and then transfer the search strategy to new tasks. On language and image classification tasks, Transfer Neural AutoML reduces convergence time over single-task training by over an order of magnitude on many tasks.',\n",
              " 'creator': 'LaTeX with hyperref package'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "c5fDf-cJmIwy",
        "outputId": "ba41a89d-b0e1-4f67-fb8e-7fa25a47ef18"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id             0\n",
              "conference     0\n",
              "decision       0\n",
              "url            0\n",
              "hasContent     0\n",
              "hasReview      0\n",
              "title          0\n",
              "authors        0\n",
              "reviews        0\n",
              "metaReview    24\n",
              "name           0\n",
              "metadata       0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conference</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decision</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>url</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hasContent</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hasReview</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>authors</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metaReview</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metadata</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['metadata'].iloc[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqrVLnQQ0jYx",
        "outputId": "686569bd-0667-4a55-c198-2f2b5ca8e59f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'META',\n",
              " 'title': 'Shallow Updates for Deep Reinforcement Learning',\n",
              " 'authors': ['Nir Levine', 'Tom Zahavy'],\n",
              " 'emails': ['levin.nir1@gmail.com',\n",
              "  'tomzahavy@campus.technion.ac.il',\n",
              "  'danielm@tx.technion.ac.il',\n",
              "  'avivt@berkeley.edu',\n",
              "  'shie@ee.technion.ac.il'],\n",
              " 'sections': [{'heading': '1 Introduction',\n",
              "   'text': 'Reinforcement learning (RL) is a field of research that uses dynamic programing (DP; Bertsekas 2008), among other approaches, to solve sequential decision making problems. The main challenge in applying DP to real world problems is an exponential growth of computational requirements as the problem size increases, known as the curse of dimensionality (Bertsekas, 2008).\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\nRL tackles the curse of dimensionality by approximating terms in the DP calculation such as the value function or policy. Popular function approximators for this task include deep neural networks, henceforth termed deep RL (DRL), and linear architectures, henceforth termed shallow RL (SRL).\\nSRL methods have enjoyed wide popularity over the years (see, e.g., Tsitsiklis et al. 1997; Bertsekas 2008 for extensive reviews). In particular, batch algorithms based on a least squares (LS) approach, such as Least Squares Temporal Difference (LSTD, Lagoudakis & Parr 2003) and Fitted-Q Iteration (FQI, Ernst et al. 2005) are known to be stable and data efficient. However, the success of these algorithms crucially depends on the quality of the feature representation. Ideally, the representation encodes rich, expressive features that can accurately represent the value function. However, in practice, finding such good features is difficult and often hampers the usage of linear function approximation methods.\\nIn DRL, on the other hand, the features are learned together with the value function in a deep architecture. Recent advancements in DRL using convolutional neural networks demonstrated learning of expressive features (Zahavy et al., 2016; Wang et al., 2016) and state-of-the-art performance in challenging tasks such as video games (Mnih et al. 2015; Tessler et al. 2017; Mnih et al. 2016), and Go (Silver et al., 2016). To date, the most impressive DRL results (E.g., the works of Mnih et al. 2015, Mnih et al. 2016) were obtained using online RL algorithms, based on a stochastic gradient descent (SGD) procedure.\\nOn the one hand, SRL is stable and data efficient. On the other hand, DRL learns powerful representations. This motivates us to ask: can we combine DRL with SRL to leverage the benefits of both?\\nIn this work, we develop a hybrid approach that combines batch SRL algorithms with online DRL. Our main insight is that the last layer in a deep architecture can be seen as a linear representation, with the preceding layers encoding features. Therefore, the last layer can be learned using standard SRL algorithms. Following this insight, we propose a method that repeatedly re-trains the last hidden layer of a DRL network with a batch SRL algorithm, using data collected throughout the DRL run.\\nWe focus on value-based DRL algorithms (e.g., the popular DQN of Mnih et al. 2015) and on SRL based on LS methods1, and propose the Least Squares DQN algorithm (LS-DQN). Key to our approach is a novel regularization term for the least squares method that uses the DRL solution as a prior in a Bayesian least squares formulation. Our experiments demonstrate that this hybrid approach significantly improves performance on the Atari benchmark for several combinations of DRL and SRL methods.\\nTo support our results, we performed an in-depth analysis to tease out the factors that make our hybrid approach outperform DRL. Interestingly, we found that the improved performance is mainly due to the large batch size of SRL methods compared to the small batch size that is typical for DRL.'},\n",
              "  {'heading': '2 Background',\n",
              "   'text': 'In this section we describe our RL framework and several shallow and deep RL algorithms that will be used throughout the paper.\\nRL Framework: We consider a standard RL formulation (Sutton & Barto, 1998) based on a Markov Decision Process (MDP). An MDP is a tuple 〈S,A,R, P, γ〉, where S is a finite set of states, A is a finite set of actions, and γ ∈ [0, 1] is the discount factor. A transition probability function P : S × A → ∆S maps states and actions to a probability distribution over next states. Finally, R : S×A→ [Rmin, Rmax] denotes the reward. The goal in RL is to learn a policy π : S → ∆A that solves the MDP by maximizing the expected discounted return E [ ∑∞ t=0 γ\\ntrt|π]. Value based RL methods make use of the action value function Qπ(s, a) = E[ ∑∞ t=0 γ\\ntrt|st = s, at = a, π], which represents the expected discounted return of executing action a ∈ A from state s ∈ S and following the policy π thereafter. The optimal action value function Q∗(s, a) obeys a fundamental recursion known as the Bellman equation Q∗(s, a) = E [rt + γmaxa′ Q∗(st+1, a′)| st = s, at = a].\\n1Our approach can be generalized to other DRL/SRL variants.'},\n",
              "  {'heading': '2.1 SRL algorithms',\n",
              "   'text': 'Least Squares Temporal Difference Q-Learning (LSTD-Q): LSTD (Barto & Crites, 1996) and LSTD-Q (Lagoudakis & Parr, 2003) are batch SRL algorithms. LSTD-Q learns a control policy π from a batch of samples by estimating a linear approximation Q̂π = Φwπ of the action value function Qπ ∈ R|S||A|, where wπ ∈ Rk are a set of weights and Φ ∈ R|S||A|×k is a feature matrix. Each row of Φ represents a feature vector for a state-action pair 〈s, a〉. The weights wπ are learned by enforcing Q̂π to satisfy a fixed point equation w.r.t. the projected Bellman operator, resulting in a system of linear equations Awπ = b, where A = ΦT (Φ− γPΠπΦ) and b = ΦTR. Here, R ∈ R|S||A| is the reward vector, P ∈ R|S||A|×|S| is the transition matrix and Ππ ∈ R|S|×|S||A| is a matrix describing the policy. Given a set of NSRL samples D = {si, ai, ri, si+1}NSRLi=1 , we can approximate A and b with the following empirical averages:\\nÃ = 1\\nNSRL NSRL∑ i=1 [ φ(si, ai) T ( φ(si, ai)−γφ(si+1, π(si+1)) )] , b̃ = 1 NSRL NSRL∑ i=1 [ φ(si, ai) T ri ] .\\n(1) The weights wπ can be calculated using a least squares minimization: w̃π = arg minw ‖Ãw − b̃‖22 or by calculating the pseudo-inverse: w̃π = Ã†b̃. LSTD-Q is an off-policy algorithm: the same set of samples D can be used to train any policy π so long as π(si+1) is defined for every si+1 in the set.\\nFitted Q Iteration (FQI): The FQI algorithm (Ernst et al., 2005) is a batch SRL algorithm that computes iterative approximations of the Q-function using regression. At iteration N of the algorithm, the set D defined above and the approximation from the previous iteration QN−1 are used to generate supervised learning targets: yi = ri + γmaxa′ Q N−1(si+1, a ′ ), ,∀i ∈ NSRL. These targets are then used by a supervised learning (regression) method to compute the next function in the sequence QN , by minimizing the MSE loss QN = argminQ ∑NSRL i=1 (Q(si, ai)− (ri + γmaxa′ QN−1(si+1, a′)))2. For a linear function approximation Qn(a, s) = φT (s, a)wn, LS can be used to give the FQI solution wn = arg minw ‖Ãw − b̃‖22, where Ã, b̃ are given by:\\nÃ = 1\\nNSRL NSRL∑ i=1 [ φ(si, ai) Tφ(si, ai) ] , b̃ = 1 NSRL NSRL∑ i=1 [ φ(si, ai) T yi ] . (2)\\nThe FQI algorithm can also be used with non-linear function approximations such as trees (Ernst et al., 2005) and neural networks (Riedmiller, 2005). The DQN algorithm (Mnih et al., 2015) can be viewed as online form of FQI.'},\n",
              "  {'heading': '2.2 DRL algorithms',\n",
              "   'text': 'Deep Q-Network (DQN): The DQN algorithm (Mnih et al., 2015) learns the Q function by minimizing the mean squared error of the Bellman equation, defined as Est,at,rt,st+1‖Qθ(st, at)− yt‖22, where yt = rt + γmaxa′ Qθtarget(st+1, a ′ ). The DQN maintains two separate networks, namely the current network with weights θ and the target network with weights θtarget. Fixing the target network makes the DQN algorithm equivalent to FQI (see the FQI MSE loss defined above), where the regression algorithm is chosen to be SGD (RMSPROP, Hinton et al. 2012). The DQN is an off-policy learning algorithm. Therefore, the tuples 〈st, at, rt, st+1〉 that are used to optimize the network weights are first collected from the agent’s experience and are stored in an Experience Replay (ER) buffer (Lin, 1993) providing improved stability and performance.\\nDouble DQN (DDQN): DDQN (Van Hasselt et al., 2016) is a modification of the DQN algorithm that addresses overly optimistic estimates of the value function. This is achieved by performing action selection with the current network θ and evaluating the action with the target network, θtarget, yielding the DDQN target update yt = rt if st+1 is terminal, otherwise yt = rt + γQθtarget(st+1,maxaQθ(st+1, a)).'},\n",
              "  {'heading': '3 The LS-DQN Algorithm',\n",
              "   'text': 'We now present a hybrid approach for DRL with SRL updates2. Our algorithm, the LS-DQN Algorithm, periodically switches between training a DRL network and re-training its last hidden layer using an SRL method. 3\\nWe assume that the DRL algorithm uses a deep network for representing the Q function4, where the last layer is linear and fully connected. Such networks have been used extensively in deep RL recently (e.g., Mnih et al. 2015; Van Hasselt et al. 2016; Mnih et al. 2016). In such a representation, the last layer, which approximates the Q function, can be seen as a linear combination of features (the output of the penultimate layer), and we propose to learn more accurate weights for it using SRL.\\nExplicitly, the LS-DQN algorithm begins by training the weights of a DRL network, wk, using a value-based DRL algorithm for NDRL steps (Line 2). LS-DQN then updates the last hidden layer weights, wlastk , by executing LS-UPDATE: retraining the weights using a SRL algorithm with NSRL samples (Line 3).\\nThe LS-UPDATE consists of the following steps. First, data trajectories D for the batch update are gathered using the current network weights, wk (Line 7). In practice, the current experience replay can be used and no additional samples need to be collected. The algorithm next generates new features Φ (s, a) from the data trajectories using the current DRL network with weights wk. This step guarantees that we do not use samples with inconsistent features, as the ER contains features from ’old’ networks weights. Computationally, this step requires running a forward pass of the deep network for every sample in D, and can be performed quickly using parallelization.\\nOnce the new features are generated, LS-DQN uses an SRL algorithm to re-calculate the weights of the last hidden layer wlastk (Line 9). While the LS-DQN algorithm is conceptually straightforward, we found that naively running it with off-the-shelf SRL algorithms such as FQI or LSTD resulted in instability and a degradation of the DRL performance. The reason is that the ‘slow’ SGD computation in DRL essentially retains information from older training epochs, while the batch SRL method ‘forgets’ all data but the most recent batch. In the following, we propose a novel regularization method for addressing this issue.\\nAlgorithm 1 LS-DQN Algorithm Require: w0\\n1: for k = 1 · · ·SRLiters do 2: wk ← trainDRLNetwork(wk−1) . Train the DRL network for NDRL steps 3: wlastk ← LS-UPDATE(wk) . Update the last layer weights with the SRL solution 4: end for 5: 6: function LS-UPDATE(w) 7: D ← gatherData(w) 8: Φ(s, a)← generateFeatures(D,w) 9: wlast ← SRL-Algorithm(D,Φ(s, a))\\n10: return wlast 11: end function\\nRegularization\\nOur goal is to improve the performance of a value-based DRL agent using a batch SRL algorithm. Batch SRL algorithms, however, do not leverage the knowledge that the agent has gained before the most recent batch5. We observed that this issue prevents the use of off-the-shelf implementations of SRL methods in our hybrid LS-DQN algorithm.\\n2Code is available online at https://github.com/Shallow-Updates-for-Deep-RL 3We refer the reader to Appendix B for a diagram of the algorithm. 4The features in the last DQN layer are not action dependent. We generate action-dependent features Φ (s, a) by zero-padding to a one-hot state-action feature vector. See Appendix E for more details. 5While conceptually, the data batch can include all the data seen so far, due to computational limitations, this is not a practical solution in the domains we consider.\\nTo enjoy the benefits of both worlds, that is, a batch algorithm that can use the accumulated knowledge gained by the DRL network, we introduce a novel Bayesian regularization method for LSTD-Q and FQI that uses the last hidden layer weights of the DRL network wlastk as a Bayesian prior for the SRL algorithm 6.\\nSRL Bayesian Prior Formulation: We are interested in learning the weights of the last hidden layer (wlast), using a least squares SRL algorithm. We pursue a Bayesian approach, where the prior weights distribution at iteration k of LS-DQN is given by wprior ∼ N(wlastk , λ−2), and we recall that wlastk are the last hidden layer weights of the DRL network at iteration SRLiter = k. The Bayesian solution for the regression problem in the FQI algorithm is given by (Box & Tiao, 2011)\\nwlast = (Ã+ λI)−1(b̃+ λwlastk ) ,\\nwhere Ã and b̃ are given in Equation 2. A similar regularization can be added to LSTD-Q based on a regularized fixed point equation (Kolter & Ng, 2009). Full details are in Appendix A.'},\n",
              "  {'heading': '4 Experiments',\n",
              "   'text': 'In this section, we present experiments showcasing the improved performance attained by our LSDQN algorithm compared to state-of-the-art DRL methods. Our experiments are divided into three sections. In Section 4.1, we start by investigating the behavior of SRL algorithms in high dimensional environments. We then show results for the LS-DQN on five Atari domains, in Section 4.2, and compare the resulting performance to regular DQN and DDQN agents. Finally, in Section 4.3, we present an ablative analysis of the LS-DQN algorithm, which clarifies the reasons behind our algorithm’s success.'},\n",
              "  {'heading': '4.1 SRL Algorithms with High Dimensional Observations',\n",
              "   'text': 'In the first set of experiments, we explore how least squares SRL algorithms perform in domains with high dimensional observations. This is an important step before applying a SRL method within the LS-DQN algorithm. In particular, we focused on answering the following questions: (1) What regularization method to use? (2) How to generate data for the LS algorithm? (3) How many policy improvement iterations to perform?\\nTo answer these questions, we performed the following procedure: We trained DQN agents on two games from the Arcade Learning Environment (ALE, Bellemare et al.); namely, Breakout and Qbert, using the vanilla DQN implementation (Mnih et al., 2015). For each DQN run, we (1) periodically 7 save the current DQN network weights and ER; (2) Use an SRL algorithm (LSTD-Q or FQI) to re-learn the weights of the last layer, and (3) evaluate the resulting DQN network by temporarily replacing the DQN weights with the SRL solution weights. After the evaluation, we replace back the original DQN weights and continue training.\\nEach evaluation entails 20 roll-outs 8 with an -greedy policy (similar to Mnih et al., = 0.05). This periodic evaluation setup allowed us to effectively experiment with the SRL algorithms and obtain clear comparisons with DQN, without waiting for full DQN runs to complete.\\n(1) Regularization: Experiments with standard SRL methods without any regularization yielded poor results. We found the main reason to be that the matrices used in the SRL solutions (Equations 1 and 2) are ill-conditioned, resulting in instability. One possible explanation stems from the sparseness of the features. The DQN uses ReLU activations (Jarrett et al., 2009), which causes the network to learn sparse feature representations. For example, once the DQN completed training on Breakout, 96% of features were zero.\\nOnce we added a regularization term, we found that the performance of the SRL algorithms improved. We experimented with the `2 and Bayesian Prior (BP) regularizers (λ ∈ [ 0, 102 ] ). While the `2 regularizer showed competitive performance in Breakout, we found that the BP performed better across domains (Figure 1, best regularizers chosen, shows the average score of each configuration following the explained evaluation procedure, for the different epochs). Moreover, the BP regularizer\\n6The reader is referred to Ghavamzadeh et al. (2015) for an overview on using Bayesian methods in RL. 7Every three million DQN steps, referred to as one epoch (out of a total of 50 million steps). 8Each roll-out starts from a new (random) game and follows a policy until the agent loses all of its lives.\\nwas not sensitive to the scale of the regularization coefficient. Regularizers in the range (10−1, 101) performed well across all domains. A table of average scores for different coefficients can be found in Appendix C.1. Note that we do not expect for much improvement as we replace back the original DQN weights after evaluation.\\n(2) Data Gathering: We experimented with two mechanisms for generating data: (1) generating new data from the current policy, and (2) using the ER. We found that the data generation mechanism had a significant impact on the performance of the algorithms. When the data is generated only from the current DQN policy (without ER) the SRL solution resulted in poor performance compared to a solution using the ER (as was observed by Mnih et al. 2015). We believe that the main reason the ER works well is that the ER contains data sampled from multiple (past) policies, and therefore exhibits more exploration of the state space.\\n(3) Policy Improvement: LSTD-Q and FQI are off-policy algorithms and can be applied iteratively on the same dataset (e.g. LSPI, Lagoudakis & Parr 2003). However, in practice, we found that performing multiple iterations did not improve the results. A possible explanation is that by improving the policy, the policy reaches new areas in the state space that are not represented well in the current ER, and therefore are not approximated well by the SRL solution and the current DRL network.'},\n",
              "  {'heading': '4.2 Atari Experiments',\n",
              "   'text': 'We next ran the full LS-DQN algorithm (Alg. 1) on five Atari domains: Asterix, Space Invaders, Breakout, Q-Bert and Bowling. We ran the LS-DQN using both DQN and DDQN as the DRL algorithm, and using both LSTD-Q and FQI as the SRL algorithms. We chose to run a LS-update every NDRL = 500k steps, for a total of 50M steps (SRLiters = 100). We used the current ER buffer as the ‘generated’ data in the LS-UPDATE function (line 7 in Alg. 1, NSRL = 1M ), and a regularization coefficient λ = 1 for the Bayesian prior solution (both for FQI and LSTQ-Q). We emphasize the we did not use any additional samples beyond the samples already obtained by the DRL algorithm.\\nFigure 2 presents the learning curves of the DQN network, LS-DQN with LSTD-Q, and LS-DQN with FQI (referred to as DQN, LS-DQNLSTD-Q, and LS-DQNFQI, respectively) on three domains: Asterix, Space Invaders and Breakout. Note that we use the same evaluation process as described in Mnih et al. (2015). We were also interested in a test to measure differences between learning curves, and not only their maximal score. Hence we chose to perform Wilcoxon signed-rank test on the average scores between the three DQN variants. This non-parametric statistical test measures whether related samples differ in their means (Wilcoxon, 1945). We found that the learning curves for both LS-DQNLSTD-Q and LS-DQNFQI were statistically significantly better than those of DQN, with p-values smaller than 1e-15 for all three domains.\\nTable 1 presents the maximum average scores along the learning curves of the five domains, when the SRL algorithms were incorporated into both DQN agents and DDQN agents (the notation is similar, i.e., LS-DDQNFQI)9. Our algorithm, LS-DQN, attained better performance compared to the\\n9 Scores for DQN and DDQN were taken from Van Hasselt et al. (2016).\\nvanilla DQN agents, as seen by the higher scores in Table 1 and Figure 2. We observe an interesting phenomenon for the game Asterix: In Figure 2, the DQN’s score “crashes” to zero (as was observed by Van Hasselt et al. 2016). LS-DQNLSTD-Q did not manage to resolve this issue, even though it achieved a significantly higher score that that of the DQN. LS-DQNFQI, however, maintained steady performance and did not “crash” to zero. We found that, in general, incorporating FQI as an SRL algorithm into the DRL agents resulted in improved performance.'},\n",
              "  {'heading': '4.3 Ablative Analysis',\n",
              "   'text': 'In the previous section, we saw that the LS-DQN algorithm has improved performance, compared to the DQN agents, across a number of domains. The goal of this section is to understand the reasons behind the LS-DQN’s improved performance by conducting an ablative analysis of our algorithm. For this analysis, we used a DQN agent that was trained on the game of Breakout, in the same manner as described in Section 4.1. We focus on analyzing the LS-DQNFQI algorithm, that has the same optimization objective as DQN (cf. Section 2), and postulate the following conjectures for its improved performance:\\n(i) The SRL algorithms use a Bayesian regularization term, which is not included in the DQN objective.\\n(ii) The SRL algorithms have less hyperparameters to tune and generate an explicit solution compared to SGD-based DRL solutions.\\n(iii) Large-batch methods perform better than small-batch methods when combining DRL with SRL.\\n(iv) SRL algorithms focus on training the last layer and are easier to optimize.\\nThe Experiments: We started by analyzing the learning method of the last layer (i.e., the ‘shallow’ part of the learning process). We did this by optimizing the last layer, at each LS-UPDATE epoch, using (1) FQI with a Bayesian prior and a LS solution, and (2) an ADAM (Kingma & Ba, 2014) optimizer with and without an additional Bayesian prior regularization term in the loss function. We compared these approaches for different mini-batch sizes of 32, 512, and 4096 data points, and used λ = 1 for all experiments.\\nRelating to conjecture (ii), note that the FQI algorithm has only one hyper-parameter to tune and produces an explicit solution using the whole dataset simultaneously. ADAM, on the other hand, has more hyper-parameters to tune and works on different mini-batch sizes.\\nThe Experimental Setup: The experiments were done in a periodic fashion similar to Section 4.1, i.e., testing behavior in different epochs over a vanilla DQN run. For both ADAM and FQI, we first collected 80k data samples from the ER at each epoch. For ADAM, we performed 20 iterations over the data, where each iteration consisted of randomly permuting the data, dividing it into mini-batches and optimizing using ADAM over the mini-batches10. We then simulate the agent and report average scores across 20 trajectories.\\nThe Results: Figure 3 depicts the difference between the average scores of (1) and (2) to that of the DQN baseline scores. We see that larger mini-batches result in improved performance. Moreover, the LS solution (FQI) outperforms the ADAM solutions for mini-batch sizes of 32 and 512 on most epochs, and even slightly outperforms the best of them (mini-batch size of 4096 and a Bayesian prior). In addition, a solution with a prior performs better than a solution without a prior.\\nSummary: Our ablative analysis experiments strongly support conjectures (iii) and (iv) from above, for explaining LS-DQN’s improved performance. That is, large-batch methods perform better than small-batch methods when combining DRL with SRL as explained above; and SRL algorithms that focus on training only the last layer are easier to optimize, as we see that optimizing the last layer improved the score across epochs.\\nWe finish this Section with an interesting observation. While the LS solution improves the performance of the DRL agents, we found that the LS solution weights are very close to the baseline DQN solution. See Appendix D, for the full results. Moreover, the distance was inversely proportional to the performance of the solution. That is, the FQI solution that performed the best, was the closest (in `2 norm) to the DQN solution, and vice versa. There were orders of magnitude differences between the norms of solutions that performed well and those that did not. Similar results, i.e., that large-batch solutions find solutions that are close to the baseline, have been reported in (Keskar et al., 2016). We further compare our results with the findings of Keskar et al. in the section to follow.'},\n",
              "  {'heading': '5 Related work',\n",
              "   'text': 'We now review recent works that are related to this paper.\\nRegularization: The general idea of applying regularization for feature selection, and to avoid overfitting is a common theme in machine learning. However, applying it to RL algorithms is challenging due to the fact that these algorithms are based on finding a fixed-point rather than optimizing a loss function (Kolter & Ng, 2009).Value-based DRL approaches do not use regularization layers (e.g. pooling, dropout and batch normalization), which are popular in other deep learning methods. The DQN, for example, has a relatively shallow architecture (three convolutional layers, followed by two fully connected layers) without any regularization layers. Recently, regularization was introduced\\n10 The selected hyper-parameters used for these experiments can be found in Appendix D, along with results for one iteration of ADAM.\\nin problems that combine value-based RL with other learning objectives. For example, Hester et al. (2017) combine RL with supervised learning from expert demonstration, and introduce regularization to avoid over-fitting the expert data; and Kirkpatrick et al. (2017) introduces regularization to avoid catastrophic forgetting in transfer learning. SRL methods, on the other hand, perform well with regularization (Kolter & Ng, 2009) and have been shown to converge Farahmand et al. (2009).\\nBatch size: Our results suggest that a large batch LS solution for the last layer of a value-based DRL network can significantly improve it’s performance. This result is somewhat surprising, as it has been observed by practitioners that using larger batches in deep learning degrades the quality of the model, as measured by its ability to generalize (Keskar et al., 2016).\\nHowever, our method differs from the experiments performed by Keskar et al. 2016 and therefore does not contradict them, for the following reasons: (1) The LS-DQN Algorithm uses the large batch solution only for the last layer. The lower layers of the network are not affected by the large batch solution and therefore do not converge to a sharp minimum. (2) The experiments of (Keskar et al., 2016) were performed for classification tasks, whereas our algorithm is minimizing an MSE loss. (3) Keskar et al. showed that large-batch solutions work well when piggy-backing (warm-started) on a small-batch solution. Similarly, our algorithm mixes small and large batch solutions as it switches between them periodically.\\nMoreover, it was recently observed that flat minima in practical deep learning model classes can be turned into sharp minima via re-parameterization without changing the generalization gap, and hence it requires further investigation Dinh et al. (2017). In addition, Hoffer et al. showed that large-batch training can generalize as well as small-batch training by adapting the number of iterations Hoffer et al. (2017). Thus, we strongly believe that our findings on combining large and small batches in DRL are in agreement with recent results of other deep learning research groups.\\nDeep and Shallow RL: Using the last-hidden layer of a DNN as a feature extractor and learning the last layer with a different algorithm has been addressed before in the literature, e.g., in the context of transfer learning (Donahue et al., 2013). In RL, there have been competitive attempts to use SRL with unsupervised features to play Atari (Liang et al., 2016; Blundell et al., 2016), and to learn features automatically followed by a linear control rule (Song et al., 2016), but to the best of our knowledge, this is the first attempt that successfully combines DRL with SRL algorithms.'},\n",
              "  {'heading': '6 Conclusion',\n",
              "   'text': 'In this work we presented LS-DQN, a hybrid approach that combines least-squares RL updates within online deep RL. LS-DQN obtains the best of both worlds: rich representations from deep RL networks as well as stability and data efficiency of least squares methods. Experiments with two deep RL methods and two least squares methods revealed that a hybrid approach consistently improves over vanilla deep RL in the Atari domain. Our ablative analysis indicates that the success of the LS-DQN algorithm is due to the large batch updates made possible by using least squares.\\nThis work focused on value-based RL. However, our hybrid linear/deep approach can be extended to other RL methods, such as actor critic (Mnih et al., 2016). More broadly, decades of research on linear RL methods have provided methods with strong guarantees, such as approximate linear programming (Desai et al., 2012) and modified policy iteration (Scherrer et al., 2015). Our approach shows that with the correct modifications, such as our Bayesian regularization term, linear methods can be combined with deep RL. This opens the door to future combinations of well-understood linear RL with deep representation learning.\\nAcknowledgement This research was supported by the European Community’s Seventh Framework Program (FP7/2007-2013) under grant agreement 306638 (SUPREL). A. Tamar is supported in part by Siemens and the Viterbi Scholarship, Technion.'}],\n",
              " 'references': [{'title': 'Improving elevator performance using reinforcement learning',\n",
              "   'author': ['AG Barto', 'Crites', 'RH'],\n",
              "   'venue': 'Advances in neural information processing systems,',\n",
              "   'citeRegEx': 'Barto et al\\\\.,? \\\\Q1996\\\\E',\n",
              "   'shortCiteRegEx': 'Barto et al\\\\.',\n",
              "   'year': 1996},\n",
              "  {'title': 'The arcade learning environment: An evaluation platform for general agents',\n",
              "   'author': ['Bellemare',\n",
              "    'Marc G',\n",
              "    'Naddaf',\n",
              "    'Yavar',\n",
              "    'Veness',\n",
              "    'Joel',\n",
              "    'Bowling',\n",
              "    'Michael'],\n",
              "   'venue': 'Journal of Artificial Intelligence Research,',\n",
              "   'citeRegEx': 'Bellemare et al\\\\.,? \\\\Q2013\\\\E',\n",
              "   'shortCiteRegEx': 'Bellemare et al\\\\.',\n",
              "   'year': 2013},\n",
              "  {'title': 'Model-free episodic control',\n",
              "   'author': ['Blundell',\n",
              "    'Charles',\n",
              "    'Uria',\n",
              "    'Benigno',\n",
              "    'Pritzel',\n",
              "    'Alexander',\n",
              "    'Li',\n",
              "    'Yazhe',\n",
              "    'Ruderman',\n",
              "    'Avraham',\n",
              "    'Leibo',\n",
              "    'Joel Z',\n",
              "    'Rae',\n",
              "    'Jack',\n",
              "    'Wierstra',\n",
              "    'Daan',\n",
              "    'Hassabis',\n",
              "    'Demis'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': 'Blundell et al\\\\.,? \\\\Q2016\\\\E',\n",
              "   'shortCiteRegEx': 'Blundell et al\\\\.',\n",
              "   'year': 2016},\n",
              "  {'title': 'Bayesian inference in statistical analysis',\n",
              "   'author': ['Box', 'George EP', 'Tiao', 'George C'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': 'Box et al\\\\.,? \\\\Q2011\\\\E',\n",
              "   'shortCiteRegEx': 'Box et al\\\\.',\n",
              "   'year': 2011},\n",
              "  {'title': 'Approximate dynamic programming via a smoothed linear program',\n",
              "   'author': ['Desai', 'Vijay V', 'Farias', 'Vivek F', 'Moallemi', 'Ciamac C'],\n",
              "   'venue': 'Operations Research,',\n",
              "   'citeRegEx': 'Desai et al\\\\.,? \\\\Q2012\\\\E',\n",
              "   'shortCiteRegEx': 'Desai et al\\\\.',\n",
              "   'year': 2012},\n",
              "  {'title': 'Sharp minima can generalize for deep nets',\n",
              "   'author': ['Dinh',\n",
              "    'Laurent',\n",
              "    'Pascanu',\n",
              "    'Razvan',\n",
              "    'Bengio',\n",
              "    'Samy',\n",
              "    'Yoshua'],\n",
              "   'venue': 'arXiv preprint arXiv:1703.04933,',\n",
              "   'citeRegEx': 'Dinh et al\\\\.,? \\\\Q2017\\\\E',\n",
              "   'shortCiteRegEx': 'Dinh et al\\\\.',\n",
              "   'year': 2017},\n",
              "  {'title': 'Decaf: A deep convolutional activation feature for generic visual recognition',\n",
              "   'author': ['Donahue',\n",
              "    'Jeff',\n",
              "    'Jia',\n",
              "    'Yangqing',\n",
              "    'Vinyals',\n",
              "    'Oriol',\n",
              "    'Hoffman',\n",
              "    'Judy',\n",
              "    'Zhang',\n",
              "    'Ning',\n",
              "    'Tzeng',\n",
              "    'Eric',\n",
              "    'Darrell',\n",
              "    'Trevor'],\n",
              "   'venue': 'In Proceedings of the 30th international conference on machine learning',\n",
              "   'citeRegEx': 'Donahue et al\\\\.,? \\\\Q2013\\\\E',\n",
              "   'shortCiteRegEx': 'Donahue et al\\\\.',\n",
              "   'year': 2013},\n",
              "  {'title': 'Tree-based batch mode reinforcement learning',\n",
              "   'author': ['Ernst', 'Damien', 'Geurts', 'Pierre', 'Wehenkel', 'Louis'],\n",
              "   'venue': 'Journal of Machine Learning Research,',\n",
              "   'citeRegEx': 'Ernst et al\\\\.,? \\\\Q2005\\\\E',\n",
              "   'shortCiteRegEx': 'Ernst et al\\\\.',\n",
              "   'year': 2005},\n",
              "  {'title': 'Regularized policy iteration',\n",
              "   'author': ['Farahmand',\n",
              "    'Amir M',\n",
              "    'Ghavamzadeh',\n",
              "    'Mohammad',\n",
              "    'Mannor',\n",
              "    'Shie',\n",
              "    'Szepesvári',\n",
              "    'Csaba'],\n",
              "   'venue': 'In Advances in Neural Information Processing Systems,',\n",
              "   'citeRegEx': 'Farahmand et al\\\\.,? \\\\Q2009\\\\E',\n",
              "   'shortCiteRegEx': 'Farahmand et al\\\\.',\n",
              "   'year': 2009},\n",
              "  {'title': 'Learning from demonstrations for real world reinforcement learning',\n",
              "   'author': ['Hester',\n",
              "    'Todd',\n",
              "    'Vecerik',\n",
              "    'Matej',\n",
              "    'Pietquin',\n",
              "    'Olivier',\n",
              "    'Lanctot',\n",
              "    'Marc',\n",
              "    'Schaul',\n",
              "    'Tom',\n",
              "    'Piot',\n",
              "    'Bilal',\n",
              "    'Sendonaris',\n",
              "    'Andrew',\n",
              "    'Dulac-Arnold',\n",
              "    'Gabriel',\n",
              "    'Osband',\n",
              "    'Ian',\n",
              "    'Agapiou',\n",
              "    'John'],\n",
              "   'venue': 'arXiv preprint arXiv:1704.03732,',\n",
              "   'citeRegEx': 'Hester et al\\\\.,? \\\\Q2017\\\\E',\n",
              "   'shortCiteRegEx': 'Hester et al\\\\.',\n",
              "   'year': 2017},\n",
              "  {'title': 'Neural networks for machine learning lecture 6a overview of mini–batch gradient descent',\n",
              "   'author': ['Hinton', 'Geoffrey', 'Srivastava', 'NiRsh', 'Swersky', 'Kevin'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': 'Hinton et al\\\\.,? \\\\Q2012\\\\E',\n",
              "   'shortCiteRegEx': 'Hinton et al\\\\.',\n",
              "   'year': 2012},\n",
              "  {'title': 'Train longer, generalize better: closing the generalization gap in large batch training of neural networks',\n",
              "   'author': ['Hoffer', 'Elad', 'Hubara', 'Itay', 'Soudry', 'Daniel'],\n",
              "   'venue': 'arXiv preprint arXiv:1705.08741,',\n",
              "   'citeRegEx': 'Hoffer et al\\\\.,? \\\\Q2017\\\\E',\n",
              "   'shortCiteRegEx': 'Hoffer et al\\\\.',\n",
              "   'year': 2017},\n",
              "  {'title': 'What is the best multi-stage architecture for object recognition',\n",
              "   'author': ['Jarrett', 'Kevin', 'Kavukcuoglu', 'Koray', 'LeCun', 'Yann'],\n",
              "   'venue': 'In Computer Vision,',\n",
              "   'citeRegEx': 'Jarrett et al\\\\.,? \\\\Q2009\\\\E',\n",
              "   'shortCiteRegEx': 'Jarrett et al\\\\.',\n",
              "   'year': 2009},\n",
              "  {'title': 'On large-batch training for deep learning: Generalization gap and sharp minima',\n",
              "   'author': ['Keskar',\n",
              "    'Nitish Shirish',\n",
              "    'Mudigere',\n",
              "    'Dheevatsa',\n",
              "    'Nocedal',\n",
              "    'Jorge',\n",
              "    'Smelyanskiy',\n",
              "    'Mikhail',\n",
              "    'Tang',\n",
              "    'Ping Tak Peter'],\n",
              "   'venue': 'arXiv preprint arXiv:1609.04836,',\n",
              "   'citeRegEx': 'Keskar et al\\\\.,? \\\\Q2016\\\\E',\n",
              "   'shortCiteRegEx': 'Keskar et al\\\\.',\n",
              "   'year': 2016},\n",
              "  {'title': 'Adam: A method for stochastic optimization',\n",
              "   'author': ['Kingma', 'Diederik', 'Ba', 'Jimmy'],\n",
              "   'venue': 'arXiv preprint arXiv:1412.6980,',\n",
              "   'citeRegEx': 'Kingma et al\\\\.,? \\\\Q2014\\\\E',\n",
              "   'shortCiteRegEx': 'Kingma et al\\\\.',\n",
              "   'year': 2014},\n",
              "  {'title': 'Overcoming catastrophic forgetting in neural networks',\n",
              "   'author': ['Kirkpatrick',\n",
              "    'James',\n",
              "    'Pascanu',\n",
              "    'Razvan',\n",
              "    'Rabinowitz',\n",
              "    'Neil',\n",
              "    'Veness',\n",
              "    'Joel',\n",
              "    'Desjardins',\n",
              "    'Guillaume',\n",
              "    'Rusu',\n",
              "    'Andrei A',\n",
              "    'Milan',\n",
              "    'Kieran',\n",
              "    'Quan',\n",
              "    'John',\n",
              "    'Ramalho',\n",
              "    'Tiago',\n",
              "    'Grabska-Barwinska',\n",
              "    'Agnieszka'],\n",
              "   'venue': 'Proceedings of the National Academy of Sciences,',\n",
              "   'citeRegEx': 'Kirkpatrick et al\\\\.,? \\\\Q2017\\\\E',\n",
              "   'shortCiteRegEx': 'Kirkpatrick et al\\\\.',\n",
              "   'year': 2017},\n",
              "  {'title': 'Regularization and feature selection in least-squares temporal difference learning',\n",
              "   'author': ['Kolter', 'J Zico', 'Ng', 'Andrew Y'],\n",
              "   'venue': 'In Proceedings of the 26th annual international conference on machine learning',\n",
              "   'citeRegEx': 'Kolter et al\\\\.,? \\\\Q2009\\\\E',\n",
              "   'shortCiteRegEx': 'Kolter et al\\\\.',\n",
              "   'year': 2009},\n",
              "  {'title': 'Least-squares policy iteration',\n",
              "   'author': ['Lagoudakis', 'Michail G', 'Parr', 'Ronald'],\n",
              "   'venue': 'Journal of machine learning research,',\n",
              "   'citeRegEx': 'Lagoudakis et al\\\\.,? \\\\Q2003\\\\E',\n",
              "   'shortCiteRegEx': 'Lagoudakis et al\\\\.',\n",
              "   'year': 2003},\n",
              "  {'title': 'State of the art control of atari games using shallow reinforcement learning',\n",
              "   'author': ['Liang',\n",
              "    'Yitao',\n",
              "    'Machado',\n",
              "    'Marlos C',\n",
              "    'Talvitie',\n",
              "    'Erik',\n",
              "    'Bowling',\n",
              "    'Michael'],\n",
              "   'venue': 'In Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems,',\n",
              "   'citeRegEx': 'Liang et al\\\\.,? \\\\Q2016\\\\E',\n",
              "   'shortCiteRegEx': 'Liang et al\\\\.',\n",
              "   'year': 2016},\n",
              "  {'title': 'Reinforcement learning for robots using neural networks',\n",
              "   'author': ['Lin', 'Long-Ji'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': 'Lin and Long.Ji.,? \\\\Q1993\\\\E',\n",
              "   'shortCiteRegEx': 'Lin and Long.Ji.',\n",
              "   'year': 1993},\n",
              "  {'title': 'Human-level control through deep reinforcement learning',\n",
              "   'author': ['Mnih',\n",
              "    'Volodymyr',\n",
              "    'Kavukcuoglu',\n",
              "    'Koray',\n",
              "    'Silver',\n",
              "    'David',\n",
              "    'Rusu',\n",
              "    'Andrei A',\n",
              "    'Veness',\n",
              "    'Joel',\n",
              "    'Bellemare',\n",
              "    'Marc G',\n",
              "    'Graves',\n",
              "    'Alex',\n",
              "    'Riedmiller',\n",
              "    'Martin',\n",
              "    'Fidjeland',\n",
              "    'Andreas K',\n",
              "    'Ostrovski',\n",
              "    'Georg'],\n",
              "   'venue': 'Nature, 518(7540):529–533,',\n",
              "   'citeRegEx': 'Mnih et al\\\\.,? \\\\Q2015\\\\E',\n",
              "   'shortCiteRegEx': 'Mnih et al\\\\.',\n",
              "   'year': 2015},\n",
              "  {'title': 'Asynchronous methods for deep reinforcement learning',\n",
              "   'author': ['Mnih',\n",
              "    'Volodymyr',\n",
              "    'Badia',\n",
              "    'Adria Puigdomenech',\n",
              "    'Mirza',\n",
              "    'Mehdi',\n",
              "    'Graves',\n",
              "    'Alex',\n",
              "    'Lillicrap',\n",
              "    'Timothy P',\n",
              "    'Harley',\n",
              "    'Tim',\n",
              "    'Silver',\n",
              "    'David',\n",
              "    'Kavukcuoglu',\n",
              "    'Koray'],\n",
              "   'venue': 'In International Conference on Machine Learning,',\n",
              "   'citeRegEx': 'Mnih et al\\\\.,? \\\\Q2016\\\\E',\n",
              "   'shortCiteRegEx': 'Mnih et al\\\\.',\n",
              "   'year': 2016},\n",
              "  {'title': 'Neural fitted q iteration–first experiences with a data efficient neural reinforcement learning method',\n",
              "   'author': ['Riedmiller', 'Martin'],\n",
              "   'venue': 'In European Conference on Machine Learning,',\n",
              "   'citeRegEx': 'Riedmiller and Martin.,? \\\\Q2005\\\\E',\n",
              "   'shortCiteRegEx': 'Riedmiller and Martin.',\n",
              "   'year': 2005},\n",
              "  {'title': 'Approximate modified policy iteration and its application to the game of tetris',\n",
              "   'author': ['Scherrer',\n",
              "    'Bruno',\n",
              "    'Ghavamzadeh',\n",
              "    'Mohammad',\n",
              "    'Gabillon',\n",
              "    'Victor',\n",
              "    'Lesner',\n",
              "    'Boris',\n",
              "    'Geist',\n",
              "    'Matthieu'],\n",
              "   'venue': 'Journal of Machine Learning Research,',\n",
              "   'citeRegEx': 'Scherrer et al\\\\.,? \\\\Q2015\\\\E',\n",
              "   'shortCiteRegEx': 'Scherrer et al\\\\.',\n",
              "   'year': 2015},\n",
              "  {'title': 'Mastering the game of go with deep neural networks and tree',\n",
              "   'author': ['Silver',\n",
              "    'David',\n",
              "    'Huang',\n",
              "    'Aja',\n",
              "    'Maddison',\n",
              "    'Chris J',\n",
              "    'Guez',\n",
              "    'Arthur',\n",
              "    'Sifre',\n",
              "    'Laurent',\n",
              "    'Van Den Driessche',\n",
              "    'George',\n",
              "    'Schrittwieser',\n",
              "    'Julian',\n",
              "    'Antonoglou',\n",
              "    'Ioannis',\n",
              "    'Panneershelvam',\n",
              "    'Veda',\n",
              "    'Lanctot',\n",
              "    'Marc'],\n",
              "   'venue': 'search. Nature,',\n",
              "   'citeRegEx': 'Silver et al\\\\.,? \\\\Q2016\\\\E',\n",
              "   'shortCiteRegEx': 'Silver et al\\\\.',\n",
              "   'year': 2016},\n",
              "  {'title': 'Linear feature encoding for reinforcement learning',\n",
              "   'author': ['Song',\n",
              "    'Zhao',\n",
              "    'Parr',\n",
              "    'Ronald E',\n",
              "    'Liao',\n",
              "    'Xuejun',\n",
              "    'Carin',\n",
              "    'Lawrence'],\n",
              "   'venue': 'In Advances in Neural Information Processing Systems,',\n",
              "   'citeRegEx': 'Song et al\\\\.,? \\\\Q2016\\\\E',\n",
              "   'shortCiteRegEx': 'Song et al\\\\.',\n",
              "   'year': 2016},\n",
              "  {'title': 'Reinforcement Learning: An Introduction',\n",
              "   'author': ['Sutton', 'Richard', 'Barto', 'Andrew'],\n",
              "   'venue': None,\n",
              "   'citeRegEx': 'Sutton et al\\\\.,? \\\\Q1998\\\\E',\n",
              "   'shortCiteRegEx': 'Sutton et al\\\\.',\n",
              "   'year': 1998},\n",
              "  {'title': 'A deep hierarchical approach to lifelong learning in minecraft',\n",
              "   'author': ['Tessler',\n",
              "    'Chen',\n",
              "    'Givony',\n",
              "    'Shahar',\n",
              "    'Zahavy',\n",
              "    'Tom',\n",
              "    'Mankowitz',\n",
              "    'Daniel J',\n",
              "    'Mannor',\n",
              "    'Shie'],\n",
              "   'venue': 'Proceedings of the National Conference on Artificial Intelligence (AAAI),',\n",
              "   'citeRegEx': 'Tessler et al\\\\.,? \\\\Q2017\\\\E',\n",
              "   'shortCiteRegEx': 'Tessler et al\\\\.',\n",
              "   'year': 2017},\n",
              "  {'title': 'An analysis of temporal-difference learning with function approximation',\n",
              "   'author': ['Tsitsiklis', 'John N', 'Van Roy', 'Benjamin'],\n",
              "   'venue': 'IEEE transactions on automatic control',\n",
              "   'citeRegEx': 'Tsitsiklis et al\\\\.,? \\\\Q1997\\\\E',\n",
              "   'shortCiteRegEx': 'Tsitsiklis et al\\\\.',\n",
              "   'year': 1997},\n",
              "  {'title': 'Deep reinforcement learning with double q-learning',\n",
              "   'author': ['Van Hasselt', 'Hado', 'Guez', 'Arthur', 'Silver', 'David'],\n",
              "   'venue': 'Proceedings of the National Conference on Artificial Intelligence (AAAI),',\n",
              "   'citeRegEx': 'Hasselt et al\\\\.,? \\\\Q2016\\\\E',\n",
              "   'shortCiteRegEx': 'Hasselt et al\\\\.',\n",
              "   'year': 2016},\n",
              "  {'title': 'Dueling network architectures for deep reinforcement learning',\n",
              "   'author': ['Wang',\n",
              "    'Ziyu',\n",
              "    'Schaul',\n",
              "    'Tom',\n",
              "    'Hessel',\n",
              "    'Matteo',\n",
              "    'van Hasselt',\n",
              "    'Hado',\n",
              "    'Lanctot',\n",
              "    'Marc',\n",
              "    'de Freitas',\n",
              "    'Nando'],\n",
              "   'venue': 'In Proceedings of The 33rd International Conference on Machine Learning,',\n",
              "   'citeRegEx': 'Wang et al\\\\.,? \\\\Q2016\\\\E',\n",
              "   'shortCiteRegEx': 'Wang et al\\\\.',\n",
              "   'year': 2016},\n",
              "  {'title': 'Individual comparisons by ranking methods',\n",
              "   'author': ['Wilcoxon', 'Frank'],\n",
              "   'venue': 'Biometrics bulletin,',\n",
              "   'citeRegEx': 'Wilcoxon and Frank.,? \\\\Q1945\\\\E',\n",
              "   'shortCiteRegEx': 'Wilcoxon and Frank.',\n",
              "   'year': 1945},\n",
              "  {'title': 'Graying the black box: Understanding dqns',\n",
              "   'author': ['Zahavy', 'Tom', 'Ben-Zrihem', 'Nir', 'Mannor', 'Shie'],\n",
              "   'venue': 'In Proceedings of The 33rd International Conference on Machine Learning,',\n",
              "   'citeRegEx': 'Zahavy et al\\\\.,? \\\\Q2016\\\\E',\n",
              "   'shortCiteRegEx': 'Zahavy et al\\\\.',\n",
              "   'year': 2016}],\n",
              " 'referenceMentions': [{'referenceID': 32,\n",
              "   'context': 'Recent advancements in DRL using convolutional neural networks demonstrated learning of expressive features (Zahavy et al., 2016; Wang et al., 2016) and state-of-the-art performance in challenging tasks such as video games (Mnih et al.',\n",
              "   'startOffset': 108,\n",
              "   'endOffset': 148},\n",
              "  {'referenceID': 30,\n",
              "   'context': 'Recent advancements in DRL using convolutional neural networks demonstrated learning of expressive features (Zahavy et al., 2016; Wang et al., 2016) and state-of-the-art performance in challenging tasks such as video games (Mnih et al.',\n",
              "   'startOffset': 108,\n",
              "   'endOffset': 148},\n",
              "  {'referenceID': 20,\n",
              "   'context': ', 2016) and state-of-the-art performance in challenging tasks such as video games (Mnih et al. 2015; Tessler et al. 2017; Mnih et al. 2016), and Go (Silver et al.',\n",
              "   'startOffset': 82,\n",
              "   'endOffset': 139},\n",
              "  {'referenceID': 27,\n",
              "   'context': ', 2016) and state-of-the-art performance in challenging tasks such as video games (Mnih et al. 2015; Tessler et al. 2017; Mnih et al. 2016), and Go (Silver et al.',\n",
              "   'startOffset': 82,\n",
              "   'endOffset': 139},\n",
              "  {'referenceID': 21,\n",
              "   'context': ', 2016) and state-of-the-art performance in challenging tasks such as video games (Mnih et al. 2015; Tessler et al. 2017; Mnih et al. 2016), and Go (Silver et al.',\n",
              "   'startOffset': 82,\n",
              "   'endOffset': 139},\n",
              "  {'referenceID': 7,\n",
              "   'context': 'Fitted Q Iteration (FQI): The FQI algorithm (Ernst et al., 2005) is a batch SRL algorithm that computes iterative approximations of the Q-function using regression.',\n",
              "   'startOffset': 44,\n",
              "   'endOffset': 64},\n",
              "  {'referenceID': 7,\n",
              "   'context': 'The FQI algorithm can also be used with non-linear function approximations such as trees (Ernst et al., 2005) and neural networks (Riedmiller, 2005).',\n",
              "   'startOffset': 89,\n",
              "   'endOffset': 109},\n",
              "  {'referenceID': 20,\n",
              "   'context': 'The DQN algorithm (Mnih et al., 2015) can be viewed as online form of FQI.',\n",
              "   'startOffset': 18,\n",
              "   'endOffset': 37},\n",
              "  {'referenceID': 20,\n",
              "   'context': 'Deep Q-Network (DQN): The DQN algorithm (Mnih et al., 2015) learns the Q function by minimizing the mean squared error of the Bellman equation, defined as Est,at,rt,st+1‖Qθ(st, at)− yt‖(2)2, where yt = rt + γmaxa′ Qθtarget(st+1, a ′ ).',\n",
              "   'startOffset': 40,\n",
              "   'endOffset': 59},\n",
              "  {'referenceID': 21,\n",
              "   'context': 'Such networks have been used extensively in deep RL recently (e.g., Mnih et al. 2015; Van Hasselt et al. 2016; Mnih et al. 2016).',\n",
              "   'startOffset': 61,\n",
              "   'endOffset': 128},\n",
              "  {'referenceID': 20,\n",
              "   'context': '); namely, Breakout and Qbert, using the vanilla DQN implementation (Mnih et al., 2015).',\n",
              "   'startOffset': 68,\n",
              "   'endOffset': 87},\n",
              "  {'referenceID': 12,\n",
              "   'context': 'The DQN uses ReLU activations (Jarrett et al., 2009), which causes the network to learn sparse feature representations.',\n",
              "   'startOffset': 30,\n",
              "   'endOffset': 52},\n",
              "  {'referenceID': 13,\n",
              "   'context': ', that large-batch solutions find solutions that are close to the baseline, have been reported in (Keskar et al., 2016).',\n",
              "   'startOffset': 98,\n",
              "   'endOffset': 119},\n",
              "  {'referenceID': 13,\n",
              "   'context': 'This result is somewhat surprising, as it has been observed by practitioners that using larger batches in deep learning degrades the quality of the model, as measured by its ability to generalize (Keskar et al., 2016).',\n",
              "   'startOffset': 196,\n",
              "   'endOffset': 217},\n",
              "  {'referenceID': 13,\n",
              "   'context': '(2) The experiments of (Keskar et al., 2016) were performed for classification tasks, whereas our algorithm is minimizing an MSE loss.',\n",
              "   'startOffset': 23,\n",
              "   'endOffset': 44},\n",
              "  {'referenceID': 6,\n",
              "   'context': ', in the context of transfer learning (Donahue et al., 2013).',\n",
              "   'startOffset': 38,\n",
              "   'endOffset': 60},\n",
              "  {'referenceID': 18,\n",
              "   'context': 'In RL, there have been competitive attempts to use SRL with unsupervised features to play Atari (Liang et al., 2016; Blundell et al., 2016), and to learn features automatically followed by a linear control rule (Song et al.',\n",
              "   'startOffset': 96,\n",
              "   'endOffset': 139},\n",
              "  {'referenceID': 2,\n",
              "   'context': 'In RL, there have been competitive attempts to use SRL with unsupervised features to play Atari (Liang et al., 2016; Blundell et al., 2016), and to learn features automatically followed by a linear control rule (Song et al.',\n",
              "   'startOffset': 96,\n",
              "   'endOffset': 139},\n",
              "  {'referenceID': 25,\n",
              "   'context': ', 2016), and to learn features automatically followed by a linear control rule (Song et al., 2016), but to the best of our knowledge, this is the first attempt that successfully combines DRL with SRL algorithms.',\n",
              "   'startOffset': 79,\n",
              "   'endOffset': 98},\n",
              "  {'referenceID': 21,\n",
              "   'context': 'However, our hybrid linear/deep approach can be extended to other RL methods, such as actor critic (Mnih et al., 2016).',\n",
              "   'startOffset': 99,\n",
              "   'endOffset': 118},\n",
              "  {'referenceID': 4,\n",
              "   'context': 'More broadly, decades of research on linear RL methods have provided methods with strong guarantees, such as approximate linear programming (Desai et al., 2012) and modified policy iteration (Scherrer et al.',\n",
              "   'startOffset': 140,\n",
              "   'endOffset': 160},\n",
              "  {'referenceID': 23,\n",
              "   'context': ', 2012) and modified policy iteration (Scherrer et al., 2015).',\n",
              "   'startOffset': 38,\n",
              "   'endOffset': 61}],\n",
              " 'year': 2017,\n",
              " 'abstractText': 'Deep reinforcement learning (DRL) methods such as the Deep Q-Network (DQN) have achieved state-of-the-art results in a variety of challenging, high-dimensional domains. This success is mainly attributed to the power of deep neural networks to learn rich domain representations for approximating the value function or policy. Batch reinforcement learning methods with linear representations, on the other hand, are more stable and require less hyper parameter tuning. Yet, substantial feature engineering is necessary to achieve good results. In this work we propose a hybrid approach – the Least Squares Deep Q-Network (LS-DQN), which combines rich feature representations learned by a DRL algorithm with the stability of a linear least squares method. We do this by periodically re-training the last hidden layer of a DRL network with a batch least squares update. Key to our approach is a Bayesian regularization term for the least squares update, which prevents over-fitting to the more recent data. We tested LS-DQN on five Atari games and demonstrate significant improvement over vanilla DQN and Double-DQN. We also investigated the reasons for the superior performance of our method. Interestingly, we found that the performance improvement can be attributed to the large batch size used by the LS method when optimizing the last layer.',\n",
              " 'creator': None}"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install datasets\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "!pip install torch transformers bert-score\n",
        "!pip install tqdm\n",
        "!pip install rouge_score\n",
        "!pip install sentence_transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br_dEMJMMAlp",
        "outputId": "7bd42e4b-3686-4cb7-c91f-03849475448e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m60.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n",
            "Successfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=11b0146bec71c32adec5cfd61a39a8db724007633cabffe9e5edd5985a065c1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.6.20)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.reviews[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-whYCEkMXcSX",
        "outputId": "c7d62165-e281-4a27-9aa6-15063dfc9571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'review': 'The term strategy is a bit ambiguous. Could you please explain more in formal terms what is strategy?\\nIs r the discounted Return at time t, or the reward at time t?\\nCould the author compare the method to TD learning?\\nThe paper is vague and using many RL terms with different meanings without clarifying those diversions.\\n\"So, the output for a given state-actions pair is always same\". Q function by definition is the value of (state, action). So as long as the policy is deterministic the output would be always same too. How\\'s this different from Q learning?\\nThe model description doesn\\'t specify what is the policy, and it\\'s only being mentioned in data generation part.\\nWhy is it a model based approach?\\nThe learning curves are only for 19 iterations, which does not give any useful information. The final results are clearly nothing comparable to previous works. The model is only being tested on three games.\\n\\nThe paper is vague and using informal language or sometimes misusing the common RL terms. The experiments are very small scale and even in that scenario performing very bad. It\\'s not clear, why it\\'s a model-based approach. ',\n",
              "  'rating': '2: Strong rejection',\n",
              "  'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'},\n",
              " {'review': 'This paper proposes a model-based reinforcement learning approach focusing on predicting future rewards given a current state and future actions. This is achieved with a \"residual recurrent neural network\", that outputs the expected reward increase at various time steps in the future. To demonstrate the usefulness of this approach, experiments are conducted on Atari games, with a simple playing strategy that consists in evaluating random sequences of moves and picking the one with highest expected reward (and low enough chance of dying). Interestingly, out of the 3 games tested, one of them exhibits better performance when the agent is trained in a multitask setting (i.e. learning all games simultaneously), hinting that transfer learning is occurring.\\n\\nThis submission is easy enough to read, and the reward prediction architecture looks like an original and sound idea. There are however several points that I believe prevent this work from reaching the ICLR bar, as detailed below.\\n\\nThe first issue is the discrepancy between the algorithm proposed in Section 3 vs its actual implementation in Section 4 (experiments): in Section 3 the output is supposed to be the expected accumulated reward in future time steps (as a single scalar), while in experiments it is instead two numbers, one which is the probability of dying and another one which is the probability of having a higher score without dying. This might work better, but it also means the idea as presented in the main body of the paper is not actually evaluated (and I guess it would not work well, as otherwise why implement it differently?)\\n\\nIn addition, the experimental results are quite limited: only on 3 games that were hand-picked to be easy enough, and no comparison to other RL techniques (DQN & friends). I realize that the main focus of the paper is not about exhibiting state-of-the-art results, since the policy being used is only a simple heuristic to show that the model predictions can ne used to drive decisions. That being said, I think experiments should have tried to demonstrate how to use this model to obtain better reinforcement learning algorithms: there is actually no reinforcement learning done here, since the model is a supervised algorithm, used in a manually-defined hardcoded policy. Another question that could have been addressed (but was not) in the experiments is how good these predictions are (e.g. classification error on dying probability, MSE on future rewards, ...), compared to simpler baselines.\\n\\nFinally, the paper\\'s \"previous work\" section is too limited, focusing only on DQN and in particular saying very little on the topic of model-based RL. I think a paper like for instance \"Action-Conditional Video Prediction using Deep Networks in Atari Games\" should have been an obvious \"must cite\".\\n\\nMinor comments:\\n- Notations are unusual, with \"a\" denoting a state rather than an action, this is potentially confusing and I see no reason to stray away from standard RL notations\\n- Using a dot for tensor concatenation is not a great choice either, since the dot usually indicates a dot product\\n- The r_i in 3.2.2 is a residual that has nothing to do with r_i the reward\\n- c_i is defined as \"The control that was performed at time i\", but instead it seems to be the control performed at time i-1\\n- There is a recurrent confusion between mean and median in 3.2.2\\n- x should not be used in Observation 1 since the x from Fig. 3 does not go through layer normalization\\n- The inequality in Observation 1 should be about |x_i|, not x_i\\n- Observation 1 (with its proof) takes too much space for such a simple result\\n- In 3.2.3 the first r_j should be r_i\\n- The probability of dying comes out of nowhere in 3.3, since we do not know yet it will be an output of the model\\n- \"Our approach is not able to learn from good strategies\" => did you mean \"*only* from good strategies\"?\\n- Please say that in Fig. 4 \"fc\" means \"fully connected\"\\n- It would be nice also to say how the architecture of Fig. 4 differs from the classical DQN architecture from Mnih et al (2015)\\n- Please clarify r_j2 as per your answer in OpenReview comments\\n- Table 3 says \"After one iteration\" but has \"PRL Iteration 2\" in it, which is confusing\\n- \"Figure 5 shows that not only there is no degradation in Pong and Demon Attack\"=> to me it seems to be a bit worse, actually\\n- \"A model that has learned only from random play is able to play at least 7 times better.\" => not clear where this 7 comes from\\n- \"Demon Attack\\'s plot in Figure 5c shows a potential problem we mentioned earlier\" => where was it mentioned?\\n',\n",
              "  'rating': '4: Ok but not good enough - rejection',\n",
              "  'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'},\n",
              " {'review': 'This paper proposes a new approach to model based reinforcement learning and\\nevaluates it on 3 ATARI games. The approach involves training a model that\\npredicts a sequence of rewards and probabilities of losing a life given a\\ncontext of frames and a sequence of actions. The controller samples random\\nsequences of actions and executes the one that balances the probabilities of\\nearning a point and losing a life given some thresholds. The proposed system\\nlearns to play 3 Atari games both individually and when trained on all 3 in a\\nmulti-task setup at super-human level.\\n\\nThe results presented in the paper are very encouraging but there are many\\nad-hoc design choices in the design of the system. The paper also provides\\nlittle insight into the importance of the different components of the system.\\n\\nMain concerns:\\n- The way predicted rewards and life loss probabilities are combined is very ad-hoc.\\n  The natural way to do this would be by learning a Q-value, instead different\\n  rules are devised for different games.\\n- Is a model actually being learned and improved? It would be good to see\\n  predictions for several actions sequences from some carefully chosen start\\n  states. This would be good to see both on a game where the approach works and\\n  on a game where it fails. The learning progress could also be measured by\\n  plotting the training loss on a fixed holdout set of sequences.\\n- How important is the proposed RRNN architecture? Would it still work without\\n  the residual connections? Would a standard LSTM also work?\\n\\nMinor points:\\n- Intro, paragraph 2 - There is a lot of much earlier work on using models in\\n  RL. For example, see Dyna and \"Memory approaches to reinforcement learning in\\n  non-Markovian domains\" by Lin and Mitchell to name just two.\\n- Section 3.1 - Minor point, but using a_i to represent the observation is\\n  unusual.  Why not use o_i for observations and a_i for actions?\\n- Section 3.2.2 - Notation again, r_i was used earlier to represent the\\n  reward at time i but it is being used again for something else.\\n- Observation 1 seems somewhat out of place. Citing the layer normalization\\n  paper for the motivation is enough.\\n- Section 3.2.2, second last paragraph - How is memory decoupled from\\n  computation here? Models like neural turning machines accomplish this by using\\n  an external memory, but this looks like an RNN with skip connections.\\n- Section 3.3, second paragraph - Whether the model overfits or not depends on\\n  the data. The approach doesn\\'t work with demonstrations precisely because it\\n  would overfit.\\n- Figure 4 - The reference for Batch Normalization should be Ioffe and Szegedy\\n  instead of Morimoto et al.\\n\\nOverall I think the paper has some really promising ideas and encouraging\\nresults but is missing a few exploratory/ablation experiments and some polish.',\n",
              "  'rating': '4: Ok but not good enough - rejection',\n",
              "  'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import bert_score\n",
        "from bert_score import score\n",
        "\n",
        "def clean_text(text):\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def extract_introduction(metadata):\n",
        "    \"\"\"Extracting the introduction section if available. If not, returns None.\"\"\"\n",
        "    if metadata is not None and isinstance(metadata, dict):\n",
        "        sections = metadata.get('sections', [])\n",
        "        for section in sections:\n",
        "            if section and section.get('heading'):  # Ensure section and heading are valid\n",
        "                heading = section.get('heading', '').lower()\n",
        "                if 'introduction' in heading:  # Look for \"introduction\"\n",
        "                    text = section.get('text', '')\n",
        "                    return clean_text(text) if text else None  # Return cleaned introduction text\n",
        "    return None  # Return None if no valid introduction found\n",
        "\n",
        "\n",
        "\n",
        "# TF-IDF based sentence extraction\n",
        "class TFIDFBaselineExtractor:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "    def extract_salient_sentences(self, text: str, num_sentences: int = 3) -> str:\n",
        "        if not text:\n",
        "            return ''\n",
        "\n",
        "        sentences = self._split_into_sentences(text)\n",
        "        if len(sentences) <= num_sentences:\n",
        "            return \" \".join(sentences)\n",
        "\n",
        "        tfidf_matrix = self.vectorizer.fit_transform(sentences)\n",
        "        sentence_scores = np.sum(tfidf_matrix.toarray(), axis=1)\n",
        "        top_sentence_indices = sentence_scores.argsort()[-num_sentences:][::-1]\n",
        "\n",
        "        return \" \".join([sentences[i] for i in sorted(top_sentence_indices)])\n",
        "\n",
        "    def _split_into_sentences(self, text: str) -> list:\n",
        "        return [s.strip() for s in text.split('.') if s.strip()]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DcXZpN1c0Rl8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_introduction(data['metadata'].iloc[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "re3_Km71nIpv",
        "outputId": "884fe75a-872a-41d2-facd-6ead1f7e55a2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'automatic machine learning (automl) aims to find the best performing learning algorithms with minimal human intervention. many automl methods exist, including random search [1], performance modelling [2, 3], bayesian optimization [4], genetic algorithms [5, 6] and rl [7, 8]. we focus on neural automl, that uses deep rl to optimize architectures. these methods have shown promising results. for example, neural architecture search has discovered novel networks that rival the best human-designed architectures on challenging image classification tasks [9, 10]. however, neural automl is expensive because it requires training many networks. this may require vast computations resources; zoph and le [8] report 800 concurrent gpus to train on cifar-10. further, training needs to be repeated for every new task. some methods have been proposed to address this cost, such as using a progressive search space [11], or by sharing weights among generated networks [12, 13]. we propose a complementary solution, applicable when one has multiple ml tasks to solve. humans can tune networks based on knowledge gained from prior tasks. we aim to leverage the same information using transfer learning. we exploit the fact that deep rl-based automl algorithms learn an explicit parameterization of the distribution over performant models. we present transfer neural automl, a method to accelerate network design on new tasks based on priors learned on previous tasks. to do this we design a network that performs neural automl on multiple tasks simultaneously. our method for multitask neural automl learns both hyperparameter choices common to multiple tasks and specific choices for individual tasks. we then transfer this controller to new tasks and leverage the learned priors over performant models. we reduce the time to converge in both text and image domains by over an order of magnitude in most tasks. in our experiments we save 10s of cpu hours for every task that we transfer to. 32nd conference on neural information processing systems (neurips 2018), montréal, canada.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating review based on extracted introduction\n",
        "def generate_review(metadata):\n",
        "    introduction = extract_introduction(metadata)\n",
        "    if introduction: # Check if introduction is not None\n",
        "        extractor = TFIDFBaselineExtractor()\n",
        "        return extractor.extract_salient_sentences(introduction, num_sentences=8)\n",
        "    return ''  # Return empty if no introduction\n",
        "\n",
        "# Function to calculate BERTScore for evaluation\n",
        "def calculate_bertscore(introduction, generated_review):\n",
        "    \"\"\"\n",
        "    This function calculates the BERTScore between the introduction and the generated review.\n",
        "    \"\"\"\n",
        "    if not introduction or not generated_review:\n",
        "        return None, None, None\n",
        "\n",
        "    # Calculate BERTScore\n",
        "    P, R, F1 = score([generated_review], [introduction], lang=\"en\", verbose=True)\n",
        "\n",
        "    return P.mean().item(), R.mean().item(), F1.mean().item()\n",
        "\n",
        "# Process the dataset\n",
        "def process_dataset(data: pd.DataFrame):\n",
        "    processed_data = []\n",
        "\n",
        "    # Iterate through the dataset rows\n",
        "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
        "        metadata = row['metadata']\n",
        "        generated_review = generate_review(metadata)\n",
        "\n",
        "        if generated_review:  # Proceed only if there's a generated review\n",
        "            introduction = extract_introduction(metadata)\n",
        "            P, R, F1 = calculate_bertscore(introduction, generated_review)\n",
        "\n",
        "            processed_data.append({\n",
        "                'paper_id': row['id'],\n",
        "                'title': row.get('title', 'unknown'),\n",
        "                'metadata': metadata,\n",
        "                'introduction': introduction,\n",
        "                'generated_review': generated_review,\n",
        "                'bert_precision': P,\n",
        "                'bert_recall': R,\n",
        "                'bert_f1': F1\n",
        "            })\n",
        "\n",
        "    # Convert to DataFrame for easy saving/processing\n",
        "    return pd.DataFrame(processed_data)\n",
        "processed_data = process_dataset(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895,
          "referenced_widgets": [
            "9719cb8ed07044ecb14b0160e36a43e9",
            "9d74816b1e514103aaf21092fb0c4f17",
            "d2be22cb459e44aea50a1e7916417a48",
            "482b4c305cc44f59adbf60a96cf82667",
            "829a28744c8c45bab588b0d962bc4aa3",
            "0aa533bf594d4bc5b4b585a1723489f6",
            "fdc8fb671bfe498cb9e16f96076dd665",
            "816efb1e7ffa4eb29549b8557c5bca8c",
            "5ef595a72afe423686b66a480a3d29cc",
            "c07390c19895456a82e3bf29c85520a5",
            "620d6ca3f12d4c769666b3a2cebaa90e",
            "fd24c904603d451e9987f322676f0805",
            "a5bc0c5ee35146bf9f478ee3088a1812",
            "bd4019e1529d4ffea435491fb1960fd2",
            "20acb52e80ac4ea2bf419bb73798ad40",
            "cf1ac15d2bf44cf5ababafc9c8553e7f",
            "091df882f9624db19663ff7291176020",
            "3f8e38b9093248b9a60d42fc4e828f0f",
            "1a8c8c48767b43c59a1de421c6019040",
            "cabd7e71cc594cb98a29c30894a667ab",
            "1786530cbc054459b227aea63071d943",
            "07eae1b6bd3443ae94b27aec390a7cee",
            "5c55e25aaa1148429ec7e527a9f9bb13",
            "7d8a997c540e4beeaee6d0976c3a938d",
            "244a55f22ace4dd2aa20772084b8af49",
            "cc245850ec6d4959a811971611820367",
            "d5de4be17281400a8954945afde5f5bf",
            "7439b1a3ae4649678699b21004ec3dfe",
            "37d06cdd898646b8af892e039f30e2e7",
            "aad42cf841b74867bcc3e8c3b77c2dc0",
            "180d495df33740629155f6cf51a5afd1",
            "e8476f07b70943719fa701fa5f5075e9",
            "3fd1d623fb0342f891b62465a26e9260",
            "214f43c4748d43d1a6df5379eb474872",
            "5135569001134cbfb5c488f7de44432c",
            "c459214333064e98bae82f4614c55855",
            "dc79c2c7920445a8acdd201033d2281b",
            "299dbd4e02a1404fb9a63e592f63cf48",
            "e8a7304b0e2d40318365893a56092cd1",
            "fd94b372f92a45d9b52daeaccc9c63e5",
            "5f8279766e6f49a58d6af41da6eaeae7",
            "a63e375376184ded91010c2825992365",
            "d0df84cb7aea45bc915b55826d212194",
            "feed17b02ead4320816568b0e4171e3d",
            "393ac9c4146b4960a95738b4d34aa05c",
            "8b56620ce7f3497dacc828b048b73f89",
            "f3304d2216cb45358595ce0a82e3909b",
            "d9dedd3e911d4f8daa9252a33dd2158a",
            "10932a95e19c461996780956f8630939",
            "e3167002fbf84a518aa584ea61bbbee0",
            "42b0e5a1d58244108e0c7aedd9ec04ca",
            "38ef565883d24b9bbfcf88469f9c35d0",
            "bfe81befd9fa434baff33947f279ae0f",
            "af6c496f1a3a45c8b34e877a64a8c07e",
            "e83b5e9532984cc9997e70e1a932459d",
            "97659cee00e74622beb4db2d8febe9dd",
            "375f650cc9ad4417a89b8b4fc11a6499",
            "fa065d3b1a61496da5e2867d8f519395",
            "78206f8d293e47eb85e69395a10cabe5",
            "a0a3b6685aef45758474efdc867bed13",
            "9e81cf133aa24738886618e041539c7b",
            "38cdc818925a4ad6a92ef538bd789647",
            "125bd0ceb3884be5ba86f5c1b5bd4f2b",
            "288327c915814996b327acd9b2ea0e8f",
            "798934c46d9c4a85a37e0d1f8dddb172",
            "753bdc41451241798311dcddc2bd6ed2",
            "15958307b4894f05a30cddadd734488a",
            "9cf6573bd74a4646a20b368563dee21f",
            "b680e3bb97a14b1d9bc0f04f24c9da57",
            "4ab1dca0fca645a095663cfdfcfd28c6",
            "17e4cde492024be58b8bed0a97e4c365",
            "9ad3223a8e3a49dd80562878688239e1",
            "8c1f15b43bcf4899a33b6dc92340873c",
            "db12b93007d248109663c85ae3e26bd8",
            "97f53cde218d4f6f94a09f6479790104",
            "8d9bcfa0f9d74a6fa82d9bc14fc979b8",
            "215e846cb78842a1b2e592a65752a3d1",
            "12f0c0ebf68244958f398ae54585f4ed",
            "2d7c0bef62994dc8bee9964eb68e4206",
            "01e7882812724661bac8decc3d057342",
            "91faa008f56a4e40b87b16483c40b247",
            "a2045b6796fe4a9b8c769af674f71507",
            "9555488f043540c38144486643955fbb",
            "699c33ec96a54db496c3628f8499552e",
            "e80714bb08874a0ca3a1d32a9cf77702",
            "02655cf4edc54b2aa583fe291c97d219",
            "0e47f2263df647edaf977dc5159481ef",
            "d2c75b388c734056a5e26fc2bcd37c45",
            "4111fe5e656a4aeca9578aa40934287a",
            "051edaa30df040d2ba77058a7a9e5896",
            "bf8588329ebf4623a64e88174f3fdd0d",
            "e3b053b460724cb38e5f9d2de0e9ad89",
            "95d4798c2a004bf6ae37300e1fb5ac60",
            "5c1a629a5bd6484e8d7897bea6050679",
            "89f3a5099fa046bcb07c7a2dfef2e707",
            "521134427e204015ba4854ae27bcdbee",
            "f14c113f82b5424db3a6769d8b5af711",
            "c613e616e52a412cb12b75204c4bb719",
            "4a956eb5660d4339857c1d0ce183267e",
            "f6950c4e78364148a4da59292b145f8b",
            "d965b538ff484aae82530c87f606a127",
            "00416faec7c84b05950e7d52a2d6cec3",
            "8084a48832b241eb9670ca92d6d96f4a",
            "243c48b86bbe42a0ae0c5ff7100e61fb",
            "a14f32c4e84b42ec8217e930f545adbf",
            "529adaa591c845e999886b0db4632f08",
            "c9607b48cb1c40b4ab17b6fdbf5f224f",
            "8f0e11f1c9ff4f88b2e01e5442aa00d4",
            "910bf26128fe4ebbbc141a94d9aba409",
            "4093ba5893b64409bfb6efda17997d48"
          ]
        },
        "id": "SrwhlZMunGLn",
        "outputId": "58085328-f505-4c09-b18e-ea520cfbc5bb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9719cb8ed07044ecb14b0160e36a43e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd24c904603d451e9987f322676f0805"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:12<00:49, 12.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 9.78 seconds, 0.10 sentences/sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c55e25aaa1148429ec7e527a9f9bb13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "214f43c4748d43d1a6df5379eb474872"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:23<00:35, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 9.61 seconds, 0.10 sentences/sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "393ac9c4146b4960a95738b4d34aa05c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97659cee00e74622beb4db2d8febe9dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:36<00:24, 12.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 11.13 seconds, 0.09 sentences/sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15958307b4894f05a30cddadd734488a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12f0c0ebf68244958f398ae54585f4ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:49<00:12, 12.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 11.11 seconds, 0.09 sentences/sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4111fe5e656a4aeca9578aa40934287a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6950c4e78364148a4da59292b145f8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:01<00:00, 12.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 10.66 seconds, 0.09 sentences/sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the processed data\n",
        "processed_data.to_csv('generated_reviews_with_bertscore.csv', index=False)\n",
        "\n",
        "# Example of how to access the first few results\n",
        "print(processed_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYHvE9yS66Wn",
        "outputId": "afd31ed8-668c-4f84-8660-dbae3e5d70bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         paper_id                                              title  \\\n",
            "0    ICLR_2019_47  Woulda, Coulda, Shoulda: Counterfactually-Guid...   \n",
            "1   NIPS_2017_300    Shallow Updates for Deep Reinforcement Learning   \n",
            "2  ICLR_2020_1491  CURSOR-BASED ADAPTIVE QUANTIZATION FOR DEEP NE...   \n",
            "3  ICLR_2020_1571  The Generalization-Stability Tradeoff in Neura...   \n",
            "4   ICLR_2020_585             Real or Not Real, that is the Question   \n",
            "\n",
            "                                            metadata  \\\n",
            "0  {'source': 'CRF', 'title': None, 'authors': ['...   \n",
            "1  {'source': 'META', 'title': 'Shallow Updates f...   \n",
            "2  {'source': 'CRF', 'title': None, 'authors': []...   \n",
            "3  {'source': 'CRF', 'title': 'THE GENERALIZATION...   \n",
            "4  {'source': 'CRF', 'title': None, 'authors': ['...   \n",
            "\n",
            "                                        introduction  \\\n",
            "0  imagine that a month ago alice had two job off...   \n",
            "1  reinforcement learning (rl) is a field of rese...   \n",
            "2  deep learning (dl) has achieved great successe...   \n",
            "3  pruning weights and/or convolutional filters f...   \n",
            "4  the development of generative adversarial netw...   \n",
            "\n",
            "                                    generated_review  bert_precision  \\\n",
            "0  this example tries to illustrate the everyday ...        0.892339   \n",
            "1  reinforcement learning (rl) is a field of rese...        0.916568   \n",
            "2  deep learning (dl) has achieved great successe...        0.890929   \n",
            "3  pruning weights and/or convolutional filters f...        0.954217   \n",
            "4  it learns a discriminator along with the targe...        0.930276   \n",
            "\n",
            "   bert_recall   bert_f1  \n",
            "0     0.869820  0.880936  \n",
            "1     0.871451  0.893441  \n",
            "2     0.852842  0.871470  \n",
            "3     0.918860  0.936205  \n",
            "4     0.875138  0.901865  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data['generated_review'].iloc[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "-OSfE786nGFR",
        "outputId": "61f9c43c-85db-4637-96df-09607c5bb4e1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reinforcement learning (rl) is a field of research that uses dynamic programing (dp; bertsekas 2008), among other approaches, to solve sequential decision making problems the main challenge in applying dp to real world problems is an exponential growth of computational requirements as the problem size increases, known as the curse of dimensionality (bertsekas, 2008) popular function approximators for this task include deep neural networks, henceforth termed deep rl (drl), and linear architectures, henceforth termed shallow rl (srl) in particular, batch algorithms based on a least squares (ls) approach, such as least squares temporal difference (lstd, lagoudakis & parr 2003) and fitted-q iteration (fqi, ernst et al recent advancements in drl using convolutional neural networks demonstrated learning of expressive features (zahavy et al this motivates us to ask: can we combine drl with srl to leverage the benefits of both? in this work, we develop a hybrid approach that combines batch srl algorithms with online drl following this insight, we propose a method that repeatedly re-trains the last hidden layer of a drl network with a batch srl algorithm, using data collected throughout the drl run our experiments demonstrate that this hybrid approach significantly improves performance on the atari benchmark for several combinations of drl and srl methods'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Kk2s2YkBkWTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ZOiZEig0Rbd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}